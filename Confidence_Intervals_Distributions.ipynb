{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "34458268",
      "metadata": {
        "id": "34458268"
      },
      "source": [
        "# Confidence Intervals and Related Distributions\n",
        "\n",
        "This notebook discusses motivations for sample intervals, introduces the Gamma, Chi-Square, and Student-t distributions, explains how they are used to construct confidence intervals. It includes definitions, formulas, conditions for validity, Python visualizations, and worked examples."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Do We Care About Confidence Intervals?\n",
        "\n",
        "In real-world data analysis, we often want to estimate unknown population parameters — such as the mean income in a city, the proportion of defective items in a shipment, or the true support for a political candidate.\n",
        "\n",
        "However, we almost never have access to the entire population. Instead, we collect a sample and compute statistics like the sample mean $\\bar{X}$ or sample proportion $\\hat{p}$.\n",
        "\n",
        "But sample statistics vary from one sample to another. If we report just a single number — like a point estimate — we provide **no sense of how precise or uncertain** that estimate is.\n",
        "\n",
        "---\n",
        "\n",
        "### What Is a Confidence Interval?\n",
        "\n",
        "A **confidence interval** gives us a **range of plausible values** for the unknown population parameter, based on our sample data.\n",
        "[link text](https://)\n",
        "- It helps us **quantify the uncertainty** in our estimate in a statistically principled way.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Not Just Use the Sample Estimate?\n",
        "\n",
        "Sample estimates (like $\\bar{X}$) are useful, but they can be misleading without context. Two studies might report the same sample mean, but if one is based on 20 observations and the other on 2,000, our confidence in those estimates should be very different.\n",
        "\n",
        "Confidence intervals:\n",
        "- Reflect the **sample size** and **variability** in the data\n",
        "- Provide a much richer and more honest summary of what we know\n",
        "\n",
        "---\n",
        "\n",
        "In short, confidence intervals help us make better decisions and communicate results with appropriate caution and clarity.\n"
      ],
      "metadata": {
        "id": "anYmhHz0N53C"
      },
      "id": "anYmhHz0N53C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beyond the Normal: Key Distributions for Confidence Intervals"
      ],
      "metadata": {
        "id": "wGS0cYW5f5Yx"
      },
      "id": "wGS0cYW5f5Yx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we introduce the theorems and formulas for confidence intervals, we need to review several key probability distributions beyond the normal distribution.\n",
        "\n",
        "We will use code and its output to help us better understand the concepts and theorems. Below, we import the relevant Python libraries and set up the Seaborn display style."
      ],
      "metadata": {
        "id": "QUIbwczhOahh"
      },
      "id": "QUIbwczhOahh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f9cd3d5",
      "metadata": {
        "id": "3f9cd3d5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gamma, chi2, t, norm\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b807c011",
      "metadata": {
        "id": "b807c011"
      },
      "source": [
        "\n",
        "### Gamma Distribution\n",
        "\n",
        "The Gamma distribution is a two-parameter continuous probability distribution characterized by shape parameter $ \\alpha > 0 $ and scale parameter $ \\beta > 0$.\n",
        "\n",
        "- **PDF**:  $\n",
        "f_{\\alpha, \\beta}(x) = \\frac{x^{\\alpha-1} e^{-x/\\beta}}{\\beta^\\alpha \\Gamma(\\alpha)}$, for  $x \\geq 0$,  where\n",
        "$\n",
        "\\Gamma(\\alpha) = \\int_{0}^{\\infty} s^{\\alpha - 1} e^{-s} \\, ds\n",
        "$\n",
        "\n",
        "- **Mean**: $ \\mathbb{E}[X] = \\alpha \\beta $  \n",
        "- **Variance**: $ \\text{Var}(X) = \\alpha \\beta^2 $\n",
        "\n",
        "Note that the Gamma function does not have a closed-form expression in general. However, it satisfies the recursive property  \n",
        "$\\Gamma(x + 1) = x \\, \\Gamma(x)$ for $x \\geq 1$.  \n",
        "\n",
        "In particular, when $x$ is a positive integer, $\\Gamma(x) = (x - 1)!$.\n",
        "\n",
        "Thus, the Gamma function is considered a generalization of the factorial function to the real (and even complex) numbers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we visualize the Gamma distributions for different shape and scale parameters."
      ],
      "metadata": {
        "id": "61Ni3tDIAZHz"
      },
      "id": "61Ni3tDIAZHz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Gamma Distribution for different parameters\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Varying shape parameter (α)\n",
        "x = np.linspace(0, 10, 1000)\n",
        "shapes = [1, 2, 3, 5, 10.5]\n",
        "scale = 2\n",
        "\n",
        "for shape in shapes:\n",
        "    pdf = gamma.pdf(x, a=shape, scale=scale)\n",
        "    axes[0].plot(x, pdf, label=f'α={shape}, β={scale}', linewidth=2)\n",
        "\n",
        "axes[0].set_title('Gamma Distribution - Varying Shape Parameter (α)')\n",
        "axes[0].set_xlabel('x')\n",
        "axes[0].set_ylabel('Probability Density')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Varying rate parameter (β)\n",
        "shape = 2\n",
        "scales = [5, 2, 1, 0.5, 0.2]\n",
        "\n",
        "for scale in scales:\n",
        "    pdf = gamma.pdf(x, a=shape, scale=scale)\n",
        "    axes[1].plot(x, pdf, label=f'α={shape}, β={scale}', linewidth=2)\n",
        "\n",
        "axes[1].set_title('Gamma Distribution - Varying Scale Parameter (β)')\n",
        "axes[1].set_xlabel('x')\n",
        "axes[1].set_ylabel('Probability Density')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LmFSQGOWBX2I"
      },
      "id": "LmFSQGOWBX2I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The left subplot shows Gamma PDF curves for different shape parameters while keeping the scale parameter fixed. As expected, the curves have noticeably different shapes.\n",
        "\n",
        "The right subplot shows Gamma PDF curves for different scale parameters while keeping the shape parameter fixed. These curves have similar overall shapes but appear stretched or compressed depending on the scale."
      ],
      "metadata": {
        "id": "pfF2iHHjAjzE"
      },
      "id": "pfF2iHHjAjzE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chi-Square Distribution"
      ],
      "metadata": {
        "id": "cy1o3kUsl2k4"
      },
      "id": "cy1o3kUsl2k4"
    },
    {
      "cell_type": "markdown",
      "id": "c511f85d",
      "metadata": {
        "id": "c511f85d"
      },
      "source": [
        "\n",
        "#### Definition and Properties\n",
        "\n",
        "The Chi-Square distribution is a special case of the Gamma distribution and is widely used in confidence intervals and hypothesis testing. Its parameter $n$ is called degrees of freedome.\n",
        "\n",
        "- **Relation**: $ \\chi^2_n \\sim \\text{Gamma}(\\alpha = \\frac{n}{2}, \\beta = 2) $\n",
        "- **PDF**: $f_{n}(x) = \\frac{x^{\\frac{n}{2}-1} e^{-\\frac{x}{2}}}{2^{\\frac{n}{2}} \\Gamma(\\frac{n}{2})}$ for $x > 0$\n",
        "- **Mean**: $ n $\n",
        "- **Variance**: $ 2n $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will display the Chi-Square distributions for different degrees of freedom."
      ],
      "metadata": {
        "id": "VtcjLfAFBavI"
      },
      "id": "VtcjLfAFBavI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Chi-Square Distribution for different degrees of freedom\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "x = np.linspace(0, 20, 1000)\n",
        "degrees_of_freedom = [1, 2, 3, 5, 10]\n",
        "\n",
        "for df in degrees_of_freedom:\n",
        "    pdf = chi2.pdf(x, df)\n",
        "    plt.plot(x, pdf, label=f'k={df}', linewidth=2)\n",
        "\n",
        "plt.title('Chi-Square Distribution for Different Degrees of Freedom')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "cS6JwLcCIX_I"
      },
      "id": "cS6JwLcCIX_I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These PDF curves of the chi-square distribution have shapes similar to those of the Gamma curves shown earlier in the left subplot. This is expected, since the chi-square distribution is a special case of the Gamma distribution.\n",
        "\n",
        "Next we will plot related chi-square and Gamma distributions together."
      ],
      "metadata": {
        "id": "nSTp1WTrCNhf"
      },
      "id": "nSTp1WTrCNhf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Relationship Between the Chi-Square and Gamma Distributions\n",
        "\n",
        "Recall that  $ \\chi^2_n \\sim \\text{Gamma}(\\alpha = \\frac{n}{2}, \\beta = 2)$.\n",
        "\n",
        "Next we will generate and plot both $\\chi^2$ and corresponding $\\Gamma$ distributions.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fn8fCrJWiA-w"
      },
      "id": "Fn8fCrJWiA-w"
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate relationship with Gamma distribution\n",
        "print(\"\\n### Relationship between Chi-Square and Gamma:\")\n",
        "n = 4\n",
        "x = np.linspace(0, 15, 1000)\n",
        "\n",
        "# Chi-square PDF\n",
        "chi2_pdf = chi2.pdf(x, n)\n",
        "\n",
        "# Equivalent Gamma PDF (shape = n/2, scale = 2)\n",
        "gamma_pdf = gamma.pdf(x, a=n/2, scale=2)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, chi2_pdf, 'b-', linewidth=3, label=f'Chi-Square (n={n})')\n",
        "plt.plot(x, gamma_pdf, 'r--', linewidth=2, label=f'Gamma (α={n/2}, β=2)')\n",
        "plt.title(f'Chi-Square (n={n}) as Special Case of Gamma Distribution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nfuJ0vMRIivT"
      },
      "id": "nfuJ0vMRIivT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two PDF curves, generated by the chi-square and Gamma distributions, match closely. This is expected, since they are theoretically equivalent."
      ],
      "metadata": {
        "id": "eUHg466xCgHH"
      },
      "id": "eUHg466xCgHH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Relationship Between the Chi-Square and Normal Distributions\n",
        "\n",
        "The chi-square distribution is directly related to the standard normal distribution.\n",
        "\n",
        "If $Z_1, Z_2, \\dots, Z_n$ are independent standard normal random variables (i.e., $Z_i \\sim N(0, 1)$), then the sum of their squares follows a chi-square distribution with $n$ degrees of freedom:\n",
        "\n",
        "$$\n",
        "X = \\sum_{i=1}^{n} Z_i^2 \\sim \\chi^2_n\n",
        "$$\n",
        "\n",
        "In other words, the chi-square distribution with $n$ degrees of freedom is the distribution of the sum of the squares of $n$ independent standard normal variables.\n",
        "\n",
        "\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "This relationship is foundational in statistics. It explains why the chi-square distribution is used in:\n",
        "\n",
        "- Constructing confidence intervals for population variance  \n",
        "- Hypothesis testing involving variance  \n",
        "- Goodness-of-fit tests and contingency tables\n",
        "\n",
        "It also forms the basis for deriving the Student-$t$ and some other distributions (e.g. the F distribution, not covered in the book), which involve ratios that include chi-square-distributed variables.\n"
      ],
      "metadata": {
        "id": "dv0zf3LYiKNz"
      },
      "id": "dv0zf3LYiKNz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will simulate the sum of the squares of 5 independent standard normal variables, and plot its histogram along with the theoretical chi-square distribution."
      ],
      "metadata": {
        "id": "vEKJkqQwDH4P"
      },
      "id": "vEKJkqQwDH4P"
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulation settings\n",
        "num_samples = 100000  # number of simulated experiments\n",
        "n = 5  # degrees of freedom (number of independent standard normals)\n",
        "\n",
        "# Generate n independent standard normal samples per experiment\n",
        "Z = np.random.randn(num_samples, n)\n",
        "\n",
        "# Compute the sum of squares of each row → Chi-Square(n)\n",
        "X = np.sum(Z**2, axis=1)\n",
        "\n",
        "# Plot the histogram and the theoretical chi-square PDF\n",
        "x_vals = np.linspace(0, 30, 500)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(X, bins=100, density=True, alpha=0.6, label=f'Simulated: sum of {n} $Z^2$')\n",
        "\n",
        "# Overlay theoretical Chi-Square PDF\n",
        "plt.plot(x_vals, chi2.pdf(x_vals, df=n), 'r-', lw=2, label=f'Chi-Square PDF (df={n})')\n",
        "\n",
        "plt.title(rf'Simulation: Sum of {n} Squared Standard Normals $\\sim \\chi^2_{{{n}}}$')\n",
        "\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UyX-MGqJkbSo"
      },
      "id": "UyX-MGqJkbSo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, the histogram of the sum of squares of five independent standard normal variables closely matches the theoretical Chi-Square distribution."
      ],
      "metadata": {
        "id": "ck8HpjJfEYjs"
      },
      "id": "ck8HpjJfEYjs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Student t-Distribution"
      ],
      "metadata": {
        "id": "UGWhycQEmG4j"
      },
      "id": "UGWhycQEmG4j"
    },
    {
      "cell_type": "markdown",
      "id": "b2ece6a0",
      "metadata": {
        "id": "b2ece6a0"
      },
      "source": [
        "\n",
        "#### Definition and Properties\n",
        "\n",
        "**Probability Density Function (PDF)**\n",
        "\n",
        "$f_n(x) = \\frac{\\Gamma\\left(\\frac{n + 1}{2}\\right)}{\\sqrt{n \\pi} \\, \\Gamma\\left(\\frac{n}{2}\\right)} \\cdot \\left(1 + \\frac{x^2}{n} \\right)^{-\\frac{n + 1}{2}}$\n",
        "---\n",
        "\n",
        "**Where** $x \\in \\mathbb{R}$ is the variable, and $n$ is degrees of freedom (positive integer)\n",
        "\n",
        "\n",
        "\n",
        "**Key Properties:**\n",
        "- **Expected Value (Mean):** E[T] = 0 (for n > 1)\n",
        "- **Variance:** Var(T) = n/(n-2) for n > 2, ∞ for 1 < n ≤ 2, undefined otherwise\n",
        "- Similar shape to normal distribution but heavier tails\n",
        "- Approaches the standard normal distribution as n → ∞\n",
        "- Important for small sample inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we plot the t-distrubtion for different degrees of freedom, along with the standard normal distribution."
      ],
      "metadata": {
        "id": "ej6zaM4fFA0f"
      },
      "id": "ej6zaM4fFA0f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot t-Distribution for different degrees of freedom\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "degrees_of_freedom = [1, 2, 5, 10, 30]\n",
        "\n",
        "for df in degrees_of_freedom:\n",
        "    pdf = t.pdf(x, df)\n",
        "    plt.plot(x, pdf, label=f'n={df}', linewidth=2)\n",
        "\n",
        "# Standard normal for comparison\n",
        "normal_pdf = norm.pdf(x)\n",
        "plt.plot(x, normal_pdf, 'k--', linewidth=2, label='Standard Normal')\n",
        "\n",
        "plt.title(\"Student's t-Distribution vs Standard Normal\")\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GIFV61DuerG5"
      },
      "id": "GIFV61DuerG5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of these t-distributions are symmetric about the y-axis and resemble the standard normal distribution. As the degrees of freedom increase, the t-distribution approaches the normal distribution.\n",
        "\n",
        "Next, we'll focus on the right tail of these curves to take a closer look at how the t-distributions have heavier tails."
      ],
      "metadata": {
        "id": "cPio_dKlFmct"
      },
      "id": "cPio_dKlFmct"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compare tail behavior\n",
        "plt.figure(figsize=(10, 6))\n",
        "x_tail = np.linspace(2.5, 4, 1000)\n",
        "\n",
        "for df in [1, 2, 5, 10, 30]:\n",
        "    pdf = t.pdf(x_tail, df)\n",
        "    plt.plot(x_tail, pdf, label=f't (n={df})', linewidth=2)\n",
        "\n",
        "normal_pdf = norm.pdf(x_tail)\n",
        "plt.plot(x_tail, normal_pdf, 'k--', linewidth=2, label='Standard Normal')\n",
        "\n",
        "plt.title('Tail Comparison: t-Distribution vs Normal')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YJ4OtCVpepr7"
      },
      "id": "YJ4OtCVpepr7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, all of these t-distributions have higher PDF values than the standard normal distribution in the tail region. This indicates that these tails have greater probability mass and, thus, are considered heavier."
      ],
      "metadata": {
        "id": "Mc52UUIgGekD"
      },
      "id": "Mc52UUIgGekD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Connection to Normal and Chi-Square Distributions\n",
        "\n",
        "If  \n",
        "- $Z \\sim N(0, 1)$  \n",
        "- $V \\sim \\chi^2_n$  \n",
        "- $Z$ and $V$ are independent\n",
        "\n",
        "then  \n",
        "\n",
        "$ T = \\frac{Z}{\\sqrt{V/n}} \\sim t_n$\n",
        "\n",
        "This shows that the Student-$t$ distribution arises as the ratio of a standard normal variable to the square root of a scaled chi-square variable.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zgLJJCLbdZuR"
      },
      "id": "zgLJJCLbdZuR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we siimulate how the Student-t distribution arises from a standard normal numerator and a scaled chi-square denominator. Then we compares the simulated t-distribution, the theoretical t-distribution (from scipy.stats.t), and the standard normal distribution."
      ],
      "metadata": {
        "id": "Dzq_Nksmnrdv"
      },
      "id": "Dzq_Nksmnrdv"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Settings\n",
        "num_samples = 100000\n",
        "n = 10  # degrees of freedom\n",
        "\n",
        "# Step 1: Generate standard normal values\n",
        "Z = np.random.randn(num_samples)\n",
        "\n",
        "# Step 2: Generate chi-square values with n degrees of freedom\n",
        "V = np.random.chisquare(df=n, size=num_samples)\n",
        "\n",
        "# Step 3: Compute the T values\n",
        "T = Z / np.sqrt(V / n)\n",
        "\n",
        "# Plot the simulated t-distribution and compare with theoretical t and normal\n",
        "x_vals = np.linspace(-5, 5, 500)\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Histogram of simulated T values\n",
        "plt.hist(T, bins=100, density=True, alpha=0.5, label='Simulated $t_n$')\n",
        "\n",
        "# Overlay theoretical t-distribution PDF\n",
        "plt.plot(x_vals, t.pdf(x_vals, df=n), 'r-', lw=2, label=f'Theoretical $t_{{{n}}}$')\n",
        "\n",
        "# Overlay standard normal for comparison\n",
        "plt.plot(x_vals, norm.pdf(x_vals), 'k--', lw=2, label='Standard Normal')\n",
        "\n",
        "plt.title(rf'Simulation: $T = Z / \\sqrt{{V / {n}}} \\sim t_{{{n}}}$')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h-23betim8kR"
      },
      "id": "h-23betim8kR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram of the $T$ values computed from independent standard normal and chi-square values matches the theoretical t-surve well. Both are also similar to the standard normal curve."
      ],
      "metadata": {
        "id": "3_KrRnsVNdIa"
      },
      "id": "3_KrRnsVNdIa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confidence Intervals"
      ],
      "metadata": {
        "id": "2yyhQ_iCgeW7"
      },
      "id": "2yyhQ_iCgeW7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Understanding the Critical z-value\n",
        "\n",
        "Before we define confidence intervals, it’s important to understand the **critical z-value**.\n",
        "\n",
        "A **critical z-value** is a value from the **standard normal distribution** such that the area **in the right tail** beyond this value equals a specified probability $\\alpha$. In other words,\n",
        "\n",
        "$$\n",
        "P(Z > z_{\\alpha}) = {\\alpha}\n",
        "$$\n",
        "\n",
        "\n",
        "In a two-tailed context, the critical value $z_{\\alpha/2}$ satisfies: $\n",
        "P(Z > z_\\frac{\\alpha}{2}) = \\frac{\\alpha}{2}\n",
        "$. This means the area to the right of $z_{\\alpha/2}$ is $\\alpha/2$, and by symmetry, the area to the left of $-z_{\\alpha/2}$ is also $\\alpha/2$. The area **between** $-z_{\\alpha/2}$ and $z_{\\alpha/2}$ is $1 - \\alpha$, i.e.\n",
        "\n",
        "$$P( z_\\frac{\\alpha}{2} > Z > -z_\\frac{\\alpha}{2}) = 1 - {\\alpha}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "o109P5S_sRQc"
      },
      "id": "o109P5S_sRQc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define a function that accepts an alpha parameter, computes the corresponding critical value, and plots the standard normal distribution with the confidence region and its boundaries highlighted.\n"
      ],
      "metadata": {
        "id": "TICOioGQONIa"
      },
      "id": "TICOioGQONIa"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_critical_z(alpha=0.05):\n",
        "    \"\"\"\n",
        "    Plot the standard normal distribution showing the critical z-values\n",
        "    and the central confidence region corresponding to (1 - alpha).\n",
        "\n",
        "    Parameters:\n",
        "    alpha (float): error rate (e.g., 1- alpha is the confidence level)\n",
        "    \"\"\"\n",
        "    z_crit = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = norm.pdf(x)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(x, y, label='Standard Normal PDF', color='black')\n",
        "\n",
        "    # Fill central (1 - alpha) region\n",
        "    plt.fill_between(x, y, where=(x >= -z_crit) & (x <= z_crit),\n",
        "                     color='skyblue', alpha=0.6,\n",
        "                     label=f'Confidence Region ({100*(1 - alpha):.0f}%)')\n",
        "\n",
        "    # Fill tail regions\n",
        "    plt.fill_between(x, y, where=(x < -z_crit), color='salmon', alpha=0.6,\n",
        "                     label=f'Tail Area ({100*alpha/2:.1f}%)')\n",
        "    plt.fill_between(x, y, where=(x > z_crit), color='salmon', alpha=0.6)\n",
        "\n",
        "    # Annotate critical values\n",
        "    plt.axvline(-z_crit, color='blue', linestyle='--',\n",
        "                label=f'$-z_{{\\\\alpha/2}} \\\\approx {-z_crit:.2f}$')\n",
        "    plt.axvline(z_crit, color='blue', linestyle='--',\n",
        "                label=f'$z_{{\\\\alpha/2}} \\\\approx {z_crit:.2f}$')\n",
        "\n",
        "    plt.title(f'Critical z-values and Confidence Region for α = {alpha}')\n",
        "    plt.xlabel('Z')\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "-ARPvixGu9Tq"
      },
      "id": "-ARPvixGu9Tq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will apply the function using different alpha values, specifically, 0.10, 0.05, and 0.01m. They correspond to 90%, 95%, and 99% confidence levels.\n"
      ],
      "metadata": {
        "id": "cKACdgruO56w"
      },
      "id": "cKACdgruO56w"
    },
    {
      "cell_type": "code",
      "source": [
        "plot_critical_z(alpha=0.10)   # 90% confidence\n"
      ],
      "metadata": {
        "id": "RQlg-m4IvA1o"
      },
      "id": "RQlg-m4IvA1o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_critical_z(alpha=0.05)   # 95% confidence\n"
      ],
      "metadata": {
        "id": "jRykBXeJvGWO"
      },
      "id": "jRykBXeJvGWO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_critical_z(alpha=0.01)   # 99% confidence"
      ],
      "metadata": {
        "id": "4tDTQIn_vOic"
      },
      "id": "4tDTQIn_vOic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the error rate decreases and the confidence level increases, the confidence interval becomes wider."
      ],
      "metadata": {
        "id": "nD11TIJFQBUH"
      },
      "id": "nD11TIJFQBUH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assumption of Simple Random Sampling\n",
        "\n",
        "Before we introduce any confidence interval formulas, it’s important to highlight a key assumption shared across all of them:\n",
        "\n",
        "> **All standard confidence interval formulas assume that the sample is a simple random sample (SRS) from the population.**\n",
        "\n",
        "A **simple random sample** means:\n",
        "- Every member of the population has an equal chance of being selected,\n",
        "- The observations in the sample are independent of one another.\n",
        "\n",
        "This assumption is critical because it ensures that:\n",
        "- Sample statistics (like the sample mean $\\bar{X}$, sample proportion $\\hat{p}$, sample variance $s^2$) are **unbiased estimators** of population parameters,\n",
        "- The theoretical formulas for confidence intervals yield **valid coverage probabilities** (e.g., 95%).\n",
        "\n",
        "---\n",
        "\n",
        "### What If the Sample Is Not Random?\n",
        "\n",
        "If the sample is not drawn randomly (e.g., convenience sample or voluntary response), or if the observations are not independent (e.g., clustered or time-dependent), then:\n",
        "- The confidence interval may not be valid,\n",
        "- The actual error rate may be much higher than expected,\n",
        "- Any conclusions drawn from the interval could be misleading.\n",
        "\n",
        "In such cases, more advanced methods are needed to adjust for the sampling design or dependence structure.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "\n",
        "| Type of Confidence Interval         | Requires Simple Random Sample? | Why?                                 |\n",
        "|------------------------------------|-------------------------------|--------------------------------------|\n",
        "| Population Mean                    | Yes                           | Ensures $\\bar{X}$ is unbiased        |\n",
        "| Population Proportion              | Yes                           | Validates binomial and CLT-based logic |\n",
        "| Population Variance                | Yes                           | Based on chi-square distribution     |\n",
        "| Correlation Coefficient            | Yes                           | Assumes independent bivariate pairs  |\n",
        "\n",
        "In all cases, **randomness and independence** are essential for reliable inference.\n",
        "\n",
        "In all of our examples and homework problems, the data are assumed to come from a simple random sample."
      ],
      "metadata": {
        "id": "wJRISJFbMmTx"
      },
      "id": "wJRISJFbMmTx"
    },
    {
      "cell_type": "markdown",
      "id": "75b219f0",
      "metadata": {
        "id": "75b219f0"
      },
      "source": [
        "\n",
        "### Confidence Interval for the Mean (σ Known)\n",
        "\n",
        "$\n",
        "\\bar{X} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
        "$\n",
        "\n",
        "where $1-\\alpha$ is the confidence level and $n$ is the sample size. The value $\\alpha$ represents the total error rate, or the probability that the true population mean falls outside the confidence interval.\n",
        "\n",
        "\n",
        "**Is a normal population required?**\n",
        "\n",
        "- Yes, if the sample size is small. The formula is exact only when the population is normally distributed.\n",
        "- No, if the sample size is large (typically $n \\geq 30$). The Central Limit Theorem (CLT) allows the sampling distribution of the sample mean to be approximately normal, so the formula is still valid for large samples.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Margin of Error\n",
        "\n",
        "In the confidence interval formula introduced above:\n",
        "\n",
        "$$\n",
        "\\bar{X} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}},\n",
        "$$\n",
        "\n",
        "the term $z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}$ is commonly referred to as the **margin of error**.\n",
        "\n",
        "The margin of error represents the **maximum expected difference** between the sample mean and the true population mean, given the specified confidence level.\n",
        "\n",
        "This concept generalizes beyond the population mean — it also applies to confidence intervals for other quantities, such as **proportions** and **variances**, and to other probability distributions. We will explore these extensions later.\n",
        "\n",
        "The margin of error also defines the **half-width** of the confidence interval:\n",
        "\n",
        "$$\n",
        "\\text{Interval Center} \\pm \\text{Margin of Error}\n",
        "$$\n",
        "\n",
        "A smaller margin of error means the estimate is more precise. The margin of error can generally be reduced by:\n",
        "\n",
        "- Increasing the sample size $n$\n",
        "- Decreasing the confidence level (which lowers $z_{\\alpha/2}$)\n",
        "- Reducing the variability in the population (i.e., a smaller $\\sigma$)\n"
      ],
      "metadata": {
        "id": "wR_etbEr0G1-"
      },
      "id": "wR_etbEr0G1-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example\n",
        "\n",
        "Next we go through an example from the textbook, allowing different confidence leavels for easy exploration with the code.\n",
        "\n",
        "First the data, sample mean, and known standard deviation."
      ],
      "metadata": {
        "id": "m1ttQwWHw8_G"
      },
      "id": "m1ttQwWHw8_G"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example 3.5: Trace element in ingots (known variance)\n",
        "print(\"\\n### Example 3.5: Trace Elements in Ingots (Known Variance)\")\n",
        "\n",
        "# Data from Table 3.3\n",
        "data = np.array([125, 110, 112, 116, 131, 108,\n",
        "                 114, 121, 107, 106, 121, 106,\n",
        "                 107, 113, 110, 113, 100, 121,\n",
        "                 112, 109, 113, 113, 116, 109,\n",
        "                 114, 123, 104, 112, 108, 113])\n",
        "\n",
        "sample_mean = np.mean(data)\n",
        "n = len(data)\n",
        "known_variance = 49  # σ² = 49\n",
        "known_std = np.sqrt(known_variance)  # σ = 7\n",
        "\n",
        "print(f\"Sample size: n = {n}\")\n",
        "print(f\"Sample mean: X̄ = {sample_mean:.3f} ppm\")\n",
        "print(f\"Known population standard deviation: σ = {known_std}\")"
      ],
      "metadata": {
        "id": "f6QBdb5xxIXi"
      },
      "id": "f6QBdb5xxIXi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output confirms the sample mean reported in the book. Next, we compute the confidence interval for the mean using the confidence level set by the variables below."
      ],
      "metadata": {
        "id": "hEk9rEj6xTjk"
      },
      "id": "hEk9rEj6xTjk"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- confidence levels ---\n",
        "confidence_level = 0.90  # Change to 0.95, 0.99, etc.\n",
        "alpha = 1 - confidence_level"
      ],
      "metadata": {
        "id": "hUA1f9Io7t_l"
      },
      "id": "hUA1f9Io7t_l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "z_critical = norm.ppf(1 - alpha / 2) #ppf serves as inverse cdf\n",
        "\n",
        "margin_of_error = z_critical * known_std / np.sqrt(n)\n",
        "ci_lower = sample_mean - margin_of_error\n",
        "ci_upper = sample_mean + margin_of_error\n",
        "\n",
        "print(f\"\\n{int(confidence_level * 100)}% Confidence Interval:\")\n",
        "print(f\"Critical value: z_{alpha/2:.3f} = {z_critical:.3f}\")\n",
        "print(f\"Margin of error: {margin_of_error:.3f}\")\n",
        "print(f\"Confidence Interval: ({ci_lower:.3f}, {ci_upper:.3f})\")"
      ],
      "metadata": {
        "id": "0RzqmAvexSMd"
      },
      "id": "0RzqmAvexSMd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results for the 95% confidence level match those presented in the textbook. Note that the confidence level used above may differ from 95%, depending on the  value of alpha that was set earlier.\n",
        "\n",
        "Next, we visualize the confidence interval."
      ],
      "metadata": {
        "id": "x8XWQTQx1jYD"
      },
      "id": "x8XWQTQx1jYD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot normal distribution\n",
        "x = np.linspace(sample_mean - 4*known_std/np.sqrt(n),\n",
        "                sample_mean + 4*known_std/np.sqrt(n), 1000)\n",
        "pdf = norm.pdf(x, sample_mean, known_std/np.sqrt(n))\n",
        "\n",
        "plt.plot(x, pdf, 'b-', linewidth=2, label='Sampling Distribution of X̄')\n",
        "plt.axvline(sample_mean, color='red', linestyle='--',\n",
        "            label=f'Sample Mean = {sample_mean:.1f}')\n",
        "\n",
        "# Shade confidence interval\n",
        "x_ci = np.linspace(ci_lower, ci_upper, 100)\n",
        "pdf_ci = norm.pdf(x_ci, sample_mean, known_std/np.sqrt(n))\n",
        "plt.fill_between(x_ci, pdf_ci, alpha=0.3, color='blue',\n",
        "                 label=f'{int(confidence_level * 100)}% Confidence Interval')\n",
        "\n",
        "plt.axvline(ci_lower, color='green', linestyle=':', alpha=0.7)\n",
        "plt.axvline(ci_upper, color='green', linestyle=':', alpha=0.7)\n",
        "\n",
        "plt.title(f'{int(confidence_level * 100)}% Confidence Interval for Mean (Known Variance)')\n",
        "plt.xlabel('Sample Mean (ppm)')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hud65I7Aphta"
      },
      "id": "hud65I7Aphta",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d36964c5",
      "metadata": {
        "id": "d36964c5"
      },
      "source": [
        "\n",
        "### Confidence Interval for the Mean (σ Unknown)\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "\n",
        "$\\bar{X} \\pm t_{n-1, \\alpha/2} \\cdot \\dfrac{s_n}{\\sqrt{n}}$\n",
        "\n",
        "where $s_n$ is the sample standard deviation, and $t_{n-1, \\alpha/2}$ is the critical value from the t-distribution with $n - 1$ degrees of freedom.\n",
        "\n",
        "Specifically, for the upper-tail critical value $t_{n,\\alpha}$:\n",
        "\n",
        "$$\n",
        "P(T_n > t_{n,\\alpha}) = \\alpha\n",
        "$$\n",
        "\n",
        "Conceptually, for the computation of confidence interval, $t_{n-1, \\alpha/2}$ plays the same role in the t-distribution that $z_{\\alpha/2}$ does in the standard normal distribution: it marks the cutoff point beyond which only $\\alpha/2$ of the probability remains in each tail.\n",
        "\n",
        "\n",
        "**Is a normal population required?**\n",
        "\n",
        "- Yes, especially for small sample sizes. The $t$-distribution is derived under the assumption of normality.\n",
        "- No, if the sample size is large. The $t$-distribution approaches the normal distribution, so the formula becomes approximately valid."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we use code to solve example 3.6"
      ],
      "metadata": {
        "id": "IQaDOVFJR-nU"
      },
      "id": "IQaDOVFJR-nU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3.6: Trace element in ingots (unknown variance)\n",
        "print(\"\\n### Example 3.6: Trace Elements in Ingots (Unknown Variance)\")\n",
        "\n",
        "\n",
        "# Assuming data, sample_mean, known_std, and n are defined\n",
        "sample_std = np.std(data, ddof=1)  # Sample standard deviation\n",
        "print(f\"Sample standard deviation: s = {sample_std:.1f}\")\n",
        "\n",
        "# --- Confidence Interval using t-distribution ---\n",
        "df = n - 1\n",
        "t_critical = t.ppf(1 - alpha / 2, df)\n",
        "\n",
        "margin_of_error_t = t_critical * sample_std / np.sqrt(n)\n",
        "ci_lower_t = sample_mean - margin_of_error_t\n",
        "ci_upper_t = sample_mean + margin_of_error_t\n",
        "\n",
        "print(f\"\\n{int(confidence_level * 100)}% Confidence Interval (Unknown Variance):\")\n",
        "print(f\"Degrees of freedom: df = {df}\")\n",
        "print(f\"Critical value: t_({df}, {alpha/2:.3f}) = {t_critical:.3f}\")\n",
        "print(f\"Margin of error: {margin_of_error_t:.3f}\")\n",
        "print(f\"Confidence Interval: ({ci_lower_t:.3f}, {ci_upper_t:.3f})\")"
      ],
      "metadata": {
        "id": "egAkn3BB6J1C"
      },
      "id": "egAkn3BB6J1C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again, the results for the 95% confidence level match those presented in the textbook. Note that the confidence level used above may differ from 95%, depending on the value of alpha that was set earlier."
      ],
      "metadata": {
        "id": "Hj-iTuaGSGF7"
      },
      "id": "Hj-iTuaGSGF7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we compare the confidence intervals computed from sample variance (right above, using t-distribution) and true variance (earlier, using the normal distribution), and plot the t-distribution and normal distribution."
      ],
      "metadata": {
        "id": "UkG6GL6ESagh"
      },
      "id": "UkG6GL6ESagh"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Comparison (assuming known variance CI already computed) ---\n",
        "print(\"\\nComparison:\")\n",
        "print(f\"Known variance CI: ({ci_lower:.3f}, {ci_upper:.3f})\")\n",
        "print(f\"Unknown variance CI: ({ci_lower_t:.3f}, {ci_upper_t:.3f})\")\n",
        "print(f\"Difference in width: {((ci_upper_t - ci_lower_t) - (ci_upper - ci_lower)):.3f}\")\n",
        "\n",
        "# --- Visualization ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "x = np.linspace(sample_mean - 4 * sample_std / np.sqrt(n),\n",
        "                sample_mean + 4 * sample_std / np.sqrt(n), 1000)\n",
        "\n",
        "pdf_normal = norm.pdf(x, sample_mean, known_std / np.sqrt(n))\n",
        "pdf_t = t.pdf((x - sample_mean) / (sample_std / np.sqrt(n)), df) * np.sqrt(n) / sample_std\n",
        "\n",
        "plt.plot(x, pdf_normal, 'b-', linewidth=2, label='Normal (Known σ)')\n",
        "plt.plot(x, pdf_t, 'r-', linewidth=2, label=f't-distribution (df={df})')\n",
        "\n",
        "plt.axvline(ci_lower, color='blue', linestyle='--', alpha=0.7, label='Normal CI bounds')\n",
        "plt.axvline(ci_upper, color='blue', linestyle='--', alpha=0.7)\n",
        "plt.axvline(ci_lower_t, color='red', linestyle='--', alpha=0.7, label='t-dist CI bounds')\n",
        "plt.axvline(ci_upper_t, color='red', linestyle='--', alpha=0.7)\n",
        "plt.axvline(sample_mean, color='black', linestyle='-', label=f'Sample Mean = {sample_mean:.1f}')\n",
        "\n",
        "plt.title(f'Comparison: {int(confidence_level * 100)}% Confidence Intervals (Known vs Unknown Variance)')\n",
        "plt.xlabel('Sample Mean (ppm)')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4yEabvIKGiIm"
      },
      "id": "4yEabvIKGiIm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this particular example, the two distributions curves are very similar to each other. So are the confidence intervals."
      ],
      "metadata": {
        "id": "QKuAej2l53lp"
      },
      "id": "QKuAej2l53lp"
    },
    {
      "cell_type": "markdown",
      "id": "efce3635",
      "metadata": {
        "id": "efce3635"
      },
      "source": [
        "### Confidence Interval for Proportions\n",
        "**Note:** We covered Section 3.3.2 (including Example 3.7) and Problem 3.6 in class. The text below is provided for your reference on the theoretical aspects of this topic.\n",
        "\n",
        "\n",
        "**Motivation**\n",
        "\n",
        "Estimating a population proportion is a common goal in statistics. For example, we may want to estimate:\n",
        "\n",
        "- The proportion of defective parts in a shipment\n",
        "- The proportion of voters who support a candidate\n",
        "- The proportion of emails that are spam\n",
        "\n",
        "Rather than trying to measure the entire population, we collect a sample and compute the sample proportion $\\bar{X} = \\hat{p} = \\frac{x}{n}$, where:\n",
        "\n",
        "- $x$ is the number of \"successes\" in the sample\n",
        "- $n$ is the total sample size\n",
        "\n",
        "We then construct a **confidence interval** to estimate the true population proportion $p$.\n",
        "\n",
        "---\n",
        "\n",
        "**Confidence Interval Formula**\n",
        "\n",
        "When the sample size is sufficiently large, the confidence interval for the population proportion $p$ is given by:\n",
        "\n",
        "$$\n",
        "\\hat{p_n} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p_n}(1 - \\hat{p_n})}{n} }\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\hat{p_n}$ is the sample proportion\n",
        "- $z_{\\alpha/2}$ is the critical value from the standard normal distribution\n",
        "- $n$ is the sample size\n",
        "- $1 - \\alpha$ is the confidence level\n",
        "\n",
        "---\n",
        "\n",
        "#### **When Is This Formula Valid?**\n",
        "\n",
        "This formula is **approximately valid** under the following conditions:\n",
        "\n",
        "- The sample is a **simple random sample** from the population\n",
        "- The sample size is **large enough** so that both:\n",
        "  - $n \\hat{p} \\geq 5$\n",
        "  - $n(1 - \\hat{p}) \\geq 5$\n",
        "\n",
        "These conditions ensure that the sampling distribution of $\\hat{p}$ is approximately normal, according to the Central Limit Theorem.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Is a Normal Population Required?**\n",
        "\n",
        "**No, when the sample size is large enough.** Since we are dealing with a proportion (a discrete quantity), the population itself is **not normally distributed**.\n",
        "\n",
        "However, the formula relies on the **sampling distribution of the sample proportion** $\\hat{p}$ being approximately normal. This happens when the sample size is large and the success/failure conditions above are met.\n",
        "\n",
        "\n",
        "\n",
        "Specifically:\n",
        "\n",
        "$$\n",
        "\\hat{p} \\approx N\\left( \\hat{p}, \\sqrt{\\hat{p}(1 - \\hat{p}) / n} \\right)\n",
        "$$\n",
        "\n",
        "That is, the sampling distribution of $\\hat{p}$ is approximately normal, with:\n",
        "\n",
        "- **Mean**: $\\hat{p}$ (the observed sample proportion)\n",
        "- **Standard deviation** (also called the standard error):  \n",
        "  $$\n",
        "  \\sqrt{ \\hat{p}(1 - \\hat{p}) / n }\n",
        "  $$\n",
        "\n",
        "This approximation allows us to use the **standard normal distribution** to construct a confidence interval, even though $\\hat{p}$ is a proportion (not a continuous variable).\n",
        "\n",
        "---\n",
        "\n",
        "#### What to Do Instead for Small Samples\n",
        "\n",
        "If the sample size is small and the success/failure conditions are not met (i.e.,  \n",
        "$n \\hat{p} < 5$ or $n(1 - \\hat{p}) < 5$), then the formula above should **not** be used for constructing a confidence interval for a proportion.\n",
        "\n",
        "Instead, consider one of the following approaches:\n",
        "\n",
        "- **Exact Binomial Interval (Clopper–Pearson):**  \n",
        "  A conservative method based on the exact binomial distribution, not an approximation.\n",
        "\n",
        "- **Wilson Score Interval:**  \n",
        "  A more accurate method than the standard normal approximation, especially for small $n$ or extreme proportions.\n",
        "\n",
        "- **Bayesian Intervals:**  \n",
        "  Use a prior distribution and provide a credible interval for the true proportion. These are conceptually different from classical confidence intervals but often better calibrated for small samples.\n",
        "\n",
        "These methods provide more reliable results when the sample size is small or the proportion is very close to 0 or 1. They are beyond the scope of our course.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}