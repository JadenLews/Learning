{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bf807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Prevents crashes when showing graphs\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "SIM_STEPS = 201\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Determined train/test/val split\n",
    "train_sims = np.load(\"../train_sims.npy\")\n",
    "train_sims = train_sims[train_sims < 750]\n",
    "val_sims = np.load(\"../val_sims.npy\")\n",
    "val_sims = val_sims[val_sims < 750]\n",
    "test_sims = np.load(\"../test_sims.npy\")\n",
    "test_sims = test_sims[test_sims < 750]\n",
    "\n",
    "# Get porosity phi\n",
    "def get_phi(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_phi.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get pressure\n",
    "def get_pres(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_P.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get conductivity K\n",
    "def get_k(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_K.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get all 3 as a 3-channel matrix\n",
    "def get_all(sim,step):\n",
    "    return np.array((get_k(sim,step), get_pres(sim,step), get_phi(sim,step)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6210558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darcy loss function\n",
    "def darcy_loss(model, inp):\n",
    "    # Takes in the k,pres,phi and outputs the prediction across the image.\n",
    "    inp = inp.requires_grad_(True)\n",
    "    out = model(inp)\n",
    "    # out is in order K,P,phi, (conductivity, pressure, porosity)\n",
    "\n",
    "    # Impose high pressure along the entire upper line by setting the pressure channelt to 200.\n",
    "    out[:, 1:2, 0, :] = 200\n",
    "\n",
    "    # If we assume the output is in order k,pres,phi\n",
    "    # pres_grad is the gradient of the pressure along the y and x directions as a tuple\n",
    "    pres_grad = torch.gradient(out[:, 1:2], dim=(-2,-1))\n",
    "\n",
    "    # get velocity by multiplying the gradient by the conductivity\n",
    "    y_grad = pres_grad[0] * out[:, 0:1]\n",
    "    x_grad = pres_grad[1] * out[:, 0:1]\n",
    "\n",
    "    # compute the divergence by the second derivative of the gradients and adding them together\n",
    "    yy_grad = torch.gradient(y_grad, spacing=(1,),dim=(-2,))[0]\n",
    "    xx_grad = torch.gradient(x_grad, spacing=(1,),dim=(-1,))[0]\n",
    "    final = yy_grad + xx_grad\n",
    "\n",
    "    # total divergence should be 0\n",
    "    loss = (final**2).mean()\n",
    "\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Blocks of the Unet\n",
    "\n",
    "class TwoConv(nn.Module):\n",
    "    # Basic block with 2 convolutional layers, each with a batch norm and relu\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, no_end_relu=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if no_end_relu:\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.seq(inp)\n",
    "\n",
    "# A single conv layer that will increase the height and width of the matrix by 2 each.\n",
    "class SmallUp(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "\n",
    "# A single conv layer that will decrease the height and width of the matrix by 2 each.\n",
    "class SmallDown(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 0)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "    \n",
    "# Applies two convolutional layers, then pools\n",
    "class Downsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = TwoConv(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        return self.pool(self.conv(inp))\n",
    "\n",
    "# Upsamples and concatenates the upsampled matrix with the \"across\" then performs convolution on the result\n",
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, tweak=None):\n",
    "        super().__init__()\n",
    "        # Upsamples by 2x\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)\n",
    "        self.tweak = tweak\n",
    "        self.conv_after = TwoConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, below, across):\n",
    "        # First upsample by 2x\n",
    "        upsampled = self.up(below)\n",
    "        # If tweak is active, apply it first\n",
    "        if not self.tweak == None:\n",
    "            upsampled = self.tweak(upsampled)\n",
    "        # Concatenate with the same size on the downswing of the unet\n",
    "        concat = torch.concat((upsampled, across), dim=-3)\n",
    "        # Convolute them together\n",
    "        return self.conv_after(concat)\n",
    "    \n",
    "# Define the actual model used\n",
    "class SmallUnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input is Nx3x200x200\n",
    "        self.c1 = TwoConv(3, 8)\n",
    "        self.d1 = Downsample(8,16) # 16x100x100\n",
    "        self.d2 = Downsample(16,32) # 32x50x50\n",
    "        self.su = nn.Sequential(\n",
    "            SmallUp(32),\n",
    "            SmallUp(32),\n",
    "            SmallUp(32)\n",
    "        ) # 3x56x56\n",
    "        self.d3 = Downsample(32,64) # 64x28x28\n",
    "        self.d4 = Downsample(64,128) # 128x14x14\n",
    "        self.d5 = Downsample(128, 256) # 256x7x7\n",
    "\n",
    "        # Now back up\n",
    "        self.u1 = Upsample(256, 128) # 128x14x14\n",
    "        self.u2 = Upsample(128, 64) # 64x28x28\n",
    "        self.u3 = Upsample(64, 32, tweak=nn.Sequential(\n",
    "            SmallDown(32),\n",
    "            SmallDown(32),\n",
    "            SmallDown(32)\n",
    "        ))  # 32x50x50\n",
    "        self.u4 = Upsample(32,16) # 16x100x100\n",
    "        self.u5 = Upsample(16,8) # 8x200x200\n",
    "        self.final = TwoConv(8, 3, no_end_relu=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Start with convolution, expand 3 channels to 8.\n",
    "        # Then downsample 5 times, saving the result\n",
    "        top = self.c1(input)\n",
    "        x1 = self.d1(top)\n",
    "        x2 = self.d2(x1)\n",
    "        x3 = self.d3(self.su(x2)) # Here we upsample slightly so that we can downsample with less border artifacts\n",
    "        x4 = self.d4(x3)\n",
    "        x5 = self.d5(x4)\n",
    "        # Now that we're at 256x7x7, we upsample from here.\n",
    "        # At each layer with concatenate with the xi that is the same size as the up after upsampling.\n",
    "        up = self.u1(x5, x4)\n",
    "        up = self.u2(up, x3)\n",
    "        up = self.u3(up, x2) # Again, a small downsample here to get back on the proper resolution\n",
    "        up = self.u4(up, x1)\n",
    "        up = self.u5(up, top)\n",
    "        # One last convolution on the result to return to 3 channels from 8, leaving us with the proper 3x200x200\n",
    "        return self.final(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e969716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 sims,\n",
    "                 unmask_size=20,\n",
    "                 points = None,\n",
    "                 block_size = 50,\n",
    "                 reveal_strategy = \"block\",\n",
    "                 n_points = 200,\n",
    "                 radius = 2,\n",
    "                 steps = None,\n",
    "                 H=200,\n",
    "                 W=200,\n",
    "                 channels=\"all\",\n",
    "                 mixed=False,\n",
    "                 types=None,\n",
    "                 noise=5,\n",
    "                 return_mask=False,                 # allows visualiztion of mask\n",
    "                 reveal_dim=[[(0, 1)], [(0, 1)]],   # x,y range for disks to exist\n",
    "                 jitter_std=0.0,                    # % each disk drifts from deterministic position\n",
    "                 deterministic_mask=True,            # if True, mask is deterministic and noise is 0\n",
    "                 future_delta=0\n",
    "                 ):\n",
    "        \n",
    "        self.sims = sims\n",
    "        self.points = points\n",
    "        self.steps = steps\n",
    "        self.size = unmask_size\n",
    "        self.reveal_strategy = reveal_strategy\n",
    "        self.block_size = block_size\n",
    "        self.n_points = n_points\n",
    "        self.radius = radius\n",
    "        self.H, self.W = H, W\n",
    "        self.channels = channels\n",
    "        self.mixed = mixed\n",
    "        self.types = types\n",
    "        self.noise = noise\n",
    "        self.return_mask = return_mask\n",
    "        self.reveal_dim = reveal_dim\n",
    "        self.jitter_std = jitter_std\n",
    "        self.deterministic_mask = deterministic_mask\n",
    "        self.future_delta = future_delta\n",
    "\n",
    "    def _chan_idx(self):\n",
    "        if self.channels == \"all\":\n",
    "            return [0,1,2]\n",
    "        elif self.channels == \"K\":\n",
    "            return [0]\n",
    "        elif self.channels == \"P\":\n",
    "            return [1]\n",
    "        elif self.channels == \"phi\":\n",
    "            return [2]\n",
    "        else:\n",
    "            raise ValueError(\"channels must be 'all', 'K', 'P', or 'phi'\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # --- In Progress --- \n",
    "\n",
    "            # pick a valid step\n",
    "        if not isinstance(self.steps, np.ndarray):\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta  # ensures step + delta â‰¤ 199\n",
    "            step = np.random.randint(1, max_start + 1)  \n",
    "        else:\n",
    "            step = int(self.steps[index])\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta\n",
    "            if step > max_start:\n",
    "                step = max_start\n",
    "\n",
    "\n",
    "\n",
    "        # if not type(self.steps) == np.ndarray:\n",
    "        #     step = np.random.randint(1,200)\n",
    "        # else:\n",
    "        #     step = self.steps[index]\n",
    "\n",
    "\n",
    "\n",
    "        # Create tensor for the target\n",
    "        t_cur = torch.tensor(get_all(self.sims[index], step), dtype=torch.float32)\n",
    "\n",
    "        # Create 0 matrix\n",
    "        z = torch.zeros_like(t_cur)\n",
    "\n",
    "        # build a boolean mask of revealed pixels, shape (H,W)\n",
    "        mask = torch.zeros((self.H, self.W), dtype=torch.bool)\n",
    "\n",
    "        chans = self._chan_idx()\n",
    "\n",
    "        if self.reveal_strategy == \"block\":\n",
    "            # choose top-left for the block\n",
    "            if not type(self.points) == np.ndarray:\n",
    "                i0 = np.random.randint(0, self.H - self.block_size + 1)\n",
    "                j0 = np.random.randint(0, self.W - self.block_size + 1)\n",
    "            else:\n",
    "                i0, j0 = self.points[index]\n",
    "                i0 = max(0, min(i0, self.H - self.block_size))\n",
    "                j0 = max(0, min(j0, self.W - self.block_size))\n",
    "            mask[i0:i0+self.block_size, j0:j0+self.block_size] = True\n",
    "\n",
    "        elif self.reveal_strategy == \"disks\":\n",
    "\n",
    "            # used for reveal_dim\n",
    "            # map fraction [0,1] to pixel indices [0, N-1] in mask layer\n",
    "            def _segments_to_indices(segments, N, pad=0):\n",
    "                idxs = []\n",
    "                for a, b in segments:\n",
    "                    i0 = max(pad, int(round(a * (N - 1))))\n",
    "                    i1 = min((N - 1) - pad, int(round(b * (N - 1))))\n",
    "                    if i1 >= i0:\n",
    "                        idxs.append(torch.arange(i0, i1 + 1, dtype=torch.long))\n",
    "                if not idxs:\n",
    "                    # fallback to full range\n",
    "                    return torch.arange(pad, N - pad, dtype=torch.long)\n",
    "                return torch.unique(torch.cat(idxs)).to(torch.long)\n",
    "\n",
    "            row_fracs = self.reveal_dim[0] # e.g, [(0, 1)]\n",
    "            col_fracs = self.reveal_dim[1] # e.g, [(0, 1)]\n",
    "            row_allowed = _segments_to_indices(row_fracs, self.H, pad=self.radius)\n",
    "            col_allowed = _segments_to_indices(col_fracs, self.W, pad=self.radius)\n",
    "\n",
    "            # choose grid shape close to aspect ratio \n",
    "            # works with non-squares\n",
    "            Hspan = (row_allowed[-1] - row_allowed[0] + 1) if len(row_allowed) > 0 else self.H\n",
    "            Wspan = (col_allowed[-1] - col_allowed[0] + 1) if len(col_allowed) > 0 else self.W\n",
    "            ratio = float(Wspan) / max(1.0, float(Hspan))\n",
    "            ny = int(max(1, round(np.sqrt(self.n_points / max(1e-8, ratio)))))\n",
    "            nx = int(max(1, round(self.n_points / ny)))\n",
    "            while nx * ny < self.n_points:\n",
    "                nx += 1\n",
    "\n",
    "            # pick evenly spaced indices from rows/cols allowed\n",
    "            def pick_lin_indices(allowed, k):\n",
    "                if k <= 1:\n",
    "                    return allowed[len(allowed)//2]\n",
    "                pos = torch.linspace(0, len(allowed)-1, steps=k)\n",
    "                idx = torch.round(pos).long()\n",
    "                return allowed[idx]\n",
    "            \n",
    "            \n",
    "            row_picks = pick_lin_indices(row_allowed, ny)\n",
    "            col_picks = pick_lin_indices(col_allowed, nx)\n",
    "            yy, xx = torch.meshgrid(row_picks, col_picks, indexing=\"ij\")\n",
    "            points = torch.stack([yy.reshape(-1), xx.reshape(-1)], dim=1) # (ny*nx, 2)\n",
    "            \n",
    "            # if more than n_points, subselect\n",
    "            if points.shape[0] > self.n_points:\n",
    "                sel_pos = torch.linspace(0, points.shape[0]-1, steps=self.n_points)\n",
    "                sel_idx = torch.round(sel_pos).long()\n",
    "                points = points[sel_idx]\n",
    "\n",
    "            ii = points[:, 0]\n",
    "            jj = points[:, 1]\n",
    "\n",
    "            if not self.deterministic_mask:\n",
    "                if self.jitter_std is not None and self.jitter_std > 0:\n",
    "                    # convert std (like 0.01 of image size) to pixels\n",
    "                    sigmaH = float(self.jitter_std) * self.H\n",
    "                    sigmaW = float(self.jitter_std) * self.W\n",
    "                    \n",
    "                    # Add Gaussian noise in pixel units\n",
    "                    ii = ii.to(torch.float32) + torch.randn_like(ii, dtype=torch.float32) * sigmaH\n",
    "                    jj = jj.to(torch.float32) + torch.randn_like(jj, dtype=torch.float32) * sigmaW\n",
    "\n",
    "                    # Round and clamp so they stay inside bounds\n",
    "                    ii = ii.round().clamp(self.radius, self.H - 1 - self.radius).to(torch.long)\n",
    "                    jj = jj.round().clamp(self.radius, self.W - 1 - self.radius).to(torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            yy, xx = torch.meshgrid(torch.arange(self.H), torch.arange(self.W), indexing=\"ij\")\n",
    "            for y0, x0 in zip(ii, jj):\n",
    "                disk = (yy - int(y0))**2 + (xx - int(x0))**2 <= (self.radius**2)\n",
    "                mask |= disk\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reveal_strategy: {self.reveal_strategy}\")\n",
    "        \n",
    "\n",
    "        obs = t_cur[chans].clone()\n",
    "        # Add noise (0 - 255 scale)\n",
    "        if self.noise is not None and self.noise > 0:\n",
    "            sigma = float(self.noise)\n",
    "            obs = obs + sigma * torch.randn_like(obs)\n",
    "            obs.clamp_(0.0, 255.0)\n",
    "\n",
    "\n",
    "        z[chans, :, :] = torch.where(mask, obs, torch.zeros_like(obs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- In Progress --- \n",
    "\n",
    "        if self.future_delta > 0:\n",
    "            step_f = step + self.future_delta   \n",
    "            t_label = torch.tensor(get_all(self.sims[index], step_f), dtype=torch.float32)\n",
    "        else:\n",
    "            t_label = t_cur.clone()\n",
    "\n",
    "\n",
    "\n",
    "        if self.return_mask:\n",
    "            return z,t_label, mask\n",
    "        else:  \n",
    "            return z,t_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sims.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e594a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ad765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b7eb2f5",
   "metadata": {},
   "source": [
    "Here you can add tests to run, each one takes a whole train test cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d05735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_for_sim_time(sim_id, t, meta, future_delta):\n",
    "    \"\"\"\n",
    "    Build a single (z, t_label) pair for a specific sim and time t\n",
    "    using the same config that was used during training.\n",
    "    \"\"\"\n",
    "    reveal_strategy    = str(meta[\"reveal_strategy\"])\n",
    "    n_points           = int(meta[\"n_points\"])\n",
    "    radius             = int(meta[\"radius\"])\n",
    "    noise              = float(meta[\"noise\"])\n",
    "    channels           = meta[\"channels\"]\n",
    "    reveal_dim         = meta[\"reveal_dim\"].tolist() if hasattr(meta[\"reveal_dim\"], \"tolist\") else meta[\"reveal_dim\"]\n",
    "    deterministic_mask = bool(meta[\"deterministic_mask_val\"])\n",
    "    jitter_std         = float(meta[\"jitter_std_val\"])\n",
    "    mixed              = bool(meta[\"mixed\"])\n",
    "\n",
    "    # make sure t is valid for this delta\n",
    "    SIM_STEPS = 201\n",
    "    max_start = SIM_STEPS - 1 - future_delta   # same logic as in MaskedDataset\n",
    "    t = min(int(t), max_start)\n",
    "\n",
    "    ds = MaskedDataset(\n",
    "        sims=np.array([sim_id]),\n",
    "        reveal_strategy=reveal_strategy,\n",
    "        n_points=n_points,\n",
    "        radius=radius,\n",
    "        noise=noise,\n",
    "        channels=channels,\n",
    "        points=None,                         # let it pick mask positions\n",
    "        steps=np.array([t]),                 # <- force time t\n",
    "        reveal_dim=reveal_dim,\n",
    "        deterministic_mask=deterministic_mask,\n",
    "        jitter_std=jitter_std,\n",
    "        mixed=mixed,\n",
    "        future_delta=future_delta,\n",
    "    )\n",
    "\n",
    "    z, t_label = ds[0]   # only one sample\n",
    "    return z, t_label, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1b0d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138]\n"
     ]
    }
   ],
   "source": [
    "vals = range(140)\n",
    "f_delta_values = list(vals[::2])\n",
    "print(f_delta_values)\n",
    "\n",
    "tests = [\n",
    "    {\n",
    "        \"name\": f\"full_d{d}_n16_clean\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": False,\n",
    "        \"noise\": 0, \n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.2, .8)],[(.2,.8)]],\n",
    "        \"future_delta\": d,\n",
    "    }\n",
    "    for d in f_delta_values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23a1a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68, 60, 58, 56, 54, 52, 50, 46, 44, 40, 32, 28, 22, 14, 8, 2, 0, 90]\n"
     ]
    }
   ],
   "source": [
    "vals = range(140)\n",
    "f_delta_values = [68, 60, 58, 56, 54, 52, 50, 46, 44, 40, 32, 28, 22, 14, 8, 2, 0, 90]\n",
    "print(f_delta_values)\n",
    "\n",
    "tests = [\n",
    "    {\n",
    "        \"name\": f\"full_d{d}_n16_clean\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": False,\n",
    "        \"noise\": 0, \n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.2, .8)],[(.2,.8)]],\n",
    "        \"future_delta\": d,\n",
    "    }\n",
    "    for d in f_delta_values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa32daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_model(model_name, base_path=\"\"):\n",
    "    \"\"\"\n",
    "    Adjust this to match how you actually load your models.\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(base_path, f\"{model_name}.pt\")\n",
    "    ckpt = torch.load(model_path, map_location=device)\n",
    "    model = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_meta(model_name, base_path=\"\"):\n",
    "    \"\"\"\n",
    "    Adjust this to match your meta file name / location.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    meta_path = os.path.join(base_path, f\"{model_name}_meta.json\")\n",
    "    with open(meta_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    return meta\n",
    "\n",
    "\n",
    "def build_val_data(meta):\n",
    "    \"\"\"\n",
    "    Adjust this to your actual validation dataset builder.\n",
    "\n",
    "    IMPORTANT: earlier you had an AttributeError (`tuple` has no attribute 'sims`),\n",
    "    so Iâ€™m explicitly unpacking here in case your function returns (dataset, sims).\n",
    "    \"\"\"\n",
    "    val_data = build_val_dataset_from_meta(meta)  # <-- your existing function\n",
    "    if isinstance(val_data, tuple) and len(val_data) == 2:\n",
    "        ds, sims = val_data\n",
    "    else:\n",
    "        ds = val_data\n",
    "        sims = val_data.sims\n",
    "    return ds, sims\n",
    "\n",
    "\n",
    "def get_input_and_target(ds, sim_id, t0, delta, channel=None):\n",
    "    \"\"\"\n",
    "    ðŸ”´ YOU MUST ADAPT THIS to your own dataset structure.\n",
    "\n",
    "    Goal:\n",
    "      - x: input tensor given to the model at time t0\n",
    "      - y: ground-truth future image at time t0 + delta (same shape as model output channel)\n",
    "\n",
    "    Example sketch (youâ€™ll replace this with real code):\n",
    "\n",
    "        x = ds.get_frame(sim_id, t0)        # shape [C, H, W]\n",
    "        y = ds.get_frame(sim_id, t0+delta)  # shape [C, H, W]\n",
    "        if channel is not None:\n",
    "            y = y[channel:channel+1]        # keep single channel\n",
    "\n",
    "    Both x and y should be torch.Tensors.\n",
    "    \"\"\"\n",
    "    # --- EXAMPLE / PSEUDOCODE: REPLACE with your own logic ---\n",
    "    x, y = ds.get_pair(sim_id, t0, t0 + delta)  # just a placeholder\n",
    "    if channel is not None:\n",
    "        y = y[channel:channel+1]\n",
    "    return x, y\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "\n",
    "def mse_over_time_for_model(\n",
    "    model_name,\n",
    "    base_path=\"\",\n",
    "    future_delta=None,\n",
    "    time_values=None,\n",
    "    channel=None,\n",
    "    max_sims=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute MSE(predicted_image, ground_truth_image) vs starting time t0\n",
    "    for a fixed Î” model.\n",
    "    \"\"\"\n",
    "    if time_values is None:\n",
    "        time_values = list(range(60, 121, 5))\n",
    "\n",
    "    # Load meta & model\n",
    "    meta = load_meta(model_name, base_path)\n",
    "    delta = future_delta\n",
    "    if delta is None:\n",
    "        # assume meta has the future horizon stored as 'future_delta' or similar\n",
    "        for key in [\"future_delta\", \"delta\", \"Î”\"]:\n",
    "            if key in meta:\n",
    "                delta = int(meta[key])\n",
    "                break\n",
    "        if delta is None:\n",
    "            raise ValueError(\"future_delta not provided and not found in meta\")\n",
    "\n",
    "    ds, sims = build_val_data(meta)\n",
    "    if max_sims is not None:\n",
    "        sims = sims[:max_sims]\n",
    "\n",
    "    model = load_model(model_name, base_path)\n",
    "\n",
    "    t_list = []\n",
    "    mse_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t0 in time_values:\n",
    "            mse_per_sim = []\n",
    "\n",
    "            for sim_id in sims:\n",
    "                # Get input & target for this sim and t0\n",
    "                x, y_true = get_input_and_target(ds, sim_id, t0, delta, channel=channel)\n",
    "\n",
    "                x = x.to(device)\n",
    "                y_true = y_true.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred = model(x.unsqueeze(0))  # add batch dim if needed: [1,C,H,W] or similar\n",
    "\n",
    "                # If model outputs all channels, pick one\n",
    "                if channel is not None:\n",
    "                    y_pred_use = y_pred[:, channel:channel+1]\n",
    "                else:\n",
    "                    y_pred_use = y_pred\n",
    "\n",
    "                # Make sure shapes match\n",
    "                if y_pred_use.shape != y_true.unsqueeze(0).shape:\n",
    "                    # you might need to slice or up/downsample depending on your setup\n",
    "                    # for now, assert:\n",
    "                    raise ValueError(\n",
    "                        f\"Shape mismatch: pred {y_pred_use.shape}, true {y_true.unsqueeze(0).shape}\"\n",
    "                    )\n",
    "\n",
    "                # Compute MSE per sim\n",
    "                mse = torch.mean((y_pred_use - y_true.unsqueeze(0)) ** 2).item()\n",
    "                mse_per_sim.append(mse)\n",
    "\n",
    "            mean_mse = float(np.mean(mse_per_sim))\n",
    "            t_list.append(t0)\n",
    "            mse_list.append(mean_mse)\n",
    "\n",
    "            print(f\"[{model_name}] t={t0}, Î”={delta} | MSE={mean_mse:.4e} over {len(mse_per_sim)} sims\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"delta\": delta,\n",
    "        \"t\": np.array(t_list),\n",
    "        \"mse\": np.array(mse_list),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d60d36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âž¡ MSE test for full_d68_n16_clean (Î”=68) over times [30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120]...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'full_d68_n16_clean_meta.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     27\u001b[39m         time_grid = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m30\u001b[39m, \u001b[32m121\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâž¡ MSE test for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Î”=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mÎ”\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) over times \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_grid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     res = \u001b[43mmse_over_time_for_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# set this appropriately\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfuture_delta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mÎ”\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# or None to read from meta\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# or whatever erosion channel is\u001b[39;49;00m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_sims\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or None to use all\u001b[39;49;00m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     results_mse.append(res)\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Finished MSE tests.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mmse_over_time_for_model\u001b[39m\u001b[34m(model_name, base_path, future_delta, time_values, channel, max_sims)\u001b[39m\n\u001b[32m     86\u001b[39m     time_values = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m60\u001b[39m, \u001b[32m121\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Load meta & model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m meta = \u001b[43mload_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m delta = future_delta\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m delta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# assume meta has the future horizon stored as 'future_delta' or similar\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mload_meta\u001b[39m\u001b[34m(model_name, base_path)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m     26\u001b[39m meta_path = os.path.join(base_path, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_meta.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmeta_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     28\u001b[39m     meta = json.load(f)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m meta\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'full_d68_n16_clean_meta.json'"
     ]
    }
   ],
   "source": [
    "results_mse = []\n",
    "path = \"\"\n",
    "\n",
    "\n",
    "\n",
    "for cfg in tests:\n",
    "    name = cfg[\"name\"]\n",
    "    Î”    = cfg[\"future_delta\"]\n",
    "\n",
    "    model_path = path + name + \".pt\"\n",
    "    meta_path = path + \"meta_\" + name + \".npz\"\n",
    "\n",
    "        # Check if both files exist\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ðŸš« Skipping {name} â€” model file not found ({model_path})\")\n",
    "        continue\n",
    "    if not os.path.exists(meta_path):\n",
    "        print(f\"ðŸš« Skipping {name} â€” meta file not found ({meta_path})\")\n",
    "        continue\n",
    "\n",
    "    # Choose how early you want to start based on Î”\n",
    "    if Î” <= 10:\n",
    "        time_grid = list(range(80, 121, 5))\n",
    "    elif Î” <= 40:\n",
    "        time_grid = list(range(60, 121, 5))\n",
    "    else:\n",
    "        time_grid = list(range(30, 121, 5))\n",
    "\n",
    "    print(f\"âž¡ MSE test for {name} (Î”={Î”}) over times {time_grid}...\")\n",
    "\n",
    "    res = mse_over_time_for_model(\n",
    "        name,\n",
    "        base_path=\"\",          # set this appropriately\n",
    "        future_delta=Î”,        # or None to read from meta\n",
    "        time_values=time_grid,\n",
    "        channel=0,             # or whatever erosion channel is\n",
    "        max_sims=250,          # or None to use all\n",
    "    )\n",
    "\n",
    "    results_mse.append(res)\n",
    "\n",
    "print(\"âœ… Finished MSE tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ee59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_vals = []\n",
    "global_mse = []\n",
    "\n",
    "for res in results_mse:\n",
    "    delta_vals.append(res[\"delta\"])\n",
    "    # average MSE across all evaluated times\n",
    "    global_mse.append(float(np.mean(res[\"mse\"])))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(delta_vals, global_mse, marker='o', linewidth=2)\n",
    "plt.xlabel(\"Î” (forecast horizon)\")\n",
    "plt.ylabel(\"Mean MSE over all tâ‚€\")\n",
    "plt.title(\"Global prediction error vs Î”\")\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
