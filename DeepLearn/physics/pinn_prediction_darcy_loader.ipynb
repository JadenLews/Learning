{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b325813",
   "metadata": {},
   "source": [
    "Same code from PINN we have been working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3bf807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Prevents crashes when showing graphs\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "SIM_STEPS = 201\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e5b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Determined train/test/val split\n",
    "train_sims = np.load(\"../train_sims.npy\")\n",
    "train_sims = train_sims[train_sims < 750]\n",
    "val_sims = np.load(\"../val_sims.npy\")\n",
    "val_sims = val_sims[val_sims < 750]\n",
    "test_sims = np.load(\"../test_sims.npy\")\n",
    "test_sims = test_sims[test_sims < 750]\n",
    "\n",
    "# Get porosity phi\n",
    "def get_phi(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Data200x200_withinfo/Image-{sim}-{step}_phi.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get pressure\n",
    "def get_pres(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Data200x200_withinfo/Image-{sim}-{step}_P.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get conductivity K\n",
    "def get_k(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Data200x200_withinfo/Image-{sim}-{step}_K.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get all 3 as a 3-channel matrix\n",
    "def get_all(sim,step):\n",
    "    return np.array((get_k(sim,step), get_pres(sim,step), get_phi(sim,step)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6210558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darcy loss function\n",
    "def darcy_loss(model, inp):\n",
    "    # Takes in the k,pres,phi and outputs the prediction across the image.\n",
    "    inp = inp.requires_grad_(True)\n",
    "    out = model(inp)\n",
    "    out = out.clone()\n",
    "    # out is in order K,P,phi, (conductivity, pressure, porosity)\n",
    "\n",
    "    # Impose high pressure along the entire upper line by setting the pressure channelt to 200.\n",
    "    out[:, 1:2, 0, :] = 200\n",
    "\n",
    "    # If we assume the output is in order k,pres,phi\n",
    "    # pres_grad is the gradient of the pressure along the y and x directions as a tuple\n",
    "    pres_grad = torch.gradient(out[:, 1:2], dim=(-2,-1))\n",
    "\n",
    "    # get velocity by multiplying the gradient by the conductivity\n",
    "    y_grad = pres_grad[0] * out[:, 0:1]\n",
    "    x_grad = pres_grad[1] * out[:, 0:1]\n",
    "\n",
    "    # compute the divergence by the second derivative of the gradients and adding them together\n",
    "    yy_grad = torch.gradient(y_grad, spacing=(1,),dim=(-2,))[0]\n",
    "    xx_grad = torch.gradient(x_grad, spacing=(1,),dim=(-1,))[0]\n",
    "    final = yy_grad + xx_grad\n",
    "\n",
    "    # total divergence should be 0\n",
    "    loss = (final**2).mean()\n",
    "\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Blocks of the Unet\n",
    "\n",
    "class TwoConv(nn.Module):\n",
    "    # Basic block with 2 convolutional layers, each with a batch norm and relu\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, no_end_relu=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if no_end_relu:\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.seq(inp)\n",
    "\n",
    "# A single conv layer that will increase the height and width of the matrix by 2 each.\n",
    "class SmallUp(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "\n",
    "# A single conv layer that will decrease the height and width of the matrix by 2 each.\n",
    "class SmallDown(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 0)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "    \n",
    "# Applies two convolutional layers, then pools\n",
    "class Downsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = TwoConv(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        return self.pool(self.conv(inp))\n",
    "\n",
    "# Upsamples and concatenates the upsampled matrix with the \"across\" then performs convolution on the result\n",
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, tweak=None):\n",
    "        super().__init__()\n",
    "        # Upsamples by 2x\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)\n",
    "        self.tweak = tweak\n",
    "        self.conv_after = TwoConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, below, across):\n",
    "        # First upsample by 2x\n",
    "        upsampled = self.up(below)\n",
    "        # If tweak is active, apply it first\n",
    "        if not self.tweak == None:\n",
    "            upsampled = self.tweak(upsampled)\n",
    "        # Concatenate with the same size on the downswing of the unet\n",
    "        concat = torch.concat((upsampled, across), dim=-3)\n",
    "        # Convolute them together\n",
    "        return self.conv_after(concat)\n",
    "    \n",
    "# Define the actual model used\n",
    "class SmallUnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input is Nx3x200x200\n",
    "        self.c1 = TwoConv(3, 8)\n",
    "        self.d1 = Downsample(8,16) # 16x100x100\n",
    "        self.d2 = Downsample(16,32) # 32x50x50\n",
    "        self.su = nn.Sequential(\n",
    "            SmallUp(32),\n",
    "            SmallUp(32),\n",
    "            SmallUp(32)\n",
    "        ) # 3x56x56\n",
    "        self.d3 = Downsample(32,64) # 64x28x28\n",
    "        self.d4 = Downsample(64,128) # 128x14x14\n",
    "        self.d5 = Downsample(128, 256) # 256x7x7\n",
    "\n",
    "        # Now back up\n",
    "        self.u1 = Upsample(256, 128) # 128x14x14\n",
    "        self.u2 = Upsample(128, 64) # 64x28x28\n",
    "        self.u3 = Upsample(64, 32, tweak=nn.Sequential(\n",
    "            SmallDown(32),\n",
    "            SmallDown(32),\n",
    "            SmallDown(32)\n",
    "        ))  # 32x50x50\n",
    "        self.u4 = Upsample(32,16) # 16x100x100\n",
    "        self.u5 = Upsample(16,8) # 8x200x200\n",
    "        self.final = TwoConv(8, 3, no_end_relu=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Start with convolution, expand 3 channels to 8.\n",
    "        # Then downsample 5 times, saving the result\n",
    "        top = self.c1(input)\n",
    "        x1 = self.d1(top)\n",
    "        x2 = self.d2(x1)\n",
    "        x3 = self.d3(self.su(x2)) # Here we upsample slightly so that we can downsample with less border artifacts\n",
    "        x4 = self.d4(x3)\n",
    "        x5 = self.d5(x4)\n",
    "        # Now that we're at 256x7x7, we upsample from here.\n",
    "        # At each layer with concatenate with the xi that is the same size as the up after upsampling.\n",
    "        up = self.u1(x5, x4)\n",
    "        up = self.u2(up, x3)\n",
    "        up = self.u3(up, x2) # Again, a small downsample here to get back on the proper resolution\n",
    "        up = self.u4(up, x1)\n",
    "        up = self.u5(up, top)\n",
    "        # One last convolution on the result to return to 3 channels from 8, leaving us with the proper 3x200x200\n",
    "        return self.final(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e969716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 sims,\n",
    "                 unmask_size=20,\n",
    "                 points = None,\n",
    "                 block_size = 50,\n",
    "                 reveal_strategy = \"block\",\n",
    "                 n_points = 200,\n",
    "                 radius = 2,\n",
    "                 steps = None,\n",
    "                 H=200,\n",
    "                 W=200,\n",
    "                 channels=\"all\",\n",
    "                 mixed=False,\n",
    "                 types=None,\n",
    "                 noise=5,\n",
    "                 return_mask=False,                 # allows visualiztion of mask\n",
    "                 reveal_dim=[[(0, 1)], [(0, 1)]],   # x,y range for disks to exist\n",
    "                 jitter_std=0.0,                    # % each disk drifts from deterministic position\n",
    "                 deterministic_mask=True,            # if True, mask is deterministic and noise is 0\n",
    "                 future_delta=0\n",
    "                 ):\n",
    "        \n",
    "        self.sims = sims\n",
    "        self.points = points\n",
    "        self.steps = steps\n",
    "        self.size = unmask_size\n",
    "        self.reveal_strategy = reveal_strategy\n",
    "        self.block_size = block_size\n",
    "        self.n_points = n_points\n",
    "        self.radius = radius\n",
    "        self.H, self.W = H, W\n",
    "        self.channels = channels\n",
    "        self.mixed = mixed\n",
    "        self.types = types\n",
    "        self.noise = noise\n",
    "        self.return_mask = return_mask\n",
    "        self.reveal_dim = reveal_dim\n",
    "        self.jitter_std = jitter_std\n",
    "        self.deterministic_mask = deterministic_mask\n",
    "        self.future_delta = future_delta\n",
    "\n",
    "    def _chan_idx(self):\n",
    "        if self.channels == \"all\":\n",
    "            return [0,1,2]\n",
    "        elif self.channels == \"K\":\n",
    "            return [0]\n",
    "        elif self.channels == \"P\":\n",
    "            return [1]\n",
    "        elif self.channels == \"phi\":\n",
    "            return [2]\n",
    "        else:\n",
    "            raise ValueError(\"channels must be 'all', 'K', 'P', or 'phi'\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # --- In Progress --- \n",
    "\n",
    "            # pick a valid step\n",
    "        if not isinstance(self.steps, np.ndarray):\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta  # ensures step + delta ≤ 199\n",
    "            step = np.random.randint(1, max_start + 1)  \n",
    "        else:\n",
    "            step = int(self.steps[index])\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta\n",
    "            if step > max_start:\n",
    "                step = max_start\n",
    "\n",
    "\n",
    "\n",
    "        # if not type(self.steps) == np.ndarray:\n",
    "        #     step = np.random.randint(1,200)\n",
    "        # else:\n",
    "        #     step = self.steps[index]\n",
    "\n",
    "\n",
    "\n",
    "        # Create tensor for the target\n",
    "        t_cur = torch.tensor(get_all(self.sims[index], step), dtype=torch.float32)\n",
    "\n",
    "        # Create 0 matrix\n",
    "        z = torch.zeros_like(t_cur)\n",
    "\n",
    "        # build a boolean mask of revealed pixels, shape (H,W)\n",
    "        mask = torch.zeros((self.H, self.W), dtype=torch.bool)\n",
    "\n",
    "        chans = self._chan_idx()\n",
    "\n",
    "        if self.reveal_strategy == \"block\":\n",
    "            # choose top-left for the block\n",
    "            if not type(self.points) == np.ndarray:\n",
    "                i0 = np.random.randint(0, self.H - self.block_size + 1)\n",
    "                j0 = np.random.randint(0, self.W - self.block_size + 1)\n",
    "            else:\n",
    "                i0, j0 = self.points[index]\n",
    "                i0 = max(0, min(i0, self.H - self.block_size))\n",
    "                j0 = max(0, min(j0, self.W - self.block_size))\n",
    "            mask[i0:i0+self.block_size, j0:j0+self.block_size] = True\n",
    "\n",
    "        elif self.reveal_strategy == \"disks\":\n",
    "\n",
    "            # used for reveal_dim\n",
    "            # map fraction [0,1] to pixel indices [0, N-1] in mask layer\n",
    "            def _segments_to_indices(segments, N, pad=0):\n",
    "                idxs = []\n",
    "                for a, b in segments:\n",
    "                    i0 = max(pad, int(round(a * (N - 1))))\n",
    "                    i1 = min((N - 1) - pad, int(round(b * (N - 1))))\n",
    "                    if i1 >= i0:\n",
    "                        idxs.append(torch.arange(i0, i1 + 1, dtype=torch.long))\n",
    "                if not idxs:\n",
    "                    # fallback to full range\n",
    "                    return torch.arange(pad, N - pad, dtype=torch.long)\n",
    "                return torch.unique(torch.cat(idxs)).to(torch.long)\n",
    "\n",
    "            row_fracs = self.reveal_dim[0] # e.g, [(0, 1)]\n",
    "            col_fracs = self.reveal_dim[1] # e.g, [(0, 1)]\n",
    "            row_allowed = _segments_to_indices(row_fracs, self.H, pad=self.radius)\n",
    "            col_allowed = _segments_to_indices(col_fracs, self.W, pad=self.radius)\n",
    "\n",
    "            # choose grid shape close to aspect ratio \n",
    "            # works with non-squares\n",
    "            Hspan = (row_allowed[-1] - row_allowed[0] + 1) if len(row_allowed) > 0 else self.H\n",
    "            Wspan = (col_allowed[-1] - col_allowed[0] + 1) if len(col_allowed) > 0 else self.W\n",
    "            ratio = float(Wspan) / max(1.0, float(Hspan))\n",
    "            ny = int(max(1, round(np.sqrt(self.n_points / max(1e-8, ratio)))))\n",
    "            nx = int(max(1, round(self.n_points / ny)))\n",
    "            while nx * ny < self.n_points:\n",
    "                nx += 1\n",
    "\n",
    "            # pick evenly spaced indices from rows/cols allowed\n",
    "            def pick_lin_indices(allowed, k):\n",
    "                if k <= 1:\n",
    "                    return allowed[len(allowed)//2]\n",
    "                pos = torch.linspace(0, len(allowed)-1, steps=k)\n",
    "                idx = torch.round(pos).long()\n",
    "                return allowed[idx]\n",
    "            \n",
    "            \n",
    "            row_picks = pick_lin_indices(row_allowed, ny)\n",
    "            col_picks = pick_lin_indices(col_allowed, nx)\n",
    "            yy, xx = torch.meshgrid(row_picks, col_picks, indexing=\"ij\")\n",
    "            points = torch.stack([yy.reshape(-1), xx.reshape(-1)], dim=1) # (ny*nx, 2)\n",
    "            \n",
    "            # if more than n_points, subselect\n",
    "            if points.shape[0] > self.n_points:\n",
    "                sel_pos = torch.linspace(0, points.shape[0]-1, steps=self.n_points)\n",
    "                sel_idx = torch.round(sel_pos).long()\n",
    "                points = points[sel_idx]\n",
    "\n",
    "            ii = points[:, 0]\n",
    "            jj = points[:, 1]\n",
    "\n",
    "            if not self.deterministic_mask:\n",
    "                if self.jitter_std is not None and self.jitter_std > 0:\n",
    "                    # convert std (like 0.01 of image size) to pixels\n",
    "                    sigmaH = float(self.jitter_std) * self.H\n",
    "                    sigmaW = float(self.jitter_std) * self.W\n",
    "                    \n",
    "                    # Add Gaussian noise in pixel units\n",
    "                    ii = ii.to(torch.float32) + torch.randn_like(ii, dtype=torch.float32) * sigmaH\n",
    "                    jj = jj.to(torch.float32) + torch.randn_like(jj, dtype=torch.float32) * sigmaW\n",
    "\n",
    "                    # Round and clamp so they stay inside bounds\n",
    "                    ii = ii.round().clamp(self.radius, self.H - 1 - self.radius).to(torch.long)\n",
    "                    jj = jj.round().clamp(self.radius, self.W - 1 - self.radius).to(torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            yy, xx = torch.meshgrid(torch.arange(self.H), torch.arange(self.W), indexing=\"ij\")\n",
    "            for y0, x0 in zip(ii, jj):\n",
    "                disk = (yy - int(y0))**2 + (xx - int(x0))**2 <= (self.radius**2)\n",
    "                mask |= disk\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reveal_strategy: {self.reveal_strategy}\")\n",
    "        \n",
    "\n",
    "        obs = t_cur[chans].clone()\n",
    "        # Add noise (0 - 255 scale)\n",
    "        if self.noise is not None and self.noise > 0:\n",
    "            sigma = float(self.noise)\n",
    "            obs = obs + sigma * torch.randn_like(obs)\n",
    "            obs.clamp_(0.0, 255.0)\n",
    "\n",
    "\n",
    "        z[chans, :, :] = torch.where(mask, obs, torch.zeros_like(obs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- In Progress --- \n",
    "\n",
    "        if self.future_delta > 0:\n",
    "            step_f = step + self.future_delta   \n",
    "            t_label = torch.tensor(get_all(self.sims[index], step_f), dtype=torch.float32)\n",
    "        else:\n",
    "            t_label = t_cur.clone()\n",
    "\n",
    "\n",
    "\n",
    "        if self.return_mask:\n",
    "            return z,t_label, mask\n",
    "        else:  \n",
    "            return z,t_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sims.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4966ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_meta(name, **kwargs):\n",
    "    \"\"\"\n",
    "    Saves meta info so you can reconstruct the exact val dataset later.\n",
    "    Usage:\n",
    "        save_meta(\n",
    "            name,\n",
    "            reveal_strategy=reveal_strategy, n_points=n_points, radius=radius,\n",
    "            noise=noise, channels=channels, val_steps=val_steps, val_points=val_points,\n",
    "            reveal_dim=reveal_dim, deterministic_mask_train=deterministic_mask,\n",
    "            jitter_std_train=jitter_std, deterministic_mask_val=True, jitter_std_val=0.0,\n",
    "            mixed=mixed, future_delta=future_delta\n",
    "        )\n",
    "    \"\"\"\n",
    "    # sanitize and cast\n",
    "    arr = {}\n",
    "    for k, v in kwargs.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if k in {\"reveal_dim\"}:\n",
    "            arr[k] = np.array(v, dtype=object)         # keep nested structure\n",
    "        elif isinstance(v, (list, tuple)) and k not in {\"val_steps\", \"val_points\"}:\n",
    "            arr[k] = np.array(v)\n",
    "        else:\n",
    "            arr[k] = v\n",
    "\n",
    "    np.savez(f\"meta_{name}.npz\", **arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ed2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model,\n",
    "    optim,\n",
    "    schedule=None,\n",
    "    crit=nn.MSELoss(),\n",
    "    epochs=250,\n",
    "    name=\"run\",\n",
    "    save_model=True,\n",
    "    save_curves=True,\n",
    "    use_darcy=True,          # <-- add\n",
    "    lambda_darcy=1.0,        # <-- add (optional weight)\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains model with Darcy loss + supervised loss.\n",
    "    Returns a dict of learning curves; optionally saves model and curves.\n",
    "\n",
    "    Curves:\n",
    "      - train_total, train_darcy\n",
    "      - val_total,   val_darcy\n",
    "    \"\"\"\n",
    "    # Histories\n",
    "    train_total_hist, train_darcy_hist = [], []\n",
    "    val_total_hist,   val_darcy_hist   = [], []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=f\"Training {name}\"):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        tot_loss_sum, darcy_loss_sum, n_train = 0.0, 0.0, 0\n",
    "\n",
    "        for feat, label in train_loader:\n",
    "            feat  = feat.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            if use_darcy:\n",
    "                p_loss, out = darcy_loss(model, feat)\n",
    "                s_loss = crit(out, label)\n",
    "                loss = s_loss + lambda_darcy * p_loss\n",
    "            else:\n",
    "                out = model(feat)\n",
    "                s_loss = crit(out, label)\n",
    "                loss = s_loss\n",
    "                p_loss = torch.tensor(0.0, device=device)  # for logging\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            # accumulate\n",
    "            bs = feat.size(0)\n",
    "            n_train         += bs\n",
    "            tot_loss_sum    += loss.item()  * bs\n",
    "            darcy_loss_sum  += p_loss.item() * bs\n",
    "\n",
    "        train_total = tot_loss_sum   / max(1, n_train)\n",
    "        train_darcy = darcy_loss_sum / max(1, n_train)\n",
    "        train_total_hist.append(train_total)\n",
    "        train_darcy_hist.append(train_darcy)\n",
    "\n",
    "        if schedule is not None:\n",
    "            schedule.step()\n",
    "\n",
    "        # ---- VALIDATE ----\n",
    "        model.eval()\n",
    "        tot_loss_sum, darcy_loss_sum, n_val = 0.0, 0.0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for feat, label in val_loader:\n",
    "                feat  = feat.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                if use_darcy:\n",
    "                    p_loss, out = darcy_loss(model, feat)\n",
    "                    s_loss = crit(out, label)\n",
    "                    loss = s_loss + lambda_darcy * p_loss\n",
    "                else:\n",
    "                    out = model(feat)\n",
    "                    s_loss = crit(out, label)\n",
    "                    loss = s_loss\n",
    "                    p_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "                bs = feat.size(0)\n",
    "                n_val         += bs\n",
    "                tot_loss_sum  += loss.item()  * bs\n",
    "                darcy_loss_sum+= p_loss.item() * bs\n",
    "\n",
    "        val_total = tot_loss_sum   / max(1, n_val)\n",
    "        val_darcy = darcy_loss_sum / max(1, n_val)\n",
    "        val_total_hist.append(val_total)\n",
    "        val_darcy_hist.append(val_darcy)\n",
    "\n",
    "    # ---- SAVE ARTIFACTS ----\n",
    "    if save_model:\n",
    "        torch.save(model, f\"{name}.pt\")\n",
    "\n",
    "    if save_curves:\n",
    "        np.savez(\n",
    "            f\"curves_{name}.npz\",\n",
    "            train_total=np.array(train_total_hist, dtype=np.float32),\n",
    "            train_darcy=np.array(train_darcy_hist, dtype=np.float32),\n",
    "            val_total=np.array(val_total_hist, dtype=np.float32),\n",
    "            val_darcy=np.array(val_darcy_hist, dtype=np.float32),\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"train_total\": train_total_hist,\n",
    "        \"train_darcy\": train_darcy_hist,\n",
    "        \"val_total\":   val_total_hist,\n",
    "        \"val_darcy\":   val_darcy_hist,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a124114",
   "metadata": {},
   "source": [
    "NEW:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7eb2f5",
   "metadata": {},
   "source": [
    "Here you can add tests to run, each one takes a whole train test cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5a4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138]\n"
     ]
    }
   ],
   "source": [
    "vals = range(140)\n",
    "f_delta_values = list(vals[::6])\n",
    "print(f_delta_values)\n",
    "\n",
    "tests = [\n",
    "    {\n",
    "        \"name\": f\"full_d{d}_n16\",   # base name only\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": False,\n",
    "        \"noise\": 0, \n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.2, .8)],[(.2,.8)]],\n",
    "        \"future_delta\": d,\n",
    "    }\n",
    "    for d in f_delta_values\n",
    "]\n",
    "\n",
    "# noise_levels = [0, 2, 5, 10, 20]\n",
    "\n",
    "# n_vals = vals = range(50)\n",
    "# for d in [10, 40]:\n",
    "#     for sig in noise_levels:\n",
    "#         tests_noise.append({\n",
    "#             \"name\": f\"rdFull_d{d}_noise{sig}\",\n",
    "#             \"reveal_strategy\": \"disks\",\n",
    "#             \"n_points\": 16,\n",
    "#             \"radius\": 5,\n",
    "#             \"mixed\": True,\n",
    "#             \"noise\": sig,\n",
    "#             \"deterministic_mask\": False,\n",
    "#             \"jitter_std\": 0.02,\n",
    "#             \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "#             \"future_delta\": d,\n",
    "#         })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3e6b6",
   "metadata": {},
   "source": [
    "Trains each configuration listed in `{tests}` one at a time.  \n",
    "For every model trained, these files are saved:\n",
    "- **`curves_{name}.npz`** – training and validation loss curves  \n",
    "- **`disks_{name}.pt`** – trained model weights  \n",
    "- **`meta_{name}.npz`** – run metadata (setup, noise)\n",
    "\n",
    "These outputs are used for evaluation and comparison in **`plot.ipynb`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa1e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training full_d0_n16_clean: 100%|██████████| 250/250 [58:11<00:00, 13.97s/it] \n",
      "Training full_d2_n16_clean: 100%|██████████| 250/250 [39:51<00:00,  9.56s/it]\n",
      "Training full_d4_n16_clean: 100%|██████████| 250/250 [30:16<00:00,  7.26s/it]\n",
      "Training full_d6_n16_clean: 100%|██████████| 250/250 [29:29<00:00,  7.08s/it]\n",
      "Training full_d8_n16_clean: 100%|██████████| 250/250 [29:26<00:00,  7.07s/it]\n",
      "Training full_d10_n16_clean: 100%|██████████| 250/250 [29:25<00:00,  7.06s/it]\n",
      "Training full_d12_n16_clean: 100%|██████████| 250/250 [29:36<00:00,  7.10s/it]\n",
      "Training full_d14_n16_clean: 100%|██████████| 250/250 [29:33<00:00,  7.09s/it]\n",
      "Training full_d16_n16_clean: 100%|██████████| 250/250 [29:26<00:00,  7.07s/it]\n",
      "Training full_d18_n16_clean: 100%|██████████| 250/250 [29:25<00:00,  7.06s/it]\n",
      "Training full_d20_n16_clean: 100%|██████████| 250/250 [29:38<00:00,  7.11s/it]\n",
      "Training full_d22_n16_clean: 100%|██████████| 250/250 [29:26<00:00,  7.07s/it]\n",
      "Training full_d24_n16_clean: 100%|██████████| 250/250 [29:26<00:00,  7.07s/it]\n",
      "Training full_d26_n16_clean: 100%|██████████| 250/250 [29:22<00:00,  7.05s/it]\n",
      "Training full_d28_n16_clean: 100%|██████████| 250/250 [29:27<00:00,  7.07s/it]\n",
      "Training full_d30_n16_clean: 100%|██████████| 250/250 [29:27<00:00,  7.07s/it]\n",
      "Training full_d32_n16_clean: 100%|██████████| 250/250 [29:31<00:00,  7.09s/it]\n",
      "Training full_d34_n16_clean: 100%|██████████| 250/250 [29:15<00:00,  7.02s/it]\n",
      "Training full_d36_n16_clean: 100%|██████████| 250/250 [29:17<00:00,  7.03s/it]\n",
      "Training full_d38_n16_clean: 100%|██████████| 250/250 [29:20<00:00,  7.04s/it]\n",
      "Training full_d40_n16_clean: 100%|██████████| 250/250 [29:16<00:00,  7.02s/it]\n",
      "Training full_d42_n16_clean: 100%|██████████| 250/250 [29:16<00:00,  7.02s/it]\n",
      "Training full_d44_n16_clean: 100%|██████████| 250/250 [29:12<00:00,  7.01s/it]\n",
      "Training full_d46_n16_clean: 100%|██████████| 250/250 [34:51<00:00,  8.37s/it]\n",
      "Training full_d48_n16_clean: 100%|██████████| 250/250 [52:33<00:00, 12.62s/it] \n",
      "Training full_d50_n16_clean: 100%|██████████| 250/250 [31:48<00:00,  7.63s/it]\n",
      "Training full_d52_n16_clean: 100%|██████████| 250/250 [29:46<00:00,  7.15s/it]\n",
      "Training full_d54_n16_clean: 100%|██████████| 250/250 [29:21<00:00,  7.05s/it]\n",
      "Training full_d56_n16_clean: 100%|██████████| 250/250 [29:19<00:00,  7.04s/it]\n",
      "Training full_d58_n16_clean: 100%|██████████| 250/250 [29:23<00:00,  7.05s/it]\n",
      "Training full_d60_n16_clean: 100%|██████████| 250/250 [29:19<00:00,  7.04s/it]\n",
      "Training full_d62_n16_clean: 100%|██████████| 250/250 [29:17<00:00,  7.03s/it]\n",
      "Training full_d64_n16_clean: 100%|██████████| 250/250 [29:20<00:00,  7.04s/it]\n",
      "Training full_d66_n16_clean: 100%|██████████| 250/250 [29:19<00:00,  7.04s/it]\n",
      "Training full_d68_n16_clean: 100%|██████████| 250/250 [29:22<00:00,  7.05s/it]\n",
      "Training full_d70_n16_clean: 100%|██████████| 250/250 [29:21<00:00,  7.05s/it]\n",
      "Training full_d72_n16_clean: 100%|██████████| 250/250 [29:23<00:00,  7.05s/it]\n",
      "Training full_d74_n16_clean: 100%|██████████| 250/250 [29:23<00:00,  7.05s/it]\n",
      "Training full_d76_n16_clean: 100%|██████████| 250/250 [29:35<00:00,  7.10s/it]\n",
      "Training full_d78_n16_clean: 100%|██████████| 250/250 [29:27<00:00,  7.07s/it]\n",
      "Training full_d80_n16_clean: 100%|██████████| 250/250 [29:39<00:00,  7.12s/it]\n",
      "Training full_d82_n16_clean: 100%|██████████| 250/250 [29:24<00:00,  7.06s/it]\n",
      "Training full_d84_n16_clean: 100%|██████████| 250/250 [29:22<00:00,  7.05s/it]\n",
      "Training full_d86_n16_clean: 100%|██████████| 250/250 [29:23<00:00,  7.05s/it]\n",
      "Training full_d88_n16_clean: 100%|██████████| 250/250 [29:39<00:00,  7.12s/it]\n",
      "Training full_d90_n16_clean: 100%|██████████| 250/250 [29:35<00:00,  7.10s/it]\n",
      "Training full_d92_n16_clean: 100%|██████████| 250/250 [29:30<00:00,  7.08s/it]\n",
      "Training full_d94_n16_clean: 100%|██████████| 250/250 [1:05:01<00:00, 15.61s/it]\n",
      "Training full_d96_n16_clean: 100%|██████████| 250/250 [50:03<00:00, 12.01s/it] \n",
      "Training full_d98_n16_clean: 100%|██████████| 250/250 [31:02<00:00,  7.45s/it]\n",
      "Training full_d100_n16_clean: 100%|██████████| 250/250 [37:08<00:00,  8.91s/it]\n",
      "Training full_d102_n16_clean: 100%|██████████| 250/250 [50:51<00:00, 12.21s/it] \n",
      "Training full_d104_n16_clean: 100%|██████████| 250/250 [30:49<00:00,  7.40s/it]\n",
      "Training full_d106_n16_clean: 100%|██████████| 250/250 [29:26<00:00,  7.07s/it]\n",
      "Training full_d108_n16_clean: 100%|██████████| 250/250 [29:23<00:00,  7.05s/it]\n",
      "Training full_d110_n16_clean: 100%|██████████| 250/250 [29:29<00:00,  7.08s/it]\n",
      "Training full_d112_n16_clean: 100%|██████████| 250/250 [29:16<00:00,  7.03s/it]\n",
      "Training full_d114_n16_clean: 100%|██████████| 250/250 [29:18<00:00,  7.03s/it]\n",
      "Training full_d116_n16_clean: 100%|██████████| 250/250 [29:17<00:00,  7.03s/it]\n",
      "Training full_d118_n16_clean: 100%|██████████| 250/250 [29:15<00:00,  7.02s/it]\n",
      "Training full_d120_n16_clean:   2%|▏         | 4/250 [00:39<40:32,  9.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m crit = nn.MSELoss()\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# --- train ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m hist = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m results[name] = {\u001b[33m\"\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m\"\u001b[39m: hist, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model.state_dict()}\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# --- save meta so plotting notebook can reconstruct val_data ---\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_loader, val_loader, model, optim, schedule, crit, epochs, name, save_model, save_curves)\u001b[39m\n\u001b[32m     62\u001b[39m feat  = feat.to(device)\n\u001b[32m     63\u001b[39m label = label.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m p_loss, out = \u001b[43mdarcy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m s_loss      = crit(out, label)\n\u001b[32m     67\u001b[39m loss        = p_loss + s_loss\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mdarcy_loss\u001b[39m\u001b[34m(model, inp)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdarcy_loss\u001b[39m(model, inp):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Takes in the k,pres,phi and outputs the prediction across the image.\u001b[39;00m\n\u001b[32m      4\u001b[39m     inp = inp.requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# out is in order K,P,phi, (conductivity, pressure, porosity)\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Impose high pressure along the entire upper line by setting the pressure channelt to 200.\u001b[39;00m\n\u001b[32m      9\u001b[39m     out[:, \u001b[32m1\u001b[39m:\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, :] = \u001b[32m200\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 128\u001b[39m, in \u001b[36mSmallUnet.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Now that we're at 256x7x7, we upsample from here.\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# At each layer with concatenate with the xi that is the same size as the up after upsampling.\u001b[39;00m\n\u001b[32m    127\u001b[39m up = \u001b[38;5;28mself\u001b[39m.u1(x5, x4)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m up = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mu2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m up = \u001b[38;5;28mself\u001b[39m.u3(up, x2) \u001b[38;5;66;03m# Again, a small downsample here to get back on the proper resolution\u001b[39;00m\n\u001b[32m    130\u001b[39m up = \u001b[38;5;28mself\u001b[39m.u4(up, x1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mUpsample.forward\u001b[39m\u001b[34m(self, below, across)\u001b[39m\n\u001b[32m     81\u001b[39m concat = torch.concat((upsampled, across), dim=-\u001b[32m3\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Convolute them together\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_after\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mTwoConv.forward\u001b[39m\u001b[34m(self, inp)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaden\\anaconda3\\envs\\newww\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for config in tests:\n",
    "    name                        = config.get(\"name\")\n",
    "    reveal_strategy             = config.get(\"reveal_strategy\", \"disks\")\n",
    "    n_points                    = config.get(\"n_points\", 5)\n",
    "    radius                      = config.get(\"radius\", 4)\n",
    "    noise                       = config.get(\"noise\", 0)\n",
    "    deterministic_mask          = config.get(\"deterministic_mask\", False)   # allow jitter by default\n",
    "    jitter_std                  = float(config.get(\"jitter_std\", 0.02))     # 2% jitter\n",
    "    reveal_dim                  = config.get(\"reveal_dim\", [[(0,1)], [(0,1)]])\n",
    "    channels                    = config.get(\"channels\", \"all\")\n",
    "    mixed                       = bool(config.get(\"mixed\", True))\n",
    "    future_delta                = int(config.get(\"future_delta\", 0))\n",
    "\n",
    "\n",
    "    # Pre-define steps and points to maintain a consistent validation set\n",
    "    MAX_TIME = 201 - future_delta\n",
    "    val_steps = np.random.randint(1,MAX_TIME,(val_sims.shape[0],))\n",
    "    val_points = np.random.randint(0,149,(val_sims.shape[0],2))\n",
    "\n",
    "    # --- TRAIN dataset/loader ---\n",
    "    train_data = MaskedDataset(\n",
    "        train_sims,\n",
    "        reveal_strategy     =reveal_strategy,\n",
    "        n_points            =n_points,\n",
    "        radius              =radius,\n",
    "        mixed               =mixed,                      \n",
    "        noise               =noise,\n",
    "        channels            =channels,\n",
    "        reveal_dim          =reveal_dim,\n",
    "        deterministic_mask  =deterministic_mask,\n",
    "        jitter_std          =jitter_std,\n",
    "        future_delta        =future_delta\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "\n",
    "    # --- VAL dataset/loader (deterministic) ---\n",
    "    val_data = MaskedDataset(\n",
    "        val_sims,\n",
    "        reveal_strategy     =reveal_strategy,\n",
    "        n_points            =n_points,\n",
    "        radius              =radius,\n",
    "        mixed               =mixed,\n",
    "        noise               =noise,\n",
    "        channels            =channels,\n",
    "        points              =val_points,\n",
    "        steps               =val_steps,\n",
    "        reveal_dim          =reveal_dim,\n",
    "        deterministic_mask  =True,            \n",
    "        jitter_std          =0.0,                       \n",
    "        future_delta        =future_delta\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)\n",
    "\n",
    "    # Train both variants with identical val_steps/val_points\n",
    "    variants = [\n",
    "        (\"With_D\", True),      # with Darcy\n",
    "        (\"NO_D\", False),   # without Darcy\n",
    "    ]\n",
    "\n",
    "    for suffix, use_darcy in variants:\n",
    "        run_name = f\"{name}_{suffix}\"   # e.g. full_d24_n16_clean, full_d24_n16_noDarcy\n",
    "\n",
    "        model = SmallUnet().to(device)\n",
    "        optim = torch.optim.Adam(model.parameters())\n",
    "        schedule = torch.optim.lr_scheduler.ExponentialLR(optim, 0.99)\n",
    "        crit = nn.MSELoss()\n",
    "\n",
    "        hist = train(\n",
    "            train_loader, val_loader, model, optim,\n",
    "            schedule=schedule, crit=crit, epochs=250,\n",
    "            name=run_name,\n",
    "            use_darcy=use_darcy,\n",
    "            lambda_darcy=1.0,\n",
    "        )\n",
    "\n",
    "        results[run_name] = {\"hist\": hist, \"model\": model.state_dict()}\n",
    "\n",
    "        save_meta(\n",
    "            run_name,  # IMPORTANT: save meta under the run_name you’ll eval later\n",
    "            reveal_strategy=reveal_strategy,\n",
    "            n_points=n_points,\n",
    "            radius=radius,\n",
    "            noise=noise,\n",
    "            channels=channels,\n",
    "            val_steps=val_steps,\n",
    "            val_points=val_points,\n",
    "            reveal_dim=reveal_dim,\n",
    "            deterministic_mask_train=deterministic_mask,\n",
    "            jitter_std_train=jitter_std,\n",
    "            deterministic_mask_val=True,\n",
    "            jitter_std_val=0.0,\n",
    "            mixed=mixed,\n",
    "            future_delta=future_delta,\n",
    "            use_darcy=use_darcy,          # optional, but nice to store\n",
    "            lambda_darcy=1.0,             # optional\n",
    "        )\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd80f0d",
   "metadata": {},
   "source": [
    "Mask Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d77bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the dataset\n",
    "val_data = MaskedDataset(\n",
    "    val_sims,\n",
    "    reveal_strategy=\"disks\",\n",
    "    n_points=12,\n",
    "    radius=5,\n",
    "    noise=0,\n",
    "    reveal_dim=[[(0.2, .8)],[(.2,.8)]],\n",
    "    return_mask=True,\n",
    "    jitter_std=0.01,\n",
    "    deterministic_mask=False\n",
    ")\n",
    "\n",
    "z, t, mask = val_data[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mask.numpy(), cmap=\"gray\")\n",
    "plt.title(\"Revealed-pixels mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
