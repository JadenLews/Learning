{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b325813",
   "metadata": {},
   "source": [
    "Requirements to run:\n",
    "\n",
    "torch, matplotlib, opencv-python, tqdm, numpy\n",
    "\n",
    "train_sims.npy, val_sims.npy, test_sims.npy (You may need to change the paths)\n",
    "\n",
    "Data in 200x200 format with conductivity, pressure, and porosity. (Again, you may need to change path)\n",
    "\n",
    "At the bottom in the evaluation section, there are some pre-named models. You should replace these with the names of your saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Prevents crashes when showing graphs\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Determined train/test/val split\n",
    "train_sims = np.load(\"../train_sims.npy\")\n",
    "train_sims = train_sims[train_sims < 750]\n",
    "val_sims = np.load(\"../val_sims.npy\")\n",
    "val_sims = val_sims[val_sims < 750]\n",
    "test_sims = np.load(\"../test_sims.npy\")\n",
    "test_sims = test_sims[test_sims < 750]\n",
    "\n",
    "# Get porosity phi\n",
    "def get_phi(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Data200x200_withinfo/Image-{sim}-{step}_phi.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get pressure\n",
    "def get_pres(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Data200x200_withinfo/Image-{sim}-{step}_P.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get conductivity K\n",
    "def get_k(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Data200x200_withinfo/Image-{sim}-{step}_K.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get all 3 as a 3-channel matrix\n",
    "def get_all(sim,step):\n",
    "    return np.array((get_k(sim,step), get_pres(sim,step), get_phi(sim,step)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-define steps and points to maintain a consistent validation set\n",
    "val_steps = np.random.randint(1,199,(val_sims.shape[0],))\n",
    "val_points = np.random.randint(0,149,(val_sims.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6210558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darcy loss function\n",
    "def darcy_loss(model, inp):\n",
    "    # Takes in the k,pres,phi and outputs the prediction across the image.\n",
    "    inp = inp.requires_grad_(True)\n",
    "    out = model(inp)\n",
    "    # out is in order K,P,phi, (conductivity, pressure, porosity)\n",
    "\n",
    "    # Impose high pressure along the entire upper line by setting the pressure channelt to 200.\n",
    "    out[:, 1:2, 0, :] = 200\n",
    "\n",
    "    # If we assume the output is in order k,pres,phi\n",
    "    # pres_grad is the gradient of the pressure along the y and x directions as a tuple\n",
    "    pres_grad = torch.gradient(out[:, 1:2], dim=(-2,-1))\n",
    "\n",
    "    # get velocity by multiplying the gradient by the conductivity\n",
    "    y_grad = pres_grad[0] * out[:, 0:1]\n",
    "    x_grad = pres_grad[1] * out[:, 0:1]\n",
    "\n",
    "    # compute the divergence by the second derivative of the gradients and adding them together\n",
    "    yy_grad = torch.gradient(y_grad, spacing=(1,),dim=(-2,))[0]\n",
    "    xx_grad = torch.gradient(x_grad, spacing=(1,),dim=(-1,))[0]\n",
    "    final = yy_grad + xx_grad\n",
    "\n",
    "    # total divergence should be 0\n",
    "    loss = (final**2).mean()\n",
    "\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Blocks of the Unet\n",
    "\n",
    "class TwoConv(nn.Module):\n",
    "    # Basic block with 2 convolutional layers, each with a batch norm and relu\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, no_end_relu=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if no_end_relu:\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.seq(inp)\n",
    "\n",
    "# A single conv layer that will increase the height and width of the matrix by 2 each.\n",
    "class SmallUp(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "\n",
    "# A single conv layer that will decrease the height and width of the matrix by 2 each.\n",
    "class SmallDown(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 0)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "    \n",
    "# Applies two convolutional layers, then pools\n",
    "class Downsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = TwoConv(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        return self.pool(self.conv(inp))\n",
    "\n",
    "# Upsamples and concatenates the upsampled matrix with the \"across\" then performs convolution on the result\n",
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, tweak=None):\n",
    "        super().__init__()\n",
    "        # Upsamples by 2x\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)\n",
    "        self.tweak = tweak\n",
    "        self.conv_after = TwoConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, below, across):\n",
    "        # First upsample by 2x\n",
    "        upsampled = self.up(below)\n",
    "        # If tweak is active, apply it first\n",
    "        if not self.tweak == None:\n",
    "            upsampled = self.tweak(upsampled)\n",
    "        # Concatenate with the same size on the downswing of the unet\n",
    "        concat = torch.concat((upsampled, across), dim=-3)\n",
    "        # Convolute them together\n",
    "        return self.conv_after(concat)\n",
    "    \n",
    "# Define the actual model used\n",
    "class SmallUnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input is Nx3x200x200\n",
    "        self.c1 = TwoConv(3, 8)\n",
    "        self.d1 = Downsample(8,16) # 16x100x100\n",
    "        self.d2 = Downsample(16,32) # 32x50x50\n",
    "        self.su = nn.Sequential(\n",
    "            SmallUp(32),\n",
    "            SmallUp(32),\n",
    "            SmallUp(32)\n",
    "        ) # 3x56x56\n",
    "        self.d3 = Downsample(32,64) # 64x28x28\n",
    "        self.d4 = Downsample(64,128) # 128x14x14\n",
    "        self.d5 = Downsample(128, 256) # 256x7x7\n",
    "\n",
    "        # Now back up\n",
    "        self.u1 = Upsample(256, 128) # 128x14x14\n",
    "        self.u2 = Upsample(128, 64) # 64x28x28\n",
    "        self.u3 = Upsample(64, 32, tweak=nn.Sequential(\n",
    "            SmallDown(32),\n",
    "            SmallDown(32),\n",
    "            SmallDown(32)\n",
    "        ))  # 32x50x50\n",
    "        self.u4 = Upsample(32,16) # 16x100x100\n",
    "        self.u5 = Upsample(16,8) # 8x200x200\n",
    "        self.final = TwoConv(8, 3, no_end_relu=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Start with convolution, expand 3 channels to 8.\n",
    "        # Then downsample 5 times, saving the result\n",
    "        top = self.c1(input)\n",
    "        x1 = self.d1(top)\n",
    "        x2 = self.d2(x1)\n",
    "        x3 = self.d3(self.su(x2)) # Here we upsample slightly so that we can downsample with less border artifacts\n",
    "        x4 = self.d4(x3)\n",
    "        x5 = self.d5(x4)\n",
    "        # Now that we're at 256x7x7, we upsample from here.\n",
    "        # At each layer with concatenate with the xi that is the same size as the up after upsampling.\n",
    "        up = self.u1(x5, x4)\n",
    "        up = self.u2(up, x3)\n",
    "        up = self.u3(up, x2) # Again, a small downsample here to get back on the proper resolution\n",
    "        up = self.u4(up, x1)\n",
    "        up = self.u5(up, top)\n",
    "        # One last convolution on the result to return to 3 channels from 8, leaving us with the proper 3x200x200\n",
    "        return self.final(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e969716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset used\n",
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, sims, unmask_size=20, points = None, block_size = 50, reveal_strategy = \"block\", n_points = 200, radius = 2, steps = None, H=200, W=200, channels=\"all\"):\n",
    "        \n",
    "        self.sims = sims\n",
    "        self.points = points\n",
    "        self.steps = steps\n",
    "        self.size = unmask_size\n",
    "        self.reveal_strategy = reveal_strategy\n",
    "        self.block_size = block_size\n",
    "        self.n_points = n_points\n",
    "        self.radius = radius\n",
    "        self.H, self.W = H, W\n",
    "        self.channels = channels\n",
    "\n",
    "    def _chan_idx(self):\n",
    "        if self.channels == \"all\":\n",
    "            return [0,1,2]\n",
    "        elif self.channels == \"K\":\n",
    "            return [0]\n",
    "        elif self.channels == \"P\":\n",
    "            return [1]\n",
    "        elif self.channels == \"phi\":\n",
    "            return [2]\n",
    "        else:\n",
    "            raise ValueError(\"channels must be 'all', 'K', 'P', or 'phi'\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        if not type(self.steps) == np.ndarray:\n",
    "            step = np.random.randint(1,200)\n",
    "        else:\n",
    "            step = self.steps[index]\n",
    "\n",
    "        # Create tensor for the target\n",
    "        t = torch.tensor(get_all(self.sims[index], step))\n",
    "\n",
    "        # Create 0-matrix\n",
    "        z = torch.zeros_like(t)\n",
    "\n",
    "        # build a boolean mask of revealed pixels, shape (H,W)\n",
    "        mask = torch.zeros((self.H, self.W), dtype=torch.bool)\n",
    "\n",
    "        if self.reveal_strategy == \"block\":\n",
    "            # choose top-left for the block\n",
    "            if not type(self.points) == np.ndarray:\n",
    "                i0 = np.random.randint(0, self.H - self.block_size + 1)\n",
    "                j0 = np.random.randint(0, self.W - self.block_size + 1)\n",
    "            else:\n",
    "                i0, j0 = self.points[index]\n",
    "                i0 = max(0, min(i0, self.H - self.block_size))\n",
    "                j0 = max(0, min(j0, self.W - self.block_size))\n",
    "            mask[i0:i0+self.block_size, j0:j0+self.block_size] = True\n",
    "\n",
    "        elif self.reveal_strategy == \"disks\":\n",
    "            ii = torch.randint(0, self.H, (self.n_points,))\n",
    "            jj = torch.randint(0, self.W, (self.n_points,))\n",
    "            yy, xx = torch.meshgrid(torch.arange(self.H), torch.arange(self.W), indexing=\"ij\")\n",
    "            for y0, x0 in zip(ii, jj):\n",
    "                disk = (yy - int(y0))**2 + (xx - int(x0))**2 <= (self.radius**2)\n",
    "                mask |= disk\n",
    "            \n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reveal_strategy: {self.reveal_strategy}\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # write revealed pixels for selected channels\n",
    "        chans = self._chan_idx()\n",
    "        z[chans, :, :] = torch.where(mask, t[chans, :, :], torch.zeros_like(t[chans, :, :]))\n",
    "\n",
    "        return z,t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # If points and steps are specified, use those, otherwise randomize\n",
    "        if not type(self.points) == np.ndarray:\n",
    "            point = np.random.randint(0, 200-self.size, size=(2,))\n",
    "        else:\n",
    "            point = self.points[index]\n",
    "        if not type(self.steps) == np.ndarray:\n",
    "            step = np.random.randint(1,200)\n",
    "        else:\n",
    "            step = self.steps[index]\n",
    "\n",
    "        # Create tensor for the target\n",
    "        t = torch.tensor(get_all(self.sims[index], step))\n",
    "        # Create 0-matrix\n",
    "        z = torch.zeros_like(t)\n",
    "        # Set points that are known to their values\n",
    "        z[:,point[0]:point[0]+self.size,point[1]:point[1]+self.size] = t[:,point[0]:point[0]+self.size,point[1]:point[1]+self.size]\n",
    "        \n",
    "        return z,t\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sims.shape[0]\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(MaskedDataset(train_sims, unmask_size=50), batch_size=8, shuffle=True)\n",
    "# Val uses preset points and steps\n",
    "val_data = MaskedDataset(val_sims, unmask_size=50, points=val_points, steps=val_steps)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcae852",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallUnet().to(device)\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "schedule = torch.optim.lr_scheduler.ExponentialLR(optim, 0.99)\n",
    "crit = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d99a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter count\n",
    "sum([k.numel() for k in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a80a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick epoch dount\n",
    "epochs = 250\n",
    "# train loss values, losses is total darcy is only darcy\n",
    "losses = []\n",
    "darcy = []\n",
    "# similar for validation\n",
    "val_loss = []\n",
    "val_darcy = []\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    epoch_loss = 0\n",
    "    epoch_darcy = 0\n",
    "    for feat,label in train_loader:\n",
    "        optim.zero_grad()\n",
    "        feat = feat.to(device)\n",
    "        label = label.to(device)\n",
    "        # Process darcy loss and save it\n",
    "        p_loss, out = darcy_loss(model, feat)\n",
    "        epoch_darcy += p_loss.item()\n",
    "        # Calculate total loss\n",
    "        loss = p_loss + crit(out, label)\n",
    "        epoch_loss += loss.item()\n",
    "        # Perform backward step\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    # Track loss\n",
    "    epoch_loss /= train_loader.__len__()\n",
    "    epoch_darcy /= train_loader.__len__()\n",
    "    losses.append(epoch_loss)\n",
    "    darcy.append(epoch_darcy)\n",
    "\n",
    "    schedule.step()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_darcy = 0\n",
    "    with torch.no_grad():\n",
    "        for feat,label in val_loader:\n",
    "\n",
    "            feat = feat.to(device)\n",
    "            label = label.to(device)\n",
    "            p_loss, out = darcy_loss(model, feat)\n",
    "            epoch_darcy += p_loss.item()\n",
    "            loss = p_loss + crit(out, label)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= val_loader.__len__()\n",
    "    epoch_darcy /= val_loader.__len__()\n",
    "    val_loss.append(epoch_loss)\n",
    "    val_darcy.append(epoch_darcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff87861",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(val_darcy))\n",
    "plt.plot(np.array(darcy))\n",
    "plt.show()\n",
    "plt.plot(np.array(val_loss) - np.array(val_darcy))\n",
    "plt.plot(np.array(losses) - np.array(darcy))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"small_unet_darcy_50_nodarcy_disk.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362206b3",
   "metadata": {},
   "source": [
    "Now to actual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a37bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_model = torch.load(\"small_unet_darcy_50_both-b1.pt\", weights_only=False).to(device)\n",
    "darcy_model = torch.load(\"small_unet_darcy_50_nomse.pt\", weights_only=False).to(device)\n",
    "mse_model = torch.load(\"small_unet_darcy_50_nodarcy.pt\", weights_only=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a27723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "def show_evaluation(model, indices, data=val_data):\n",
    "\n",
    "    fig, axs = plt.subplots(len(indices), 6, dpi=600)\n",
    "\n",
    "    axs[0,0].set_title(\"Given K\", fontsize=8)\n",
    "    axs[0,1].set_title(\"Predicted K\",fontsize=8)\n",
    "    axs[0,2].set_title(\"Actual K\",fontsize=8)\n",
    "\n",
    "    axs[0,3].set_title(\"Given Pres\",fontsize=8)\n",
    "    axs[0,4].set_title(\"Predicted Pres\",fontsize=8)\n",
    "    axs[0,5].set_title(\"Actual Pres\",fontsize=8)\n",
    "\n",
    "    for i,e in enumerate(indices):\n",
    "        sample = val_data.__getitem__(e)\n",
    "        out = model(sample[0].to(device).unsqueeze(0))[0]\n",
    "\n",
    "        axs[i,0].imshow(vis(sample[0][0]), cmap='gray', vmin=0, vmax=255)\n",
    "        axs[i,1].imshow(vis(out[0]), cmap='gray', vmin=0, vmax=255)\n",
    "        axs[i,2].imshow(vis(sample[1][0]), cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "        axs[i,3].imshow(vis(sample[0][1]), cmap='gray', vmin=0, vmax=255)\n",
    "        axs[i,4].imshow(vis(out[1]), cmap='gray', vmin=0, vmax=255)\n",
    "        axs[i,5].imshow(vis(sample[1][1]), cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "    for axs in fig.get_axes():\n",
    "        axs.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8fdf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using only darcy loss\n",
    "show_evaluation(darcy_model, [9,6,12,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e475fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using only darcy loss\n",
    "show_evaluation(mse_model, [9,6,12,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation(model, [9,2,12,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "created = torch.load(\"small_unet_darcy_50_nodarcy_disk.pt\", weights_only=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation(created, [9,2,12,17])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
