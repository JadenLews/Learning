{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bf807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Prevents crashes when showing graphs\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "SIM_STEPS = 201\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Determined train/test/val split\n",
    "train_sims = np.load(\"../train_sims.npy\")\n",
    "train_sims = train_sims[train_sims < 750]\n",
    "val_sims = np.load(\"../val_sims.npy\")\n",
    "val_sims = val_sims[val_sims < 750]\n",
    "test_sims = np.load(\"../test_sims.npy\")\n",
    "test_sims = test_sims[test_sims < 750]\n",
    "\n",
    "# Get porosity phi\n",
    "def get_phi(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_phi.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get pressure\n",
    "def get_pres(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_P.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get conductivity K\n",
    "def get_k(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_K.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get all 3 as a 3-channel matrix\n",
    "def get_all(sim,step):\n",
    "    return np.array((get_k(sim,step), get_pres(sim,step), get_phi(sim,step)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6210558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darcy loss function\n",
    "def darcy_loss(model, inp):\n",
    "    # Takes in the k,pres,phi and outputs the prediction across the image.\n",
    "    inp = inp.requires_grad_(True)\n",
    "    out = model(inp)\n",
    "    # out is in order K,P,phi, (conductivity, pressure, porosity)\n",
    "\n",
    "    # Impose high pressure along the entire upper line by setting the pressure channelt to 200.\n",
    "    out[:, 1:2, 0, :] = 200\n",
    "\n",
    "    # If we assume the output is in order k,pres,phi\n",
    "    # pres_grad is the gradient of the pressure along the y and x directions as a tuple\n",
    "    pres_grad = torch.gradient(out[:, 1:2], dim=(-2,-1))\n",
    "\n",
    "    # get velocity by multiplying the gradient by the conductivity\n",
    "    y_grad = pres_grad[0] * out[:, 0:1]\n",
    "    x_grad = pres_grad[1] * out[:, 0:1]\n",
    "\n",
    "    # compute the divergence by the second derivative of the gradients and adding them together\n",
    "    yy_grad = torch.gradient(y_grad, spacing=(1,),dim=(-2,))[0]\n",
    "    xx_grad = torch.gradient(x_grad, spacing=(1,),dim=(-1,))[0]\n",
    "    final = yy_grad + xx_grad\n",
    "\n",
    "    # total divergence should be 0\n",
    "    loss = (final**2).mean()\n",
    "\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Blocks of the Unet\n",
    "\n",
    "class TwoConv(nn.Module):\n",
    "    # Basic block with 2 convolutional layers, each with a batch norm and relu\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, no_end_relu=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if no_end_relu:\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.seq(inp)\n",
    "\n",
    "# A single conv layer that will increase the height and width of the matrix by 2 each.\n",
    "class SmallUp(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "\n",
    "# A single conv layer that will decrease the height and width of the matrix by 2 each.\n",
    "class SmallDown(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 0)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "    \n",
    "# Applies two convolutional layers, then pools\n",
    "class Downsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = TwoConv(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        return self.pool(self.conv(inp))\n",
    "\n",
    "# Upsamples and concatenates the upsampled matrix with the \"across\" then performs convolution on the result\n",
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, tweak=None):\n",
    "        super().__init__()\n",
    "        # Upsamples by 2x\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)\n",
    "        self.tweak = tweak\n",
    "        self.conv_after = TwoConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, below, across):\n",
    "        # First upsample by 2x\n",
    "        upsampled = self.up(below)\n",
    "        # If tweak is active, apply it first\n",
    "        if not self.tweak == None:\n",
    "            upsampled = self.tweak(upsampled)\n",
    "        # Concatenate with the same size on the downswing of the unet\n",
    "        concat = torch.concat((upsampled, across), dim=-3)\n",
    "        # Convolute them together\n",
    "        return self.conv_after(concat)\n",
    "    \n",
    "# Define the actual model used\n",
    "class SmallUnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input is Nx3x200x200\n",
    "        self.c1 = TwoConv(3, 8)\n",
    "        self.d1 = Downsample(8,16) # 16x100x100\n",
    "        self.d2 = Downsample(16,32) # 32x50x50\n",
    "        self.su = nn.Sequential(\n",
    "            SmallUp(32),\n",
    "            SmallUp(32),\n",
    "            SmallUp(32)\n",
    "        ) # 3x56x56\n",
    "        self.d3 = Downsample(32,64) # 64x28x28\n",
    "        self.d4 = Downsample(64,128) # 128x14x14\n",
    "        self.d5 = Downsample(128, 256) # 256x7x7\n",
    "\n",
    "        # Now back up\n",
    "        self.u1 = Upsample(256, 128) # 128x14x14\n",
    "        self.u2 = Upsample(128, 64) # 64x28x28\n",
    "        self.u3 = Upsample(64, 32, tweak=nn.Sequential(\n",
    "            SmallDown(32),\n",
    "            SmallDown(32),\n",
    "            SmallDown(32)\n",
    "        ))  # 32x50x50\n",
    "        self.u4 = Upsample(32,16) # 16x100x100\n",
    "        self.u5 = Upsample(16,8) # 8x200x200\n",
    "        self.final = TwoConv(8, 3, no_end_relu=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Start with convolution, expand 3 channels to 8.\n",
    "        # Then downsample 5 times, saving the result\n",
    "        top = self.c1(input)\n",
    "        x1 = self.d1(top)\n",
    "        x2 = self.d2(x1)\n",
    "        x3 = self.d3(self.su(x2)) # Here we upsample slightly so that we can downsample with less border artifacts\n",
    "        x4 = self.d4(x3)\n",
    "        x5 = self.d5(x4)\n",
    "        # Now that we're at 256x7x7, we upsample from here.\n",
    "        # At each layer with concatenate with the xi that is the same size as the up after upsampling.\n",
    "        up = self.u1(x5, x4)\n",
    "        up = self.u2(up, x3)\n",
    "        up = self.u3(up, x2) # Again, a small downsample here to get back on the proper resolution\n",
    "        up = self.u4(up, x1)\n",
    "        up = self.u5(up, top)\n",
    "        # One last convolution on the result to return to 3 channels from 8, leaving us with the proper 3x200x200\n",
    "        return self.final(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e969716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 sims,\n",
    "                 unmask_size=20,\n",
    "                 points = None,\n",
    "                 block_size = 50,\n",
    "                 reveal_strategy = \"block\",\n",
    "                 n_points = 200,\n",
    "                 radius = 2,\n",
    "                 steps = None,\n",
    "                 H=200,\n",
    "                 W=200,\n",
    "                 channels=\"all\",\n",
    "                 mixed=False,\n",
    "                 types=None,\n",
    "                 noise=5,\n",
    "                 return_mask=False,                 # allows visualiztion of mask\n",
    "                 reveal_dim=[[(0, 1)], [(0, 1)]],   # x,y range for disks to exist\n",
    "                 jitter_std=0.0,                    # % each disk drifts from deterministic position\n",
    "                 deterministic_mask=True,            # if True, mask is deterministic and noise is 0\n",
    "                 future_delta=0\n",
    "                 ):\n",
    "        \n",
    "        self.sims = sims\n",
    "        self.points = points\n",
    "        self.steps = steps\n",
    "        self.size = unmask_size\n",
    "        self.reveal_strategy = reveal_strategy\n",
    "        self.block_size = block_size\n",
    "        self.n_points = n_points\n",
    "        self.radius = radius\n",
    "        self.H, self.W = H, W\n",
    "        self.channels = channels\n",
    "        self.mixed = mixed\n",
    "        self.types = types\n",
    "        self.noise = noise\n",
    "        self.return_mask = return_mask\n",
    "        self.reveal_dim = reveal_dim\n",
    "        self.jitter_std = jitter_std\n",
    "        self.deterministic_mask = deterministic_mask\n",
    "        self.future_delta = future_delta\n",
    "\n",
    "    def _chan_idx(self):\n",
    "        if self.channels == \"all\":\n",
    "            return [0,1,2]\n",
    "        elif self.channels == \"K\":\n",
    "            return [0]\n",
    "        elif self.channels == \"P\":\n",
    "            return [1]\n",
    "        elif self.channels == \"phi\":\n",
    "            return [2]\n",
    "        else:\n",
    "            raise ValueError(\"channels must be 'all', 'K', 'P', or 'phi'\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # --- In Progress --- \n",
    "\n",
    "            # pick a valid step\n",
    "        if not isinstance(self.steps, np.ndarray):\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta  # ensures step + delta ≤ 199\n",
    "            step = np.random.randint(1, max_start + 1)  \n",
    "        else:\n",
    "            step = int(self.steps[index])\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta\n",
    "            if step > max_start:\n",
    "                step = max_start\n",
    "\n",
    "\n",
    "\n",
    "        # if not type(self.steps) == np.ndarray:\n",
    "        #     step = np.random.randint(1,200)\n",
    "        # else:\n",
    "        #     step = self.steps[index]\n",
    "\n",
    "\n",
    "\n",
    "        # Create tensor for the target\n",
    "        t_cur = torch.tensor(get_all(self.sims[index], step), dtype=torch.float32)\n",
    "\n",
    "        # Create 0 matrix\n",
    "        z = torch.zeros_like(t_cur)\n",
    "\n",
    "        # build a boolean mask of revealed pixels, shape (H,W)\n",
    "        mask = torch.zeros((self.H, self.W), dtype=torch.bool)\n",
    "\n",
    "        chans = self._chan_idx()\n",
    "\n",
    "        if self.reveal_strategy == \"block\":\n",
    "            # choose top-left for the block\n",
    "            if not type(self.points) == np.ndarray:\n",
    "                i0 = np.random.randint(0, self.H - self.block_size + 1)\n",
    "                j0 = np.random.randint(0, self.W - self.block_size + 1)\n",
    "            else:\n",
    "                i0, j0 = self.points[index]\n",
    "                i0 = max(0, min(i0, self.H - self.block_size))\n",
    "                j0 = max(0, min(j0, self.W - self.block_size))\n",
    "            mask[i0:i0+self.block_size, j0:j0+self.block_size] = True\n",
    "\n",
    "        elif self.reveal_strategy == \"disks\":\n",
    "\n",
    "            # used for reveal_dim\n",
    "            # map fraction [0,1] to pixel indices [0, N-1] in mask layer\n",
    "            def _segments_to_indices(segments, N, pad=0):\n",
    "                idxs = []\n",
    "                for a, b in segments:\n",
    "                    i0 = max(pad, int(round(a * (N - 1))))\n",
    "                    i1 = min((N - 1) - pad, int(round(b * (N - 1))))\n",
    "                    if i1 >= i0:\n",
    "                        idxs.append(torch.arange(i0, i1 + 1, dtype=torch.long))\n",
    "                if not idxs:\n",
    "                    # fallback to full range\n",
    "                    return torch.arange(pad, N - pad, dtype=torch.long)\n",
    "                return torch.unique(torch.cat(idxs)).to(torch.long)\n",
    "\n",
    "            row_fracs = self.reveal_dim[0] # e.g, [(0, 1)]\n",
    "            col_fracs = self.reveal_dim[1] # e.g, [(0, 1)]\n",
    "            row_allowed = _segments_to_indices(row_fracs, self.H, pad=self.radius)\n",
    "            col_allowed = _segments_to_indices(col_fracs, self.W, pad=self.radius)\n",
    "\n",
    "            # choose grid shape close to aspect ratio \n",
    "            # works with non-squares\n",
    "            Hspan = (row_allowed[-1] - row_allowed[0] + 1) if len(row_allowed) > 0 else self.H\n",
    "            Wspan = (col_allowed[-1] - col_allowed[0] + 1) if len(col_allowed) > 0 else self.W\n",
    "            ratio = float(Wspan) / max(1.0, float(Hspan))\n",
    "            ny = int(max(1, round(np.sqrt(self.n_points / max(1e-8, ratio)))))\n",
    "            nx = int(max(1, round(self.n_points / ny)))\n",
    "            while nx * ny < self.n_points:\n",
    "                nx += 1\n",
    "\n",
    "            # pick evenly spaced indices from rows/cols allowed\n",
    "            def pick_lin_indices(allowed, k):\n",
    "                if k <= 1:\n",
    "                    return allowed[len(allowed)//2]\n",
    "                pos = torch.linspace(0, len(allowed)-1, steps=k)\n",
    "                idx = torch.round(pos).long()\n",
    "                return allowed[idx]\n",
    "            \n",
    "            \n",
    "            row_picks = pick_lin_indices(row_allowed, ny)\n",
    "            col_picks = pick_lin_indices(col_allowed, nx)\n",
    "            yy, xx = torch.meshgrid(row_picks, col_picks, indexing=\"ij\")\n",
    "            points = torch.stack([yy.reshape(-1), xx.reshape(-1)], dim=1) # (ny*nx, 2)\n",
    "            \n",
    "            # if more than n_points, subselect\n",
    "            if points.shape[0] > self.n_points:\n",
    "                sel_pos = torch.linspace(0, points.shape[0]-1, steps=self.n_points)\n",
    "                sel_idx = torch.round(sel_pos).long()\n",
    "                points = points[sel_idx]\n",
    "\n",
    "            ii = points[:, 0]\n",
    "            jj = points[:, 1]\n",
    "\n",
    "            if not self.deterministic_mask:\n",
    "                if self.jitter_std is not None and self.jitter_std > 0:\n",
    "                    # convert std (like 0.01 of image size) to pixels\n",
    "                    sigmaH = float(self.jitter_std) * self.H\n",
    "                    sigmaW = float(self.jitter_std) * self.W\n",
    "                    \n",
    "                    # Add Gaussian noise in pixel units\n",
    "                    ii = ii.to(torch.float32) + torch.randn_like(ii, dtype=torch.float32) * sigmaH\n",
    "                    jj = jj.to(torch.float32) + torch.randn_like(jj, dtype=torch.float32) * sigmaW\n",
    "\n",
    "                    # Round and clamp so they stay inside bounds\n",
    "                    ii = ii.round().clamp(self.radius, self.H - 1 - self.radius).to(torch.long)\n",
    "                    jj = jj.round().clamp(self.radius, self.W - 1 - self.radius).to(torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            yy, xx = torch.meshgrid(torch.arange(self.H), torch.arange(self.W), indexing=\"ij\")\n",
    "            for y0, x0 in zip(ii, jj):\n",
    "                disk = (yy - int(y0))**2 + (xx - int(x0))**2 <= (self.radius**2)\n",
    "                mask |= disk\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reveal_strategy: {self.reveal_strategy}\")\n",
    "        \n",
    "\n",
    "        obs = t_cur[chans].clone()\n",
    "        # Add noise (0 - 255 scale)\n",
    "        if self.noise is not None and self.noise > 0:\n",
    "            sigma = float(self.noise)\n",
    "            obs = obs + sigma * torch.randn_like(obs)\n",
    "            obs.clamp_(0.0, 255.0)\n",
    "\n",
    "\n",
    "        z[chans, :, :] = torch.where(mask, obs, torch.zeros_like(obs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- In Progress --- \n",
    "\n",
    "        if self.future_delta > 0:\n",
    "            step_f = step + self.future_delta   \n",
    "            t_label = torch.tensor(get_all(self.sims[index], step_f), dtype=torch.float32)\n",
    "        else:\n",
    "            t_label = t_cur.clone()\n",
    "\n",
    "\n",
    "\n",
    "        if self.return_mask:\n",
    "            return z,t_label, mask\n",
    "        else:  \n",
    "            return z,t_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sims.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc351e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "092ad765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def build_val_dataset_from_meta(meta):\n",
    "    \"\"\"\n",
    "    Rebuilds the validation MaskedDataset exactly as used in training.\n",
    "    Assumes you saved meta with keys like:\n",
    "      - reveal_strategy, n_points, radius, noise, channels\n",
    "      - val_steps, val_points\n",
    "      - reveal_dim, deterministic_mask_val, jitter_std_val\n",
    "      - mixed, future_delta\n",
    "    \"\"\"\n",
    "    reveal_strategy   = str(meta[\"reveal_strategy\"])\n",
    "    n_points          = int(meta[\"n_points\"])\n",
    "    radius            = int(meta[\"radius\"])\n",
    "    noise             = float(meta[\"noise\"])\n",
    "    channels          = meta[\"channels\"]\n",
    "    val_steps         = meta[\"val_steps\"]\n",
    "    val_points        = meta[\"val_points\"]\n",
    "    reveal_dim        = meta[\"reveal_dim\"].tolist() if hasattr(meta[\"reveal_dim\"], \"tolist\") else meta[\"reveal_dim\"]\n",
    "    deterministic_mask= bool(meta[\"deterministic_mask_val\"])\n",
    "    jitter_std        = float(meta[\"jitter_std_val\"])\n",
    "    mixed             = bool(meta[\"mixed\"])\n",
    "    future_delta      = int(meta[\"future_delta\"]) if \"future_delta\" in meta.files else 0\n",
    "\n",
    "    # match plotting/val reproducibility\n",
    "    torch.manual_seed(123); np.random.seed(123)\n",
    "\n",
    "    val_data = MaskedDataset(\n",
    "        val_sims,\n",
    "        reveal_strategy=reveal_strategy,\n",
    "        n_points=n_points,\n",
    "        radius=radius,\n",
    "        noise=noise,\n",
    "        channels=channels,\n",
    "        points=val_points,\n",
    "        steps=val_steps,\n",
    "        reveal_dim=reveal_dim,\n",
    "        deterministic_mask=deterministic_mask,\n",
    "        jitter_std=jitter_std,\n",
    "        mixed=mixed,\n",
    "        future_delta=future_delta,\n",
    "    )\n",
    "    return val_data, val_steps, future_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d05735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_for_sim_time(sim_id, t, meta, future_delta):\n",
    "    \"\"\"\n",
    "    Build a single (z, t_label) pair for a specific sim and time t\n",
    "    using the same config that was used during training.\n",
    "    \"\"\"\n",
    "    reveal_strategy    = str(meta[\"reveal_strategy\"])\n",
    "    n_points           = int(meta[\"n_points\"])\n",
    "    radius             = int(meta[\"radius\"])\n",
    "    noise              = float(meta[\"noise\"])\n",
    "    channels           = meta[\"channels\"]\n",
    "    reveal_dim         = meta[\"reveal_dim\"].tolist() if hasattr(meta[\"reveal_dim\"], \"tolist\") else meta[\"reveal_dim\"]\n",
    "    deterministic_mask = bool(meta[\"deterministic_mask_val\"])\n",
    "    jitter_std         = float(meta[\"jitter_std_val\"])\n",
    "    mixed              = bool(meta[\"mixed\"])\n",
    "\n",
    "    # make sure t is valid for this delta\n",
    "    SIM_STEPS = 201\n",
    "    max_start = SIM_STEPS - 1 - future_delta   # same logic as in MaskedDataset\n",
    "    t = min(int(t), max_start)\n",
    "\n",
    "    ds = MaskedDataset(\n",
    "        sims=np.array([sim_id]),\n",
    "        reveal_strategy=reveal_strategy,\n",
    "        n_points=n_points,\n",
    "        radius=radius,\n",
    "        noise=noise,\n",
    "        channels=channels,\n",
    "        points=None,                         # let it pick mask positions\n",
    "        steps=np.array([t]),                 # <- force time t\n",
    "        reveal_dim=reveal_dim,\n",
    "        deterministic_mask=deterministic_mask,\n",
    "        jitter_std=jitter_std,\n",
    "        mixed=mixed,\n",
    "        future_delta=future_delta,\n",
    "    )\n",
    "\n",
    "    z, t_label = ds[0]   # only one sample\n",
    "    return z, t_label, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab746cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138]\n"
     ]
    }
   ],
   "source": [
    "vals = range(140)\n",
    "f_delta_values = list(vals[::2])\n",
    "print(f_delta_values)\n",
    "\n",
    "tests = [\n",
    "    {\n",
    "        \"name\": f\"full_d{d}_n16_clean\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": False,\n",
    "        \"noise\": 0, \n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.2, .8)],[(.2,.8)]],\n",
    "        \"future_delta\": d,\n",
    "    }\n",
    "    for d in f_delta_values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc0742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def side_from_image(img, channel=0, top_rows=40, min_mass=1e-3):\n",
    "    \"\"\"\n",
    "    Decide whether the channel is more on the left or right in the top part\n",
    "    of the image.\n",
    "\n",
    "    img: (C, H, W) numpy array or torch tensor\n",
    "    channel: which channel to look at (0=K, 1=P, 2=phi)\n",
    "    top_rows: only look at rows [0:top_rows] to focus on the inlet region\n",
    "    min_mass: if total intensity is below this, treat as 'too weak'\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(img):\n",
    "        arr = img.detach().cpu().numpy()\n",
    "    else:\n",
    "        arr = np.asarray(img)\n",
    "\n",
    "    C, H, W = arr.shape\n",
    "    top_rows = min(top_rows, H)\n",
    "\n",
    "    patch = arr[channel, :top_rows, :]          # (top_rows, W)\n",
    "\n",
    "    left_mass  = patch[:, :W//2].sum()\n",
    "    right_mass = patch[:, W//2:].sum()\n",
    "    total      = left_mass + right_mass\n",
    "\n",
    "    if total < min_mass:\n",
    "        # essentially no channel signal -> skip\n",
    "        return None, 0.0, total\n",
    "\n",
    "    margin = abs(left_mass - right_mass) / max(total, 1e-8)\n",
    "    side   = \"L\" if left_mass > right_mass else \"R\"\n",
    "\n",
    "    return side, margin, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a26435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_right_accuracy_over_time(\n",
    "    model_name,\n",
    "    base_path=\"\",\n",
    "    future_delta=None,        # if None, read from meta\n",
    "    time_values=None,         # list of times t to evaluate\n",
    "    channel=0,                # 0=K, 1=P, 2=phi (for deciding side)\n",
    "    top_rows=40,\n",
    "    min_mass=1e-3,\n",
    "    strong_margin=0.10,       # margin threshold for “strong GT”\n",
    "    max_sims=None,            # limit sims for speed\n",
    "):\n",
    "    \"\"\"\n",
    "    For a single trained model, compute directional accuracy (left vs right)\n",
    "    as a function of the start time t.\n",
    "\n",
    "    Returns a dict with:\n",
    "      times, acc_all, acc_strong, n_all, n_strong,\n",
    "      n_lowmass, n_ambig, future_delta\n",
    "    \"\"\"\n",
    "    # ---- load meta + model ----\n",
    "    meta_path  = f\"{base_path}meta_{model_name}.npz\"\n",
    "    model_path = f\"{base_path}{model_name}.pt\"\n",
    "\n",
    "    meta  = np.load(meta_path, allow_pickle=True)\n",
    "    model = torch.load(model_path, weights_only=False,\n",
    "                       map_location=torch.device(\"cpu\")).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # get Δ\n",
    "    if future_delta is None:\n",
    "        future_delta = int(meta[\"future_delta\"]) if \"future_delta\" in meta.files else 0\n",
    "\n",
    "    # which sims to use\n",
    "    sims = val_sims.copy()\n",
    "    if max_sims is not None:\n",
    "        sims = sims[:max_sims]\n",
    "\n",
    "    # default time grid if not given\n",
    "    if time_values is None:\n",
    "        # e.g. from 60 to 140 in steps of 5\n",
    "        time_values = list(range(60, 141, 5))\n",
    "\n",
    "    results = {\n",
    "        \"times\": [],\n",
    "        \"acc_all\": [],\n",
    "        \"acc_strong\": [],\n",
    "        \"n_all\": [],\n",
    "        \"n_strong\": [],\n",
    "        \"n_lowmass\": [],\n",
    "        \"n_ambig\": [],\n",
    "        \"future_delta\": future_delta,\n",
    "    }\n",
    "\n",
    "    for t in time_values:\n",
    "        # skip times whose future t+Δ goes past the end\n",
    "        if t + future_delta >= SIM_STEPS:\n",
    "            continue\n",
    "\n",
    "        correct_all = total_all = 0\n",
    "        correct_str = total_str = 0\n",
    "        n_lowmass = 0\n",
    "        n_ambig   = 0\n",
    "\n",
    "        for sim_id in sims:\n",
    "            sim_id = int(sim_id)\n",
    "\n",
    "            # build masked input at time t using your same meta config\n",
    "            z, t_label, t_actual = make_sample_for_sim_time(sim_id, t, meta, future_delta)\n",
    "\n",
    "            t_f = t + future_delta\n",
    "\n",
    "            # ground-truth future (from raw data)\n",
    "            img_true_future = get_all(sim_id, t_f)    # (3, H, W)\n",
    "\n",
    "            # model prediction\n",
    "            with torch.no_grad():\n",
    "                out = model(z.to(device).unsqueeze(0))[0]\n",
    "            img_pred_future = out.detach().cpu().numpy()  # (3, H, W)\n",
    "\n",
    "            # ---- decide L/R for GT ----\n",
    "            side_true, margin_true, mass_true = side_from_image(\n",
    "                img_true_future,\n",
    "                channel=channel,\n",
    "                top_rows=top_rows,\n",
    "                min_mass=min_mass,\n",
    "            )\n",
    "\n",
    "            if side_true is None:\n",
    "                # too little signal -> low mass\n",
    "                n_lowmass += 1\n",
    "                continue\n",
    "\n",
    "            # ---- decide L/R for prediction ----\n",
    "            side_pred, margin_pred, mass_pred = side_from_image(\n",
    "                img_pred_future,\n",
    "                channel=channel,\n",
    "                top_rows=top_rows,\n",
    "                min_mass=min_mass,\n",
    "            )\n",
    "\n",
    "            if side_pred is None:\n",
    "                # model predicted nothing meaningful: count as trial, but incorrect\n",
    "                total_all += 1\n",
    "                # not strong GT if margin below threshold\n",
    "                if margin_true >= strong_margin:\n",
    "                    total_str += 1\n",
    "                continue\n",
    "\n",
    "            # classify GT as strong vs ambiguous\n",
    "            is_strong = (margin_true >= strong_margin)\n",
    "            is_ambig  = (margin_true < strong_margin)\n",
    "\n",
    "            total_all += 1\n",
    "            if side_pred == side_true:\n",
    "                correct_all += 1\n",
    "\n",
    "            if is_strong:\n",
    "                total_str += 1\n",
    "                if side_pred == side_true:\n",
    "                    correct_str += 1\n",
    "            else:\n",
    "                n_ambig += 1\n",
    "\n",
    "        acc_all = np.nan if total_all == 0 else correct_all / total_all\n",
    "        acc_str = np.nan if total_str == 0 else correct_str / total_str\n",
    "\n",
    "        results[\"times\"].append(t)\n",
    "        results[\"acc_all\"].append(acc_all)\n",
    "        results[\"acc_strong\"].append(acc_str)\n",
    "        results[\"n_all\"].append(total_all)\n",
    "        results[\"n_strong\"].append(total_str)\n",
    "        results[\"n_lowmass\"].append(n_lowmass)\n",
    "        results[\"n_ambig\"].append(n_ambig)\n",
    "\n",
    "        print(\n",
    "            f\"[{model_name}] t={t:3d}, Δ={future_delta:3d} | \"\n",
    "            f\"acc_all={acc_all:.3f} (n={total_all}), \"\n",
    "            f\"acc_strong={acc_str:.3f} (n_str={total_str}), \"\n",
    "            f\"lowmass={n_lowmass}, ambig={n_ambig}\"\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7242f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_lr_accuracy_curves(model_names, base_path=\"\", time_values=None,\n",
    "                            channel=0, top_rows=40, strong_margin=0.10,\n",
    "                            max_sims=250):\n",
    "    \"\"\"\n",
    "    model_names: list of strings, e.g. [\"full_d0_n16_clean\", \"full_d20_n16_clean\", ...]\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for name in model_names:\n",
    "        print(f\"\\n=== Evaluating left/right vs time for {name} ===\")\n",
    "        res = left_right_accuracy_over_time(\n",
    "            name,\n",
    "            base_path=base_path,\n",
    "            future_delta=None,          # read from meta\n",
    "            time_values=time_values,    # you can pass something like range(70,121,5)\n",
    "            channel=channel,\n",
    "            top_rows=top_rows,\n",
    "            strong_margin=strong_margin,\n",
    "            max_sims=max_sims,\n",
    "        )\n",
    "        all_results[name] = res\n",
    "\n",
    "        ts   = np.array(res[\"times\"])\n",
    "        accs = np.array(res[\"acc_strong\"])   # I’d plot strong GT for clarity\n",
    "\n",
    "        Δ = res[\"future_delta\"]\n",
    "        plt.plot(ts, accs, \"-o\", label=f\"Δ={Δ}\")\n",
    "\n",
    "    plt.xlabel(\"Start time t\")\n",
    "    plt.ylabel(\"Directional accuracy (strong GT)\")\n",
    "    plt.title(\"Left/right prediction vs time for different Δ\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(title=\"Future Δ\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93044dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Evaluating full_d0_n16_clean (Δ=0) over times [80, 85, 90, 95, 100, 105, 110, 115, 120]...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m     time_grid = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m30\u001b[39m, \u001b[32m121\u001b[39m, \u001b[32m5\u001b[39m))   \u001b[38;5;66;03m# long-horizon\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m➡ Evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Δ=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mΔ\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) over times \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_grid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m res = \u001b[43mleft_right_accuracy_over_time\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture_delta\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# read from meta\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# customized per Δ\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrong_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_sims\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDone. Accuracy summary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres.get(\u001b[33m'\u001b[39m\u001b[33maccuracy_summary\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee metrics output\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mleft_right_accuracy_over_time\u001b[39m\u001b[34m(model_name, base_path, future_delta, time_values, channel, top_rows, min_mass, strong_margin, max_sims)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# model prediction\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     78\u001b[39m img_pred_future = out.detach().cpu().numpy()  \u001b[38;5;66;03m# (3, H, W)\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# ---- decide L/R for GT ----\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36mSmallUnet.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    120\u001b[39m x1 = \u001b[38;5;28mself\u001b[39m.d1(top)\n\u001b[32m    121\u001b[39m x2 = \u001b[38;5;28mself\u001b[39m.d2(x1)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m x3 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43md3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Here we upsample slightly so that we can downsample with less border artifacts\u001b[39;00m\n\u001b[32m    123\u001b[39m x4 = \u001b[38;5;28mself\u001b[39m.d4(x3)\n\u001b[32m    124\u001b[39m x5 = \u001b[38;5;28mself\u001b[39m.d5(x4)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mDownsample.forward\u001b[39m\u001b[34m(self, inp)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pool(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mTwoConv.forward\u001b[39m\u001b[34m(self, inp)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for cfg in tests:\n",
    "    name = cfg[\"name\"]\n",
    "    Δ    = cfg[\"future_delta\"]\n",
    "\n",
    "    # Required files for evaluation\n",
    "    model_path = f\"{name}.pt\"\n",
    "    meta_path  = f\"meta_{name}.npz\"\n",
    "\n",
    "    # Check if both files exist\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"🚫 Skipping {name} — model file not found ({model_path})\")\n",
    "        continue\n",
    "    if not os.path.exists(meta_path):\n",
    "        print(f\"🚫 Skipping {name} — meta file not found ({meta_path})\")\n",
    "        continue\n",
    "\n",
    "    # Assign time grid based on future_delta\n",
    "    if Δ <= 10:\n",
    "        time_grid = list(range(80, 121, 5))   # short-horizon\n",
    "    elif Δ <= 40:\n",
    "        time_grid = list(range(60, 121, 5))   # medium-horizon\n",
    "    else:\n",
    "        time_grid = list(range(30, 121, 5))   # long-horizon\n",
    "\n",
    "    print(f\"➡ Evaluating {name} (Δ={Δ}) over times {time_grid}...\")\n",
    "\n",
    "    res = left_right_accuracy_over_time(\n",
    "        name,\n",
    "        base_path=\"\",\n",
    "        future_delta=None,      # read from meta\n",
    "        time_values=time_grid,  # customized per Δ\n",
    "        channel=0,\n",
    "        top_rows=40,\n",
    "        strong_margin=0.10,\n",
    "        max_sims=250,\n",
    "    )\n",
    "\n",
    "    print(f\"Done. Accuracy summary: {res.get('accuracy_summary', 'See metrics output')}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b015de0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
