{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b325813",
   "metadata": {},
   "source": [
    "Same code from PINN we have been working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Prevents crashes when showing graphs\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "SIM_STEPS = 201\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Determined train/test/val split\n",
    "train_sims = np.load(\"../train_sims.npy\")\n",
    "train_sims = train_sims[train_sims < 750]\n",
    "val_sims = np.load(\"../val_sims.npy\")\n",
    "val_sims = val_sims[val_sims < 750]\n",
    "test_sims = np.load(\"../test_sims.npy\")\n",
    "test_sims = test_sims[test_sims < 750]\n",
    "\n",
    "# Get porosity phi\n",
    "def get_phi(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_phi.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get pressure\n",
    "def get_pres(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_P.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get conductivity K\n",
    "def get_k(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_K.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get all 3 as a 3-channel matrix\n",
    "def get_all(sim,step):\n",
    "    return np.array((get_k(sim,step), get_pres(sim,step), get_phi(sim,step)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6210558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darcy loss function\n",
    "def darcy_loss(model, inp):\n",
    "    # Takes in the k,pres,phi and outputs the prediction across the image.\n",
    "    inp = inp.requires_grad_(True)\n",
    "    out = model(inp)\n",
    "    # out is in order K,P,phi, (conductivity, pressure, porosity)\n",
    "\n",
    "    # Impose high pressure along the entire upper line by setting the pressure channelt to 200.\n",
    "    out[:, 1:2, 0, :] = 200\n",
    "\n",
    "    # If we assume the output is in order k,pres,phi\n",
    "    # pres_grad is the gradient of the pressure along the y and x directions as a tuple\n",
    "    pres_grad = torch.gradient(out[:, 1:2], dim=(-2,-1))\n",
    "\n",
    "    # get velocity by multiplying the gradient by the conductivity\n",
    "    y_grad = pres_grad[0] * out[:, 0:1]\n",
    "    x_grad = pres_grad[1] * out[:, 0:1]\n",
    "\n",
    "    # compute the divergence by the second derivative of the gradients and adding them together\n",
    "    yy_grad = torch.gradient(y_grad, spacing=(1,),dim=(-2,))[0]\n",
    "    xx_grad = torch.gradient(x_grad, spacing=(1,),dim=(-1,))[0]\n",
    "    final = yy_grad + xx_grad\n",
    "\n",
    "    # total divergence should be 0\n",
    "    loss = (final**2).mean()\n",
    "\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Blocks of the Unet\n",
    "\n",
    "class TwoConv(nn.Module):\n",
    "    # Basic block with 2 convolutional layers, each with a batch norm and relu\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, no_end_relu=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if no_end_relu:\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.seq(inp)\n",
    "\n",
    "# A single conv layer that will increase the height and width of the matrix by 2 each.\n",
    "class SmallUp(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "\n",
    "# A single conv layer that will decrease the height and width of the matrix by 2 each.\n",
    "class SmallDown(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 0)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "    \n",
    "# Applies two convolutional layers, then pools\n",
    "class Downsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = TwoConv(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        return self.pool(self.conv(inp))\n",
    "\n",
    "# Upsamples and concatenates the upsampled matrix with the \"across\" then performs convolution on the result\n",
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, tweak=None):\n",
    "        super().__init__()\n",
    "        # Upsamples by 2x\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)\n",
    "        self.tweak = tweak\n",
    "        self.conv_after = TwoConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, below, across):\n",
    "        # First upsample by 2x\n",
    "        upsampled = self.up(below)\n",
    "        # If tweak is active, apply it first\n",
    "        if not self.tweak == None:\n",
    "            upsampled = self.tweak(upsampled)\n",
    "        # Concatenate with the same size on the downswing of the unet\n",
    "        concat = torch.concat((upsampled, across), dim=-3)\n",
    "        # Convolute them together\n",
    "        return self.conv_after(concat)\n",
    "    \n",
    "# Define the actual model used\n",
    "class SmallUnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input is Nx3x200x200\n",
    "        self.c1 = TwoConv(3, 8)\n",
    "        self.d1 = Downsample(8,16) # 16x100x100\n",
    "        self.d2 = Downsample(16,32) # 32x50x50\n",
    "        self.su = nn.Sequential(\n",
    "            SmallUp(32),\n",
    "            SmallUp(32),\n",
    "            SmallUp(32)\n",
    "        ) # 3x56x56\n",
    "        self.d3 = Downsample(32,64) # 64x28x28\n",
    "        self.d4 = Downsample(64,128) # 128x14x14\n",
    "        self.d5 = Downsample(128, 256) # 256x7x7\n",
    "\n",
    "        # Now back up\n",
    "        self.u1 = Upsample(256, 128) # 128x14x14\n",
    "        self.u2 = Upsample(128, 64) # 64x28x28\n",
    "        self.u3 = Upsample(64, 32, tweak=nn.Sequential(\n",
    "            SmallDown(32),\n",
    "            SmallDown(32),\n",
    "            SmallDown(32)\n",
    "        ))  # 32x50x50\n",
    "        self.u4 = Upsample(32,16) # 16x100x100\n",
    "        self.u5 = Upsample(16,8) # 8x200x200\n",
    "        self.final = TwoConv(8, 3, no_end_relu=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Start with convolution, expand 3 channels to 8.\n",
    "        # Then downsample 5 times, saving the result\n",
    "        top = self.c1(input)\n",
    "        x1 = self.d1(top)\n",
    "        x2 = self.d2(x1)\n",
    "        x3 = self.d3(self.su(x2)) # Here we upsample slightly so that we can downsample with less border artifacts\n",
    "        x4 = self.d4(x3)\n",
    "        x5 = self.d5(x4)\n",
    "        # Now that we're at 256x7x7, we upsample from here.\n",
    "        # At each layer with concatenate with the xi that is the same size as the up after upsampling.\n",
    "        up = self.u1(x5, x4)\n",
    "        up = self.u2(up, x3)\n",
    "        up = self.u3(up, x2) # Again, a small downsample here to get back on the proper resolution\n",
    "        up = self.u4(up, x1)\n",
    "        up = self.u5(up, top)\n",
    "        # One last convolution on the result to return to 3 channels from 8, leaving us with the proper 3x200x200\n",
    "        return self.final(up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22876e85",
   "metadata": {},
   "source": [
    "# New Parameters \n",
    "**`return_mask`** : Used for visualizing mask. Check bottom of file for example\n",
    "\n",
    "**`reveal_dim`** : Two lists of tuples for y, x dimension. Marks areas for sensor points to appear\n",
    "\n",
    "**`jitter_std`** : pixel standard deviation for sensor points to move around\n",
    "\n",
    "**`deterministic_mask`** : If true, sensor points do not jitter\n",
    "\n",
    "**`future_delta`** : In progress, changes label from current time to current + delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e969716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 sims,\n",
    "                 unmask_size=20,\n",
    "                 points = None,\n",
    "                 block_size = 50,\n",
    "                 reveal_strategy = \"block\",\n",
    "                 n_points = 200,\n",
    "                 radius = 2,\n",
    "                 steps = None,\n",
    "                 H=200,\n",
    "                 W=200,\n",
    "                 channels=\"all\",\n",
    "                 mixed=False,\n",
    "                 types=None,\n",
    "                 noise=5,\n",
    "                 return_mask=False,                 # allows visualiztion of mask\n",
    "                 reveal_dim=[[(0, 1)], [(0, 1)]],   # x,y range for disks to exist\n",
    "                 jitter_std=0.0,                    # % each disk drifts from deterministic position\n",
    "                 deterministic_mask=True,            # if True, mask is deterministic and noise is 0\n",
    "                 future_delta=0\n",
    "                 ):\n",
    "        \n",
    "        self.sims = sims\n",
    "        self.points = points\n",
    "        self.steps = steps\n",
    "        self.size = unmask_size\n",
    "        self.reveal_strategy = reveal_strategy\n",
    "        self.block_size = block_size\n",
    "        self.n_points = n_points\n",
    "        self.radius = radius\n",
    "        self.H, self.W = H, W\n",
    "        self.channels = channels\n",
    "        self.mixed = mixed\n",
    "        self.types = types\n",
    "        self.noise = noise\n",
    "        self.return_mask = return_mask\n",
    "        self.reveal_dim = reveal_dim\n",
    "        self.jitter_std = jitter_std\n",
    "        self.deterministic_mask = deterministic_mask\n",
    "        self.future_delta = future_delta\n",
    "\n",
    "    def _chan_idx(self):\n",
    "        if self.channels == \"all\":\n",
    "            return [0,1,2]\n",
    "        elif self.channels == \"K\":\n",
    "            return [0]\n",
    "        elif self.channels == \"P\":\n",
    "            return [1]\n",
    "        elif self.channels == \"phi\":\n",
    "            return [2]\n",
    "        else:\n",
    "            raise ValueError(\"channels must be 'all', 'K', 'P', or 'phi'\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # --- In Progress --- \n",
    "\n",
    "            # pick a valid step\n",
    "        if not isinstance(self.steps, np.ndarray):\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta  # ensures step + delta ≤ 199\n",
    "            step = np.random.randint(1, max_start + 1)  \n",
    "        else:\n",
    "            step = int(self.steps[index])\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta\n",
    "            if step > max_start:\n",
    "                step = max_start\n",
    "\n",
    "\n",
    "\n",
    "        # if not type(self.steps) == np.ndarray:\n",
    "        #     step = np.random.randint(1,200)\n",
    "        # else:\n",
    "        #     step = self.steps[index]\n",
    "\n",
    "\n",
    "\n",
    "        # Create tensor for the target\n",
    "        t_cur = torch.tensor(get_all(self.sims[index], step), dtype=torch.float32)\n",
    "\n",
    "        # Create 0 matrix\n",
    "        z = torch.zeros_like(t_cur)\n",
    "\n",
    "        # build a boolean mask of revealed pixels, shape (H,W)\n",
    "        mask = torch.zeros((self.H, self.W), dtype=torch.bool)\n",
    "\n",
    "        chans = self._chan_idx()\n",
    "\n",
    "        if self.reveal_strategy == \"block\":\n",
    "            # choose top-left for the block\n",
    "            if not type(self.points) == np.ndarray:\n",
    "                i0 = np.random.randint(0, self.H - self.block_size + 1)\n",
    "                j0 = np.random.randint(0, self.W - self.block_size + 1)\n",
    "            else:\n",
    "                i0, j0 = self.points[index]\n",
    "                i0 = max(0, min(i0, self.H - self.block_size))\n",
    "                j0 = max(0, min(j0, self.W - self.block_size))\n",
    "            mask[i0:i0+self.block_size, j0:j0+self.block_size] = True\n",
    "\n",
    "        elif self.reveal_strategy == \"disks\":\n",
    "\n",
    "            # used for reveal_dim\n",
    "            # map fraction [0,1] to pixel indices [0, N-1] in mask layer\n",
    "            def _segments_to_indices(segments, N, pad=0):\n",
    "                idxs = []\n",
    "                for a, b in segments:\n",
    "                    i0 = max(pad, int(round(a * (N - 1))))\n",
    "                    i1 = min((N - 1) - pad, int(round(b * (N - 1))))\n",
    "                    if i1 >= i0:\n",
    "                        idxs.append(torch.arange(i0, i1 + 1, dtype=torch.long))\n",
    "                if not idxs:\n",
    "                    # fallback to full range\n",
    "                    return torch.arange(pad, N - pad, dtype=torch.long)\n",
    "                return torch.unique(torch.cat(idxs)).to(torch.long)\n",
    "\n",
    "            row_fracs = self.reveal_dim[0] # e.g, [(0, 1)]\n",
    "            col_fracs = self.reveal_dim[1] # e.g, [(0, 1)]\n",
    "            row_allowed = _segments_to_indices(row_fracs, self.H, pad=self.radius)\n",
    "            col_allowed = _segments_to_indices(col_fracs, self.W, pad=self.radius)\n",
    "\n",
    "            # choose grid shape close to aspect ratio \n",
    "            # works with non-squares\n",
    "            Hspan = (row_allowed[-1] - row_allowed[0] + 1) if len(row_allowed) > 0 else self.H\n",
    "            Wspan = (col_allowed[-1] - col_allowed[0] + 1) if len(col_allowed) > 0 else self.W\n",
    "            ratio = float(Wspan) / max(1.0, float(Hspan))\n",
    "            ny = int(max(1, round(np.sqrt(self.n_points / max(1e-8, ratio)))))\n",
    "            nx = int(max(1, round(self.n_points / ny)))\n",
    "            while nx * ny < self.n_points:\n",
    "                nx += 1\n",
    "\n",
    "            # pick evenly spaced indices from rows/cols allowed\n",
    "            def pick_lin_indices(allowed, k):\n",
    "                if k <= 1:\n",
    "                    return allowed[len(allowed)//2]\n",
    "                pos = torch.linspace(0, len(allowed)-1, steps=k)\n",
    "                idx = torch.round(pos).long()\n",
    "                return allowed[idx]\n",
    "            \n",
    "            \n",
    "            row_picks = pick_lin_indices(row_allowed, ny)\n",
    "            col_picks = pick_lin_indices(col_allowed, nx)\n",
    "            yy, xx = torch.meshgrid(row_picks, col_picks, indexing=\"ij\")\n",
    "            points = torch.stack([yy.reshape(-1), xx.reshape(-1)], dim=1) # (ny*nx, 2)\n",
    "            \n",
    "            # if more than n_points, subselect\n",
    "            if points.shape[0] > self.n_points:\n",
    "                sel_pos = torch.linspace(0, points.shape[0]-1, steps=self.n_points)\n",
    "                sel_idx = torch.round(sel_pos).long()\n",
    "                points = points[sel_idx]\n",
    "\n",
    "            ii = points[:, 0]\n",
    "            jj = points[:, 1]\n",
    "\n",
    "            if not self.deterministic_mask:\n",
    "                if self.jitter_std is not None and self.jitter_std > 0:\n",
    "                    # convert std (like 0.01 of image size) to pixels\n",
    "                    sigmaH = float(self.jitter_std) * self.H\n",
    "                    sigmaW = float(self.jitter_std) * self.W\n",
    "                    \n",
    "                    # Add Gaussian noise in pixel units\n",
    "                    ii = ii.to(torch.float32) + torch.randn_like(ii, dtype=torch.float32) * sigmaH\n",
    "                    jj = jj.to(torch.float32) + torch.randn_like(jj, dtype=torch.float32) * sigmaW\n",
    "\n",
    "                    # Round and clamp so they stay inside bounds\n",
    "                    ii = ii.round().clamp(self.radius, self.H - 1 - self.radius).to(torch.long)\n",
    "                    jj = jj.round().clamp(self.radius, self.W - 1 - self.radius).to(torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            yy, xx = torch.meshgrid(torch.arange(self.H), torch.arange(self.W), indexing=\"ij\")\n",
    "            for y0, x0 in zip(ii, jj):\n",
    "                disk = (yy - int(y0))**2 + (xx - int(x0))**2 <= (self.radius**2)\n",
    "                mask |= disk\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reveal_strategy: {self.reveal_strategy}\")\n",
    "        \n",
    "\n",
    "        obs = t_cur[chans].clone()\n",
    "        # Add noise (0 - 255 scale)\n",
    "        if self.noise is not None and self.noise > 0:\n",
    "            sigma = float(self.noise)\n",
    "            obs = obs + sigma * torch.randn_like(obs)\n",
    "            obs.clamp_(0.0, 255.0)\n",
    "\n",
    "\n",
    "        z[chans, :, :] = torch.where(mask, obs, torch.zeros_like(obs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- In Progress --- \n",
    "\n",
    "        if self.future_delta > 0:\n",
    "            step_f = step + self.future_delta   \n",
    "            t_label = torch.tensor(get_all(self.sims[index], step_f), dtype=torch.float32)\n",
    "        else:\n",
    "            t_label = t_cur.clone()\n",
    "\n",
    "\n",
    "\n",
    "        if self.return_mask:\n",
    "            return z,t_label, mask\n",
    "        else:  \n",
    "            return z,t_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sims.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_meta(name, **kwargs):\n",
    "    \"\"\"\n",
    "    Saves meta info so you can reconstruct the exact val dataset later.\n",
    "    Usage:\n",
    "        save_meta(\n",
    "            name,\n",
    "            reveal_strategy=reveal_strategy, n_points=n_points, radius=radius,\n",
    "            noise=noise, channels=channels, val_steps=val_steps, val_points=val_points,\n",
    "            reveal_dim=reveal_dim, deterministic_mask_train=deterministic_mask,\n",
    "            jitter_std_train=jitter_std, deterministic_mask_val=True, jitter_std_val=0.0,\n",
    "            mixed=mixed, future_delta=future_delta\n",
    "        )\n",
    "    \"\"\"\n",
    "    # sanitize and cast\n",
    "    arr = {}\n",
    "    for k, v in kwargs.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if k in {\"reveal_dim\"}:\n",
    "            arr[k] = np.array(v, dtype=object)         # keep nested structure\n",
    "        elif isinstance(v, (list, tuple)) and k not in {\"val_steps\", \"val_points\"}:\n",
    "            arr[k] = np.array(v)\n",
    "        else:\n",
    "            arr[k] = v\n",
    "\n",
    "    np.savez(f\"meta_{name}.npz\", **arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ed2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model,\n",
    "    optim,\n",
    "    schedule=None,\n",
    "    crit=nn.MSELoss(),\n",
    "    epochs=250,\n",
    "    name=\"run\",\n",
    "    save_model=True,\n",
    "    save_curves=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains model with Darcy loss + supervised loss.\n",
    "    Returns a dict of learning curves; optionally saves model and curves.\n",
    "\n",
    "    Curves:\n",
    "      - train_total, train_darcy\n",
    "      - val_total,   val_darcy\n",
    "    \"\"\"\n",
    "    # Histories\n",
    "    train_total_hist, train_darcy_hist = [], []\n",
    "    val_total_hist,   val_darcy_hist   = [], []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=f\"Training {name}\"):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        tot_loss_sum, darcy_loss_sum, n_train = 0.0, 0.0, 0\n",
    "\n",
    "        for feat, label in train_loader:\n",
    "            feat  = feat.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            p_loss, out = darcy_loss(model, feat)\n",
    "            s_loss      = crit(out, label)\n",
    "            loss        = p_loss + s_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            # accumulate\n",
    "            bs = feat.size(0)\n",
    "            n_train         += bs\n",
    "            tot_loss_sum    += loss.item()  * bs\n",
    "            darcy_loss_sum  += p_loss.item() * bs\n",
    "\n",
    "        train_total = tot_loss_sum   / max(1, n_train)\n",
    "        train_darcy = darcy_loss_sum / max(1, n_train)\n",
    "        train_total_hist.append(train_total)\n",
    "        train_darcy_hist.append(train_darcy)\n",
    "\n",
    "        if schedule is not None:\n",
    "            schedule.step()\n",
    "\n",
    "        # ---- VALIDATE ----\n",
    "        model.eval()\n",
    "        tot_loss_sum, darcy_loss_sum, n_val = 0.0, 0.0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for feat, label in val_loader:\n",
    "                feat  = feat.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                p_loss, out = darcy_loss(model, feat)\n",
    "                s_loss      = crit(out, label)\n",
    "                loss        = p_loss + s_loss\n",
    "\n",
    "                bs = feat.size(0)\n",
    "                n_val         += bs\n",
    "                tot_loss_sum  += loss.item()  * bs\n",
    "                darcy_loss_sum+= p_loss.item() * bs\n",
    "\n",
    "        val_total = tot_loss_sum   / max(1, n_val)\n",
    "        val_darcy = darcy_loss_sum / max(1, n_val)\n",
    "        val_total_hist.append(val_total)\n",
    "        val_darcy_hist.append(val_darcy)\n",
    "\n",
    "    # ---- SAVE ARTIFACTS ----\n",
    "    if save_model:\n",
    "        torch.save(model, f\"{name}.pt\")\n",
    "\n",
    "    if save_curves:\n",
    "        np.savez(\n",
    "            f\"curves_{name}.npz\",\n",
    "            train_total=np.array(train_total_hist, dtype=np.float32),\n",
    "            train_darcy=np.array(train_darcy_hist, dtype=np.float32),\n",
    "            val_total=np.array(val_total_hist, dtype=np.float32),\n",
    "            val_darcy=np.array(val_darcy_hist, dtype=np.float32),\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"train_total\": train_total_hist,\n",
    "        \"train_darcy\": train_darcy_hist,\n",
    "        \"val_total\":   val_total_hist,\n",
    "        \"val_darcy\":   val_darcy_hist,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a124114",
   "metadata": {},
   "source": [
    "NEW:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7eb2f5",
   "metadata": {},
   "source": [
    "Here you can add tests to run, each one takes a whole train test cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    # Short-term prediction (1-step ahead)\n",
    "    {\"name\":\"delta_1_short\",\n",
    "     \"reveal_strategy\":\"disks\", \"n_points\":16, \"radius\":5,\n",
    "     \"mixed\":True, \"noise\":5,\n",
    "     \"deterministic_mask\":False, \"jitter_std\":0.02,\n",
    "     \"future_delta\":1},\n",
    "\n",
    "    # Medium-term (5 steps ahead)\n",
    "    {\"name\":\"delta_5_medium\",\n",
    "     \"reveal_strategy\":\"disks\", \"n_points\":16, \"radius\":5,\n",
    "     \"mixed\":True, \"noise\":5,\n",
    "     \"deterministic_mask\":False, \"jitter_std\":0.02,\n",
    "     \"future_delta\":5},\n",
    "\n",
    "    # Long-term (10 steps ahead)\n",
    "    {\"name\":\"delta_10_long\",\n",
    "     \"reveal_strategy\":\"disks\", \"n_points\":16, \"radius\":5,\n",
    "     \"mixed\":True, \"noise\":5,\n",
    "     \"deterministic_mask\":False, \"jitter_std\":0.02,\n",
    "     \"future_delta\":10},\n",
    "\n",
    "    # Very long-term (20 steps ahead)\n",
    "    {\"name\":\"delta_20_verylong\",\n",
    "     \"reveal_strategy\":\"disks\", \"n_points\":16, \"radius\":5,\n",
    "     \"mixed\":True, \"noise\":5,\n",
    "     \"deterministic_mask\":False, \"jitter_std\":0.02,\n",
    "     \"future_delta\":20},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3e6b6",
   "metadata": {},
   "source": [
    "Trains each configuration listed in `{tests}` one at a time.  \n",
    "For every model trained, these files are saved:\n",
    "- **`curves_{name}.npz`** – training and validation loss curves  \n",
    "- **`disks_{name}.pt`** – trained model weights  \n",
    "- **`meta_{name}.npz`** – run metadata (setup, noise)\n",
    "\n",
    "These outputs are used for evaluation and comparison in **`plot.ipynb`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa1e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m crit = nn.MSELoss()\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# --- train ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m hist = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m results[config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]] = {\u001b[33m\"\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m\"\u001b[39m: hist, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model.state_dict()}\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# --- save meta so plotting notebook can reconstruct val_data ---\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_loader, val_loader, model, optim, schedule, crit, epochs, name)\u001b[39m\n\u001b[32m     13\u001b[39m label = label.to(device)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Process darcy loss and save it\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m p_loss, out = \u001b[43mdarcy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m epoch_darcy += p_loss.item()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Calculate total loss\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mdarcy_loss\u001b[39m\u001b[34m(model, inp)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdarcy_loss\u001b[39m(model, inp):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Takes in the k,pres,phi and outputs the prediction across the image.\u001b[39;00m\n\u001b[32m      4\u001b[39m     inp = inp.requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# out is in order K,P,phi, (conductivity, pressure, porosity)\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Impose high pressure along the entire upper line by setting the pressure channelt to 200.\u001b[39;00m\n\u001b[32m      9\u001b[39m     out[:, \u001b[32m1\u001b[39m:\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, :] = \u001b[32m200\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mSmallUnet.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    128\u001b[39m up = \u001b[38;5;28mself\u001b[39m.u2(up, x3)\n\u001b[32m    129\u001b[39m up = \u001b[38;5;28mself\u001b[39m.u3(up, x2) \u001b[38;5;66;03m# Again, a small downsample here to get back on the proper resolution\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m up = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mu4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m up = \u001b[38;5;28mself\u001b[39m.u5(up, top)\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# One last convolution on the result to return to 3 channels from 8, leaving us with the proper 3x200x200\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mUpsample.forward\u001b[39m\u001b[34m(self, below, across)\u001b[39m\n\u001b[32m     81\u001b[39m concat = torch.concat((upsampled, across), dim=-\u001b[32m3\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Convolute them together\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_after\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mTwoConv.forward\u001b[39m\u001b[34m(self, inp)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for config in tests:\n",
    "    name                        = config.get(\"name\")\n",
    "    reveal_strategy             = config.get(\"reveal_strategy\", \"disks\")\n",
    "    n_points                    = config.get(\"n_points\", 5)\n",
    "    radius                      = config.get(\"radius\", 4)\n",
    "    noise                       = config.get(\"noise\", 0)\n",
    "    deterministic_mask          = config.get(\"deterministic_mask\", False)   # allow jitter by default\n",
    "    jitter_std                  = float(config.get(\"jitter_std\", 0.02))     # 2% jitter\n",
    "    reveal_dim                  = config.get(\"reveal_dim\", [[(0,1)], [(0,1)]])\n",
    "    channels                    = config.get(\"channels\", \"all\")\n",
    "    mixed                       = bool(config.get(\"mixed\", True))\n",
    "    future_delta                = int(config.get(\"future_delta\", 0))\n",
    "\n",
    "\n",
    "    # Pre-define steps and points to maintain a consistent validation set\n",
    "    MAX_TIME = 201 - future_delta\n",
    "    val_steps = np.random.randint(1,MAX_TIME,(val_sims.shape[0],))\n",
    "    val_points = np.random.randint(0,149,(val_sims.shape[0],2))\n",
    "\n",
    "    # --- TRAIN dataset/loader ---\n",
    "    train_data = MaskedDataset(\n",
    "        train_sims,\n",
    "        reveal_strategy     =reveal_strategy,\n",
    "        n_points            =n_points,\n",
    "        radius              =radius,\n",
    "        mixed               =mixed,                      \n",
    "        noise               =noise,\n",
    "        channels            =channels,\n",
    "        reveal_dim          =reveal_dim,\n",
    "        deterministic_mask  =deterministic_mask,\n",
    "        jitter_std          =jitter_std,\n",
    "        future_delta        =future_delta\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "\n",
    "    # --- VAL dataset/loader (deterministic) ---\n",
    "    val_data = MaskedDataset(\n",
    "        val_sims,\n",
    "        reveal_strategy     =reveal_strategy,\n",
    "        n_points            =n_points,\n",
    "        radius              =radius,\n",
    "        mixed               =mixed,\n",
    "        noise               =noise,\n",
    "        channels            =channels,\n",
    "        points              =val_points,\n",
    "        steps               =val_steps,\n",
    "        reveal_dim          =reveal_dim,\n",
    "        deterministic_mask  =True,            \n",
    "        jitter_std          =0.0,                       \n",
    "        future_delta        =future_delta\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)\n",
    "\n",
    "    # --- model/optim ---\n",
    "    model = SmallUnet().to(device)\n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "    schedule = torch.optim.lr_scheduler.ExponentialLR(optim, 0.99)\n",
    "    crit = nn.MSELoss()\n",
    "\n",
    "    # --- train ---\n",
    "    hist = train(train_loader, val_loader, model, optim, schedule, crit, epochs=250, name=name)\n",
    "    results[name] = {\"hist\": hist, \"model\": model.state_dict()}\n",
    "\n",
    "    # --- save meta so plotting notebook can reconstruct val_data ---\n",
    "    save_meta(\n",
    "        name,\n",
    "        reveal_strategy=reveal_strategy,\n",
    "        n_points=n_points,\n",
    "        radius=radius,\n",
    "        noise=noise,\n",
    "        channels=channels,\n",
    "        val_steps=val_steps,\n",
    "        val_points=val_points,\n",
    "        reveal_dim=reveal_dim,\n",
    "        deterministic_mask_train=deterministic_mask,\n",
    "        jitter_std_train=jitter_std,\n",
    "        deterministic_mask_val=True,\n",
    "        jitter_std_val=0.0,\n",
    "        mixed=mixed,\n",
    "        future_delta=future_delta,\n",
    "    )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd80f0d",
   "metadata": {},
   "source": [
    "Mask Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d77bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the dataset\n",
    "val_data = MaskedDataset(\n",
    "    val_sims,\n",
    "    reveal_strategy=\"disks\",\n",
    "    n_points=16,\n",
    "    radius=5,\n",
    "    noise=0,\n",
    "    reveal_dim=[[(0,0.15),(0.85,1)],[(0,1)]],\n",
    "    return_mask=True,\n",
    "    jitter_std=0.01,\n",
    "    deterministic_mask=False\n",
    ")\n",
    "\n",
    "z, t, mask = val_data[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mask.numpy(), cmap=\"gray\")\n",
    "plt.title(\"Revealed-pixels mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
