{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b325813",
   "metadata": {},
   "source": [
    "Same code from PINN we have been working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Prevents crashes when showing graphs\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "SIM_STEPS = 200\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Determined train/test/val split\n",
    "train_sims = np.load(\"../train_sims.npy\")\n",
    "train_sims = train_sims[train_sims < 750]\n",
    "val_sims = np.load(\"../val_sims.npy\")\n",
    "val_sims = val_sims[val_sims < 750]\n",
    "test_sims = np.load(\"../test_sims.npy\")\n",
    "test_sims = test_sims[test_sims < 750]\n",
    "\n",
    "# Get porosity phi\n",
    "def get_phi(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_phi.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get pressure\n",
    "def get_pres(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_P.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get conductivity K\n",
    "def get_k(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_K.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get all 3 as a 3-channel matrix\n",
    "def get_all(sim,step):\n",
    "    return np.array((get_k(sim,step), get_pres(sim,step), get_phi(sim,step)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-define steps and points to maintain a consistent validation set\n",
    "val_steps = np.random.randint(1,199,(val_sims.shape[0],))\n",
    "val_points = np.random.randint(0,149,(val_sims.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6210558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darcy loss function\n",
    "def darcy_loss(model, inp):\n",
    "    # Takes in the k,pres,phi and outputs the prediction across the image.\n",
    "    inp = inp.requires_grad_(True)\n",
    "    out = model(inp)\n",
    "    # out is in order K,P,phi, (conductivity, pressure, porosity)\n",
    "\n",
    "    # Impose high pressure along the entire upper line by setting the pressure channelt to 200.\n",
    "    out[:, 1:2, 0, :] = 200\n",
    "\n",
    "    # If we assume the output is in order k,pres,phi\n",
    "    # pres_grad is the gradient of the pressure along the y and x directions as a tuple\n",
    "    pres_grad = torch.gradient(out[:, 1:2], dim=(-2,-1))\n",
    "\n",
    "    # get velocity by multiplying the gradient by the conductivity\n",
    "    y_grad = pres_grad[0] * out[:, 0:1]\n",
    "    x_grad = pres_grad[1] * out[:, 0:1]\n",
    "\n",
    "    # compute the divergence by the second derivative of the gradients and adding them together\n",
    "    yy_grad = torch.gradient(y_grad, spacing=(1,),dim=(-2,))[0]\n",
    "    xx_grad = torch.gradient(x_grad, spacing=(1,),dim=(-1,))[0]\n",
    "    final = yy_grad + xx_grad\n",
    "\n",
    "    # total divergence should be 0\n",
    "    loss = (final**2).mean()\n",
    "\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Blocks of the Unet\n",
    "\n",
    "class TwoConv(nn.Module):\n",
    "    # Basic block with 2 convolutional layers, each with a batch norm and relu\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, no_end_relu=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if no_end_relu:\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.seq(inp)\n",
    "\n",
    "# A single conv layer that will increase the height and width of the matrix by 2 each.\n",
    "class SmallUp(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "\n",
    "# A single conv layer that will decrease the height and width of the matrix by 2 each.\n",
    "class SmallDown(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 0)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "    \n",
    "# Applies two convolutional layers, then pools\n",
    "class Downsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = TwoConv(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        return self.pool(self.conv(inp))\n",
    "\n",
    "# Upsamples and concatenates the upsampled matrix with the \"across\" then performs convolution on the result\n",
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, tweak=None):\n",
    "        super().__init__()\n",
    "        # Upsamples by 2x\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)\n",
    "        self.tweak = tweak\n",
    "        self.conv_after = TwoConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, below, across):\n",
    "        # First upsample by 2x\n",
    "        upsampled = self.up(below)\n",
    "        # If tweak is active, apply it first\n",
    "        if not self.tweak == None:\n",
    "            upsampled = self.tweak(upsampled)\n",
    "        # Concatenate with the same size on the downswing of the unet\n",
    "        concat = torch.concat((upsampled, across), dim=-3)\n",
    "        # Convolute them together\n",
    "        return self.conv_after(concat)\n",
    "    \n",
    "# Define the actual model used\n",
    "class SmallUnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input is Nx3x200x200\n",
    "        self.c1 = TwoConv(3, 8)\n",
    "        self.d1 = Downsample(8,16) # 16x100x100\n",
    "        self.d2 = Downsample(16,32) # 32x50x50\n",
    "        self.su = nn.Sequential(\n",
    "            SmallUp(32),\n",
    "            SmallUp(32),\n",
    "            SmallUp(32)\n",
    "        ) # 3x56x56\n",
    "        self.d3 = Downsample(32,64) # 64x28x28\n",
    "        self.d4 = Downsample(64,128) # 128x14x14\n",
    "        self.d5 = Downsample(128, 256) # 256x7x7\n",
    "\n",
    "        # Now back up\n",
    "        self.u1 = Upsample(256, 128) # 128x14x14\n",
    "        self.u2 = Upsample(128, 64) # 64x28x28\n",
    "        self.u3 = Upsample(64, 32, tweak=nn.Sequential(\n",
    "            SmallDown(32),\n",
    "            SmallDown(32),\n",
    "            SmallDown(32)\n",
    "        ))  # 32x50x50\n",
    "        self.u4 = Upsample(32,16) # 16x100x100\n",
    "        self.u5 = Upsample(16,8) # 8x200x200\n",
    "        self.final = TwoConv(8, 3, no_end_relu=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Start with convolution, expand 3 channels to 8.\n",
    "        # Then downsample 5 times, saving the result\n",
    "        top = self.c1(input)\n",
    "        x1 = self.d1(top)\n",
    "        x2 = self.d2(x1)\n",
    "        x3 = self.d3(self.su(x2)) # Here we upsample slightly so that we can downsample with less border artifacts\n",
    "        x4 = self.d4(x3)\n",
    "        x5 = self.d5(x4)\n",
    "        # Now that we're at 256x7x7, we upsample from here.\n",
    "        # At each layer with concatenate with the xi that is the same size as the up after upsampling.\n",
    "        up = self.u1(x5, x4)\n",
    "        up = self.u2(up, x3)\n",
    "        up = self.u3(up, x2) # Again, a small downsample here to get back on the proper resolution\n",
    "        up = self.u4(up, x1)\n",
    "        up = self.u5(up, top)\n",
    "        # One last convolution on the result to return to 3 channels from 8, leaving us with the proper 3x200x200\n",
    "        return self.final(up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22876e85",
   "metadata": {},
   "source": [
    "# New Parameters \n",
    "**`return_mask`** : Used for visualizing mask. Check bottom of file for example\n",
    "\n",
    "**`reveal_dim`** : Two lists of tuples for y, x dimension. Marks areas for sensor points to appear\n",
    "\n",
    "**`jitter_std`** : pixel standard deviation for sensor points to move around\n",
    "\n",
    "**`deterministic_mask`** : If true, sensor points do not jitter\n",
    "\n",
    "**`future_delta`** : In progress, changes label from current time to current + delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e969716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 sims,\n",
    "                 unmask_size=20,\n",
    "                 points = None,\n",
    "                 block_size = 50,\n",
    "                 reveal_strategy = \"block\",\n",
    "                 n_points = 200,\n",
    "                 radius = 2,\n",
    "                 steps = None,\n",
    "                 H=200,\n",
    "                 W=200,\n",
    "                 channels=\"all\",\n",
    "                 mixed=False,\n",
    "                 types=None,\n",
    "                 noise=5,\n",
    "                 return_mask=False,                 # allows visualiztion of mask\n",
    "                 reveal_dim=[[(0, 1)], [(0, 1)]],   # x,y range for disks to exist\n",
    "                 jitter_std=0.0,                    # % each disk drifts from deterministic position\n",
    "                 deterministic_mask=True,            # if True, mask is deterministic and noise is 0\n",
    "                 future_delta=0\n",
    "                 ):\n",
    "        \n",
    "        self.sims = sims\n",
    "        self.points = points\n",
    "        self.steps = steps\n",
    "        self.size = unmask_size\n",
    "        self.reveal_strategy = reveal_strategy\n",
    "        self.block_size = block_size\n",
    "        self.n_points = n_points\n",
    "        self.radius = radius\n",
    "        self.H, self.W = H, W\n",
    "        self.channels = channels\n",
    "        self.mixed = mixed\n",
    "        self.types = types\n",
    "        self.noise = noise\n",
    "        self.return_mask = return_mask\n",
    "        self.reveal_dim = reveal_dim\n",
    "        self.jitter_std = jitter_std\n",
    "        self.deterministic_mask = deterministic_mask\n",
    "        self.future_delta = future_delta\n",
    "\n",
    "    def _chan_idx(self):\n",
    "        if self.channels == \"all\":\n",
    "            return [0,1,2]\n",
    "        elif self.channels == \"K\":\n",
    "            return [0]\n",
    "        elif self.channels == \"P\":\n",
    "            return [1]\n",
    "        elif self.channels == \"phi\":\n",
    "            return [2]\n",
    "        else:\n",
    "            raise ValueError(\"channels must be 'all', 'K', 'P', or 'phi'\")\n",
    "\n",
    "        \n",
    "        \n",
    "    # helper function used to turn segments (0, 1) into points on the H-W grid\n",
    "    def _segments_to_indices(self, segments, N, pad=0):\n",
    "        idxs = []\n",
    "        for a, b in segments:\n",
    "            # map fraction [0,1] to pixel indices [0, N-1]\n",
    "            i0 = max(pad, int(round(a * (N - 1))))\n",
    "            i1 = min((N - 1) - pad, int(round(b * (N - 1))))\n",
    "            if i1 >= i0:\n",
    "                idxs.append(torch.arange(i0, i1 + 1, dtype=torch.long))\n",
    "        if not idxs:\n",
    "            # full range if nothing provided\n",
    "            return torch.arange(pad, N - pad, dtype=torch.long)\n",
    "        return torch.unique(torch.cat(idxs)).to(torch.long)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # --- In Progress --- \n",
    "\n",
    "        #     # pick a valid step\n",
    "        # if not isinstance(self.steps, np.ndarray):\n",
    "        #     max_start = SIM_STEPS - 1 - self.future_delta  # ensures step + delta ≤ 199\n",
    "        #     step = np.random.randint(1, max_start + 1)  \n",
    "        # else:\n",
    "        #     step = int(self.steps[index])\n",
    "        #     max_start = SIM_STEPS - 1 - self.future_delta\n",
    "        #     if step > max_start:\n",
    "        #         step = max_start\n",
    "\n",
    "\n",
    "\n",
    "        if not type(self.steps) == np.ndarray:\n",
    "            step = np.random.randint(1,200)\n",
    "        else:\n",
    "            step = self.steps[index]\n",
    "\n",
    "        # Create tensor for the target\n",
    "        t_cur = torch.tensor(get_all(self.sims[index], step), dtype=torch.float32)\n",
    "\n",
    "        # Create 0 matrix\n",
    "        z = torch.zeros_like(t_cur)\n",
    "\n",
    "        # build a boolean mask of revealed pixels, shape (H,W)\n",
    "        mask = torch.zeros((self.H, self.W), dtype=torch.bool)\n",
    "\n",
    "        chans = self._chan_idx()\n",
    "\n",
    "        if self.reveal_strategy == \"block\":\n",
    "            # choose top-left for the block\n",
    "            if not type(self.points) == np.ndarray:\n",
    "                i0 = np.random.randint(0, self.H - self.block_size + 1)\n",
    "                j0 = np.random.randint(0, self.W - self.block_size + 1)\n",
    "            else:\n",
    "                i0, j0 = self.points[index]\n",
    "                i0 = max(0, min(i0, self.H - self.block_size))\n",
    "                j0 = max(0, min(j0, self.W - self.block_size))\n",
    "            mask[i0:i0+self.block_size, j0:j0+self.block_size] = True\n",
    "\n",
    "        elif self.reveal_strategy == \"disks\":\n",
    "            row_fracs = self.reveal_dim[0] # e.g, [(0, 1)]\n",
    "            col_fracs = self.reveal_dim[1]\n",
    "\n",
    "            row_allowed = self._segments_to_indices(row_fracs, self.H, pad=self.radius)\n",
    "            col_allowed = self._segments_to_indices(col_fracs, self.W, pad=self.radius)\n",
    "\n",
    "            # choose grid shape close to aspect ratio\n",
    "            # works with non-squares\n",
    "            Hspan = (row_allowed[-1] - row_allowed[0] + 1) if len(row_allowed) > 0 else self.H\n",
    "            Wspan = (col_allowed[-1] - col_allowed[0] + 1) if len(col_allowed) > 0 else self.W\n",
    "            ratio = float(Wspan) / max(1.0, float(Hspan))\n",
    "\n",
    "            ny = int(max(1, round(np.sqrt(self.n_points / max(1e-8, ratio)))))\n",
    "            nx = int(max(1, round(self.n_points / ny)))\n",
    "\n",
    "\n",
    "            while nx * ny < self.n_points:\n",
    "                nx += 1\n",
    "\n",
    "            # pick evenly spaced indices from rows/cols allowed\n",
    "            def pick_lin_indices(allowed, k):\n",
    "                if k <= 1:\n",
    "                    return allowed[len(allowed)//2]\n",
    "                pos = torch.linspace(0, len(allowed)-1, steps=k)\n",
    "                idx = torch.round(pos).long()\n",
    "                return allowed[idx]\n",
    "            \n",
    "            row_picks = pick_lin_indices(row_allowed, ny)\n",
    "            col_picks = pick_lin_indices(col_allowed, nx)\n",
    "\n",
    "\n",
    "            yy, xx = torch.meshgrid(row_picks, col_picks, indexing=\"ij\")\n",
    "            points = torch.stack([yy.reshape(-1), xx.reshape(-1)], dim=1) # (ny*nx, 2)\n",
    "            \n",
    "            # if more than n_points, subselect\n",
    "            if points.shape[0] > self.n_points:\n",
    "                sel_pos = torch.linspace(0, points.shape[0]-1, steps=self.n_points)\n",
    "                sel_idx = torch.round(sel_pos).long()\n",
    "                points = points[sel_idx]\n",
    "\n",
    "            ii = points[:, 0]\n",
    "            jj = points[:, 1]\n",
    "\n",
    "\n",
    "            yy, xx = torch.meshgrid(torch.arange(self.H), torch.arange(self.W), indexing=\"ij\")\n",
    "            for y0, x0 in zip(ii, jj):\n",
    "                disk = (yy - int(y0))**2 + (xx - int(x0))**2 <= (self.radius**2)\n",
    "                mask |= disk\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reveal_strategy: {self.reveal_strategy}\")\n",
    "        \n",
    "\n",
    "        obs = t_cur[chans].clone()\n",
    "        # Add noise (0 - 255 scale)\n",
    "        if self.noise is not None and self.noise > 0:\n",
    "            sigma = float(self.noise)\n",
    "            obs = obs + sigma * torch.randn_like(obs)\n",
    "            obs.clamp_(0.0, 255.0)\n",
    "\n",
    "\n",
    "        z[chans, :, :] = torch.where(mask, obs, torch.zeros_like(obs))\n",
    "\n",
    "\n",
    "\n",
    "        # --- In Progress --- \n",
    "\n",
    "        # if self.future_delta > 0:\n",
    "        #     step_f = step + self.future_delta   \n",
    "        #     t_label = torch.tensor(get_all(self.sims[index], step_f), dtype=torch.float32)\n",
    "        # else:\n",
    "        #     t_label = t_cur\n",
    "\n",
    "        t_label = t_cur\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if self.return_mask:\n",
    "            return z,t_label, mask\n",
    "        else:  \n",
    "            return z,t_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sims.shape[0]\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(MaskedDataset(train_sims,\n",
    "                                                         reveal_strategy=\"disks\",\n",
    "                                                         n_points=12,\n",
    "                                                         radius=5,\n",
    "                                                         mixed=True),\n",
    "                                                         batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ed2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, optim, schedule, crit, epochs=250, name = \"test\"):\n",
    "    # train loss values, losses is total darcy is only darcy\n",
    "    losses, darcy = [], []\n",
    "    # similar for validation\n",
    "    val_loss, val_darcy = [], []\n",
    "\n",
    "    for e in tqdm(range(epochs)):\n",
    "        epoch_loss = 0\n",
    "        epoch_darcy = 0\n",
    "        for feat,label in train_loader:\n",
    "            optim.zero_grad()\n",
    "            feat = feat.to(device)\n",
    "            label = label.to(device)\n",
    "            # Process darcy loss and save it\n",
    "            p_loss, out = darcy_loss(model, feat)\n",
    "            epoch_darcy += p_loss.item()\n",
    "            # Calculate total loss\n",
    "            loss = p_loss + crit(out, label)\n",
    "            epoch_loss += loss.item()\n",
    "            # Perform backward step\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        # Track loss\n",
    "        epoch_loss /= train_loader.__len__()\n",
    "        epoch_darcy /= train_loader.__len__()\n",
    "        losses.append(epoch_loss)\n",
    "        darcy.append(epoch_darcy)\n",
    "\n",
    "        schedule.step()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_darcy = 0\n",
    "        with torch.no_grad():\n",
    "            for feat,label in val_loader:\n",
    "\n",
    "                feat = feat.to(device)\n",
    "                label = label.to(device)\n",
    "                p_loss, out = darcy_loss(model, feat)\n",
    "                epoch_darcy += p_loss.item()\n",
    "                loss = p_loss + crit(out, label)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "        epoch_loss /= val_loader.__len__()\n",
    "        epoch_darcy /= val_loader.__len__()\n",
    "        val_loss.append(epoch_loss)\n",
    "        val_darcy.append(epoch_darcy)\n",
    "\n",
    "    torch.save(model, f\"{name}.pt\")\n",
    "\n",
    "\n",
    "    \n",
    "    # saving \"curves_{name}.npz\"\n",
    "    np.savez(\n",
    "    f\"curves_{name}.npz\",\n",
    "    train_total=np.array(losses),\n",
    "    train_darcy=np.array(darcy),\n",
    "    val_total=np.array(val_loss),\n",
    "    val_darcy=np.array(val_darcy)\n",
    "    )\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"train_total\": losses,\n",
    "        \"train_darcy\": darcy,\n",
    "        \"val_total\": val_loss,\n",
    "        \"val_darcy\": val_darcy,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a124114",
   "metadata": {},
   "source": [
    "NEW:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7eb2f5",
   "metadata": {},
   "source": [
    "Here you can add tests to run, each one takes a whole train test cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    # Short-term prediction (1-step ahead)\n",
    "    {\"name\":\"delta_1_short\",\n",
    "     \"reveal_strategy\":\"disks\", \"n_points\":16, \"radius\":5,\n",
    "     \"mixed\":True, \"noise\":5,\n",
    "     \"deterministic_mask\":False, \"jitter_std\":0.02,\n",
    "     \"future_delta\":1},\n",
    "\n",
    "    # Medium-term (5 steps ahead)\n",
    "    {\"name\":\"delta_5_medium\",\n",
    "     \"reveal_strategy\":\"disks\", \"n_points\":16, \"radius\":5,\n",
    "     \"mixed\":True, \"noise\":5,\n",
    "     \"deterministic_mask\":False, \"jitter_std\":0.02,\n",
    "     \"future_delta\":5},\n",
    "\n",
    "    # Long-term (10 steps ahead)\n",
    "    {\"name\":\"delta_10_long\",\n",
    "     \"reveal_strategy\":\"disks\", \"n_points\":16, \"radius\":5,\n",
    "     \"mixed\":True, \"noise\":5,\n",
    "     \"deterministic_mask\":False, \"jitter_std\":0.02,\n",
    "     \"future_delta\":10},\n",
    "\n",
    "    # Very long-term (20 steps ahead)\n",
    "    {\"name\":\"delta_20_verylong\",\n",
    "     \"reveal_strategy\":\"disks\", \"n_points\":16, \"radius\":5,\n",
    "     \"mixed\":True, \"noise\":5,\n",
    "     \"deterministic_mask\":False, \"jitter_std\":0.02,\n",
    "     \"future_delta\":20},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3e6b6",
   "metadata": {},
   "source": [
    "Trains each configuration listed in `{tests}` one at a time.  \n",
    "For every model trained, these files are saved:\n",
    "- **`curves_{name}.npz`** – training and validation loss curves  \n",
    "- **`disks_{name}.pt`** – trained model weights  \n",
    "- **`meta_{name}.npz`** – run metadata (setup, noise)\n",
    "\n",
    "These outputs are used for evaluation and comparison in **`plot.ipynb`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31aa1e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [04:48<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m crit = nn.MSELoss()\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# --- train (your train() already saves curves_{name}.npz and {name}.pt) ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m hist = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m results[config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]] = {\u001b[33m\"\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m\"\u001b[39m: hist, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model.state_dict()}\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# --- save meta so the plotting notebook can reconstruct val_data exactly ---\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_loader, val_loader, model, optim, schedule, crit, epochs, name)\u001b[39m\n\u001b[32m     19\u001b[39m     epoch_loss += loss.item()\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# Perform backward step\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     optim.step()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Track loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for config in tests:\n",
    "    deterministic_mask = config.get(\"deterministic_mask\", False)   # allow jitter by default\n",
    "    jitter_std         = float(config.get(\"jitter_std\", 0.02))     # 2% jitter\n",
    "    reveal_dim         = config.get(\"reveal_dim\", [[(0,1)], [(0,1)]])\n",
    "    channels           = config.get(\"channels\", \"all\")\n",
    "    mixed              = bool(config.get(\"mixed\", True))\n",
    "    future_delta       = int(config.get(\"future_delta\", 0))\n",
    "\n",
    "    # --- TRAIN dataset/loader ---\n",
    "    train_data = MaskedDataset(\n",
    "        train_sims,\n",
    "        reveal_strategy=config[\"reveal_strategy\"],\n",
    "        n_points=config[\"n_points\"],\n",
    "        radius=config[\"radius\"],\n",
    "        mixed=mixed,                      \n",
    "        noise=config[\"noise\"],\n",
    "        channels=channels,\n",
    "        reveal_dim=reveal_dim,\n",
    "        deterministic_mask=deterministic_mask,\n",
    "        jitter_std=jitter_std,\n",
    "        future_delta=future_delta\n",
    "        \n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "\n",
    "    # --- VAL dataset/loader (deterministic) ---\n",
    "    val_data = MaskedDataset(\n",
    "        val_sims,\n",
    "        reveal_strategy=config[\"reveal_strategy\"],\n",
    "        n_points=config[\"n_points\"],\n",
    "        radius=config[\"radius\"],\n",
    "        mixed=mixed,\n",
    "        noise=config[\"noise\"],\n",
    "        channels=channels,\n",
    "        points=val_points,\n",
    "        steps=val_steps,\n",
    "        reveal_dim=reveal_dim,\n",
    "        deterministic_mask=True,            \n",
    "        jitter_std=0.0,                       \n",
    "        future_delta=future_delta\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)\n",
    "\n",
    "    # --- model/optim ---\n",
    "    model = SmallUnet().to(device)\n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "    schedule = torch.optim.lr_scheduler.ExponentialLR(optim, 0.99)\n",
    "    crit = nn.MSELoss()\n",
    "\n",
    "    # --- train ---\n",
    "    hist = train(train_loader, val_loader, model, optim, schedule, crit, epochs=250, name=config[\"name\"])\n",
    "    results[config[\"name\"]] = {\"hist\": hist, \"model\": model.state_dict()}\n",
    "\n",
    "    # --- save meta so plotting notebook can reconstruct val_data ---\n",
    "    np.savez(\n",
    "        f\"meta_{config['name']}.npz\",\n",
    "        reveal_strategy=np.array(config[\"reveal_strategy\"]),\n",
    "        n_points=np.array(config[\"n_points\"]),\n",
    "        radius=np.array(config[\"radius\"]),\n",
    "        noise=np.array(config[\"noise\"]),\n",
    "        channels=np.array(channels),\n",
    "\n",
    "        val_steps=val_steps,\n",
    "        val_points=val_points,\n",
    "\n",
    "        reveal_dim=np.array(reveal_dim, dtype=object),\n",
    "        deterministic_mask_train=np.array(deterministic_mask),\n",
    "        jitter_std_train=np.array(jitter_std),\n",
    "        deterministic_mask_val=np.array(True),\n",
    "        jitter_std_val=np.array(0.0),\n",
    "        mixed=np.array(mixed),\n",
    "        future_delta=future_delta\n",
    "    )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd80f0d",
   "metadata": {},
   "source": [
    "Mask Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e22d77bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the dataset\n",
    "val_data = MaskedDataset(\n",
    "    val_sims,\n",
    "    reveal_strategy=\"disks\",\n",
    "    n_points=16,\n",
    "    radius=5,\n",
    "    noise=0,\n",
    "    reveal_dim=[[(0,0.15),(0.85,1)],[(0,1)]],\n",
    "    return_mask=True,\n",
    ")\n",
    "\n",
    "z, t, mask = val_data[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mask.numpy(), cmap=\"gray\")\n",
    "plt.title(\"Revealed-pixels mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
