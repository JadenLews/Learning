{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b325813",
   "metadata": {},
   "source": [
    "Same code from PINN we have been working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bf807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Prevents crashes when showing graphs\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "SIM_STEPS = 201\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Determined train/test/val split\n",
    "train_sims = np.load(\"../train_sims.npy\")\n",
    "train_sims = train_sims[train_sims < 750]\n",
    "val_sims = np.load(\"../val_sims.npy\")\n",
    "val_sims = val_sims[val_sims < 750]\n",
    "test_sims = np.load(\"../test_sims.npy\")\n",
    "test_sims = test_sims[test_sims < 750]\n",
    "\n",
    "# Get porosity phi\n",
    "def get_phi(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_phi.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get pressure\n",
    "def get_pres(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_P.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get conductivity K\n",
    "def get_k(sim,step):\n",
    "    return cv2.imread(f\"../Data200x200_withinfo/Image-{sim}-{step}_K.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get all 3 as a 3-channel matrix\n",
    "def get_all(sim,step):\n",
    "    return np.array((get_k(sim,step), get_pres(sim,step), get_phi(sim,step)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6210558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darcy loss function\n",
    "def darcy_loss(model, inp):\n",
    "    # Takes in the k,pres,phi and outputs the prediction across the image.\n",
    "    inp = inp.requires_grad_(True)\n",
    "    out = model(inp)\n",
    "    # out is in order K,P,phi, (conductivity, pressure, porosity)\n",
    "\n",
    "    # Impose high pressure along the entire upper line by setting the pressure channelt to 200.\n",
    "    out[:, 1:2, 0, :] = 200\n",
    "\n",
    "    # If we assume the output is in order k,pres,phi\n",
    "    # pres_grad is the gradient of the pressure along the y and x directions as a tuple\n",
    "    pres_grad = torch.gradient(out[:, 1:2], dim=(-2,-1))\n",
    "\n",
    "    # get velocity by multiplying the gradient by the conductivity\n",
    "    y_grad = pres_grad[0] * out[:, 0:1]\n",
    "    x_grad = pres_grad[1] * out[:, 0:1]\n",
    "\n",
    "    # compute the divergence by the second derivative of the gradients and adding them together\n",
    "    yy_grad = torch.gradient(y_grad, spacing=(1,),dim=(-2,))[0]\n",
    "    xx_grad = torch.gradient(x_grad, spacing=(1,),dim=(-1,))[0]\n",
    "    final = yy_grad + xx_grad\n",
    "\n",
    "    # total divergence should be 0\n",
    "    loss = (final**2).mean()\n",
    "\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Blocks of the Unet\n",
    "\n",
    "class TwoConv(nn.Module):\n",
    "    # Basic block with 2 convolutional layers, each with a batch norm and relu\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, no_end_relu=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if no_end_relu:\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.seq(inp)\n",
    "\n",
    "# A single conv layer that will increase the height and width of the matrix by 2 each.\n",
    "class SmallUp(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "\n",
    "# A single conv layer that will decrease the height and width of the matrix by 2 each.\n",
    "class SmallDown(nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 0)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return F.relu(self.conv(inp))\n",
    "    \n",
    "# Applies two convolutional layers, then pools\n",
    "class Downsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = TwoConv(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        return self.pool(self.conv(inp))\n",
    "\n",
    "# Upsamples and concatenates the upsampled matrix with the \"across\" then performs convolution on the result\n",
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, tweak=None):\n",
    "        super().__init__()\n",
    "        # Upsamples by 2x\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)\n",
    "        self.tweak = tweak\n",
    "        self.conv_after = TwoConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, below, across):\n",
    "        # First upsample by 2x\n",
    "        upsampled = self.up(below)\n",
    "        # If tweak is active, apply it first\n",
    "        if not self.tweak == None:\n",
    "            upsampled = self.tweak(upsampled)\n",
    "        # Concatenate with the same size on the downswing of the unet\n",
    "        concat = torch.concat((upsampled, across), dim=-3)\n",
    "        # Convolute them together\n",
    "        return self.conv_after(concat)\n",
    "    \n",
    "# Define the actual model used\n",
    "class SmallUnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input is Nx3x200x200\n",
    "        self.c1 = TwoConv(3, 8)\n",
    "        self.d1 = Downsample(8,16) # 16x100x100\n",
    "        self.d2 = Downsample(16,32) # 32x50x50\n",
    "        self.su = nn.Sequential(\n",
    "            SmallUp(32),\n",
    "            SmallUp(32),\n",
    "            SmallUp(32)\n",
    "        ) # 3x56x56\n",
    "        self.d3 = Downsample(32,64) # 64x28x28\n",
    "        self.d4 = Downsample(64,128) # 128x14x14\n",
    "        self.d5 = Downsample(128, 256) # 256x7x7\n",
    "\n",
    "        # Now back up\n",
    "        self.u1 = Upsample(256, 128) # 128x14x14\n",
    "        self.u2 = Upsample(128, 64) # 64x28x28\n",
    "        self.u3 = Upsample(64, 32, tweak=nn.Sequential(\n",
    "            SmallDown(32),\n",
    "            SmallDown(32),\n",
    "            SmallDown(32)\n",
    "        ))  # 32x50x50\n",
    "        self.u4 = Upsample(32,16) # 16x100x100\n",
    "        self.u5 = Upsample(16,8) # 8x200x200\n",
    "        self.final = TwoConv(8, 3, no_end_relu=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Start with convolution, expand 3 channels to 8.\n",
    "        # Then downsample 5 times, saving the result\n",
    "        top = self.c1(input)\n",
    "        x1 = self.d1(top)\n",
    "        x2 = self.d2(x1)\n",
    "        x3 = self.d3(self.su(x2)) # Here we upsample slightly so that we can downsample with less border artifacts\n",
    "        x4 = self.d4(x3)\n",
    "        x5 = self.d5(x4)\n",
    "        # Now that we're at 256x7x7, we upsample from here.\n",
    "        # At each layer with concatenate with the xi that is the same size as the up after upsampling.\n",
    "        up = self.u1(x5, x4)\n",
    "        up = self.u2(up, x3)\n",
    "        up = self.u3(up, x2) # Again, a small downsample here to get back on the proper resolution\n",
    "        up = self.u4(up, x1)\n",
    "        up = self.u5(up, top)\n",
    "        # One last convolution on the result to return to 3 channels from 8, leaving us with the proper 3x200x200\n",
    "        return self.final(up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22876e85",
   "metadata": {},
   "source": [
    "# New Parameters \n",
    "**`return_mask`** : Used for visualizing mask. Check bottom of file for example\n",
    "\n",
    "**`reveal_dim`** : Two lists of tuples for y, x dimension. Marks areas for sensor points to appear\n",
    "\n",
    "**`jitter_std`** : pixel standard deviation for sensor points to move around\n",
    "\n",
    "**`deterministic_mask`** : If true, sensor points do not jitter\n",
    "\n",
    "**`future_delta`** : In progress, changes label from current time to current + delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e969716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 sims,\n",
    "                 unmask_size=20,\n",
    "                 points = None,\n",
    "                 block_size = 50,\n",
    "                 reveal_strategy = \"block\",\n",
    "                 n_points = 200,\n",
    "                 radius = 2,\n",
    "                 steps = None,\n",
    "                 H=200,\n",
    "                 W=200,\n",
    "                 channels=\"all\",\n",
    "                 mixed=False,\n",
    "                 types=None,\n",
    "                 noise=5,\n",
    "                 return_mask=False,                 # allows visualiztion of mask\n",
    "                 reveal_dim=[[(0, 1)], [(0, 1)]],   # x,y range for disks to exist\n",
    "                 jitter_std=0.0,                    # % each disk drifts from deterministic position\n",
    "                 deterministic_mask=True,            # if True, mask is deterministic and noise is 0\n",
    "                 future_delta=0\n",
    "                 ):\n",
    "        \n",
    "        self.sims = sims\n",
    "        self.points = points\n",
    "        self.steps = steps\n",
    "        self.size = unmask_size\n",
    "        self.reveal_strategy = reveal_strategy\n",
    "        self.block_size = block_size\n",
    "        self.n_points = n_points\n",
    "        self.radius = radius\n",
    "        self.H, self.W = H, W\n",
    "        self.channels = channels\n",
    "        self.mixed = mixed\n",
    "        self.types = types\n",
    "        self.noise = noise\n",
    "        self.return_mask = return_mask\n",
    "        self.reveal_dim = reveal_dim\n",
    "        self.jitter_std = jitter_std\n",
    "        self.deterministic_mask = deterministic_mask\n",
    "        self.future_delta = future_delta\n",
    "\n",
    "    def _chan_idx(self):\n",
    "        if self.channels == \"all\":\n",
    "            return [0,1,2]\n",
    "        elif self.channels == \"K\":\n",
    "            return [0]\n",
    "        elif self.channels == \"P\":\n",
    "            return [1]\n",
    "        elif self.channels == \"phi\":\n",
    "            return [2]\n",
    "        else:\n",
    "            raise ValueError(\"channels must be 'all', 'K', 'P', or 'phi'\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # --- In Progress --- \n",
    "\n",
    "            # pick a valid step\n",
    "        if not isinstance(self.steps, np.ndarray):\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta  # ensures step + delta ≤ 199\n",
    "            step = np.random.randint(1, max_start + 1)  \n",
    "        else:\n",
    "            step = int(self.steps[index])\n",
    "            max_start = SIM_STEPS - 1 - self.future_delta\n",
    "            if step > max_start:\n",
    "                step = max_start\n",
    "\n",
    "\n",
    "\n",
    "        # if not type(self.steps) == np.ndarray:\n",
    "        #     step = np.random.randint(1,200)\n",
    "        # else:\n",
    "        #     step = self.steps[index]\n",
    "\n",
    "\n",
    "\n",
    "        # Create tensor for the target\n",
    "        t_cur = torch.tensor(get_all(self.sims[index], step), dtype=torch.float32)\n",
    "\n",
    "        # Create 0 matrix\n",
    "        z = torch.zeros_like(t_cur)\n",
    "\n",
    "        # build a boolean mask of revealed pixels, shape (H,W)\n",
    "        mask = torch.zeros((self.H, self.W), dtype=torch.bool)\n",
    "\n",
    "        chans = self._chan_idx()\n",
    "\n",
    "        if self.reveal_strategy == \"block\":\n",
    "            # choose top-left for the block\n",
    "            if not type(self.points) == np.ndarray:\n",
    "                i0 = np.random.randint(0, self.H - self.block_size + 1)\n",
    "                j0 = np.random.randint(0, self.W - self.block_size + 1)\n",
    "            else:\n",
    "                i0, j0 = self.points[index]\n",
    "                i0 = max(0, min(i0, self.H - self.block_size))\n",
    "                j0 = max(0, min(j0, self.W - self.block_size))\n",
    "            mask[i0:i0+self.block_size, j0:j0+self.block_size] = True\n",
    "\n",
    "        elif self.reveal_strategy == \"disks\":\n",
    "\n",
    "            # used for reveal_dim\n",
    "            # map fraction [0,1] to pixel indices [0, N-1] in mask layer\n",
    "            def _segments_to_indices(segments, N, pad=0):\n",
    "                idxs = []\n",
    "                for a, b in segments:\n",
    "                    i0 = max(pad, int(round(a * (N - 1))))\n",
    "                    i1 = min((N - 1) - pad, int(round(b * (N - 1))))\n",
    "                    if i1 >= i0:\n",
    "                        idxs.append(torch.arange(i0, i1 + 1, dtype=torch.long))\n",
    "                if not idxs:\n",
    "                    # fallback to full range\n",
    "                    return torch.arange(pad, N - pad, dtype=torch.long)\n",
    "                return torch.unique(torch.cat(idxs)).to(torch.long)\n",
    "\n",
    "            row_fracs = self.reveal_dim[0] # e.g, [(0, 1)]\n",
    "            col_fracs = self.reveal_dim[1] # e.g, [(0, 1)]\n",
    "            row_allowed = _segments_to_indices(row_fracs, self.H, pad=self.radius)\n",
    "            col_allowed = _segments_to_indices(col_fracs, self.W, pad=self.radius)\n",
    "\n",
    "            # choose grid shape close to aspect ratio \n",
    "            # works with non-squares\n",
    "            Hspan = (row_allowed[-1] - row_allowed[0] + 1) if len(row_allowed) > 0 else self.H\n",
    "            Wspan = (col_allowed[-1] - col_allowed[0] + 1) if len(col_allowed) > 0 else self.W\n",
    "            ratio = float(Wspan) / max(1.0, float(Hspan))\n",
    "            ny = int(max(1, round(np.sqrt(self.n_points / max(1e-8, ratio)))))\n",
    "            nx = int(max(1, round(self.n_points / ny)))\n",
    "            while nx * ny < self.n_points:\n",
    "                nx += 1\n",
    "\n",
    "            # pick evenly spaced indices from rows/cols allowed\n",
    "            def pick_lin_indices(allowed, k):\n",
    "                if k <= 1:\n",
    "                    return allowed[len(allowed)//2]\n",
    "                pos = torch.linspace(0, len(allowed)-1, steps=k)\n",
    "                idx = torch.round(pos).long()\n",
    "                return allowed[idx]\n",
    "            \n",
    "            \n",
    "            row_picks = pick_lin_indices(row_allowed, ny)\n",
    "            col_picks = pick_lin_indices(col_allowed, nx)\n",
    "            yy, xx = torch.meshgrid(row_picks, col_picks, indexing=\"ij\")\n",
    "            points = torch.stack([yy.reshape(-1), xx.reshape(-1)], dim=1) # (ny*nx, 2)\n",
    "            \n",
    "            # if more than n_points, subselect\n",
    "            if points.shape[0] > self.n_points:\n",
    "                sel_pos = torch.linspace(0, points.shape[0]-1, steps=self.n_points)\n",
    "                sel_idx = torch.round(sel_pos).long()\n",
    "                points = points[sel_idx]\n",
    "\n",
    "            ii = points[:, 0]\n",
    "            jj = points[:, 1]\n",
    "\n",
    "            if not self.deterministic_mask:\n",
    "                if self.jitter_std is not None and self.jitter_std > 0:\n",
    "                    # convert std (like 0.01 of image size) to pixels\n",
    "                    sigmaH = float(self.jitter_std) * self.H\n",
    "                    sigmaW = float(self.jitter_std) * self.W\n",
    "                    \n",
    "                    # Add Gaussian noise in pixel units\n",
    "                    ii = ii.to(torch.float32) + torch.randn_like(ii, dtype=torch.float32) * sigmaH\n",
    "                    jj = jj.to(torch.float32) + torch.randn_like(jj, dtype=torch.float32) * sigmaW\n",
    "\n",
    "                    # Round and clamp so they stay inside bounds\n",
    "                    ii = ii.round().clamp(self.radius, self.H - 1 - self.radius).to(torch.long)\n",
    "                    jj = jj.round().clamp(self.radius, self.W - 1 - self.radius).to(torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            yy, xx = torch.meshgrid(torch.arange(self.H), torch.arange(self.W), indexing=\"ij\")\n",
    "            for y0, x0 in zip(ii, jj):\n",
    "                disk = (yy - int(y0))**2 + (xx - int(x0))**2 <= (self.radius**2)\n",
    "                mask |= disk\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown reveal_strategy: {self.reveal_strategy}\")\n",
    "        \n",
    "\n",
    "        obs = t_cur[chans].clone()\n",
    "        # Add noise (0 - 255 scale)\n",
    "        if self.noise is not None and self.noise > 0:\n",
    "            sigma = float(self.noise)\n",
    "            obs = obs + sigma * torch.randn_like(obs)\n",
    "            obs.clamp_(0.0, 255.0)\n",
    "\n",
    "\n",
    "        z[chans, :, :] = torch.where(mask, obs, torch.zeros_like(obs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- In Progress --- \n",
    "\n",
    "        if self.future_delta > 0:\n",
    "            step_f = step + self.future_delta   \n",
    "            t_label = torch.tensor(get_all(self.sims[index], step_f), dtype=torch.float32)\n",
    "        else:\n",
    "            t_label = t_cur.clone()\n",
    "\n",
    "\n",
    "\n",
    "        if self.return_mask:\n",
    "            return z,t_label, mask\n",
    "        else:  \n",
    "            return z,t_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sims.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4966ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_meta(name, **kwargs):\n",
    "    \"\"\"\n",
    "    Saves meta info so you can reconstruct the exact val dataset later.\n",
    "    Usage:\n",
    "        save_meta(\n",
    "            name,\n",
    "            reveal_strategy=reveal_strategy, n_points=n_points, radius=radius,\n",
    "            noise=noise, channels=channels, val_steps=val_steps, val_points=val_points,\n",
    "            reveal_dim=reveal_dim, deterministic_mask_train=deterministic_mask,\n",
    "            jitter_std_train=jitter_std, deterministic_mask_val=True, jitter_std_val=0.0,\n",
    "            mixed=mixed, future_delta=future_delta\n",
    "        )\n",
    "    \"\"\"\n",
    "    # sanitize and cast\n",
    "    arr = {}\n",
    "    for k, v in kwargs.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if k in {\"reveal_dim\"}:\n",
    "            arr[k] = np.array(v, dtype=object)         # keep nested structure\n",
    "        elif isinstance(v, (list, tuple)) and k not in {\"val_steps\", \"val_points\"}:\n",
    "            arr[k] = np.array(v)\n",
    "        else:\n",
    "            arr[k] = v\n",
    "\n",
    "    np.savez(f\"meta_{name}.npz\", **arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0ed2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model,\n",
    "    optim,\n",
    "    schedule=None,\n",
    "    crit=nn.MSELoss(),\n",
    "    epochs=250,\n",
    "    name=\"run\",\n",
    "    save_model=True,\n",
    "    save_curves=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains model with Darcy loss + supervised loss.\n",
    "    Returns a dict of learning curves; optionally saves model and curves.\n",
    "\n",
    "    Curves:\n",
    "      - train_total, train_darcy\n",
    "      - val_total,   val_darcy\n",
    "    \"\"\"\n",
    "    # Histories\n",
    "    train_total_hist, train_darcy_hist = [], []\n",
    "    val_total_hist,   val_darcy_hist   = [], []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=f\"Training {name}\"):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        tot_loss_sum, darcy_loss_sum, n_train = 0.0, 0.0, 0\n",
    "\n",
    "        for feat, label in train_loader:\n",
    "            feat  = feat.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            p_loss, out = darcy_loss(model, feat)\n",
    "            s_loss      = crit(out, label)\n",
    "            loss        = p_loss + s_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            # accumulate\n",
    "            bs = feat.size(0)\n",
    "            n_train         += bs\n",
    "            tot_loss_sum    += loss.item()  * bs\n",
    "            darcy_loss_sum  += p_loss.item() * bs\n",
    "\n",
    "        train_total = tot_loss_sum   / max(1, n_train)\n",
    "        train_darcy = darcy_loss_sum / max(1, n_train)\n",
    "        train_total_hist.append(train_total)\n",
    "        train_darcy_hist.append(train_darcy)\n",
    "\n",
    "        if schedule is not None:\n",
    "            schedule.step()\n",
    "\n",
    "        # ---- VALIDATE ----\n",
    "        model.eval()\n",
    "        tot_loss_sum, darcy_loss_sum, n_val = 0.0, 0.0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for feat, label in val_loader:\n",
    "                feat  = feat.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                p_loss, out = darcy_loss(model, feat)\n",
    "                s_loss      = crit(out, label)\n",
    "                loss        = p_loss + s_loss\n",
    "\n",
    "                bs = feat.size(0)\n",
    "                n_val         += bs\n",
    "                tot_loss_sum  += loss.item()  * bs\n",
    "                darcy_loss_sum+= p_loss.item() * bs\n",
    "\n",
    "        val_total = tot_loss_sum   / max(1, n_val)\n",
    "        val_darcy = darcy_loss_sum / max(1, n_val)\n",
    "        val_total_hist.append(val_total)\n",
    "        val_darcy_hist.append(val_darcy)\n",
    "\n",
    "    # ---- SAVE ARTIFACTS ----\n",
    "    if save_model:\n",
    "        torch.save(model, f\"{name}.pt\")\n",
    "\n",
    "    if save_curves:\n",
    "        np.savez(\n",
    "            f\"curves_{name}.npz\",\n",
    "            train_total=np.array(train_total_hist, dtype=np.float32),\n",
    "            train_darcy=np.array(train_darcy_hist, dtype=np.float32),\n",
    "            val_total=np.array(val_total_hist, dtype=np.float32),\n",
    "            val_darcy=np.array(val_darcy_hist, dtype=np.float32),\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"train_total\": train_total_hist,\n",
    "        \"train_darcy\": train_darcy_hist,\n",
    "        \"val_total\":   val_total_hist,\n",
    "        \"val_darcy\":   val_darcy_hist,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a124114",
   "metadata": {},
   "source": [
    "NEW:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7eb2f5",
   "metadata": {},
   "source": [
    "Here you can add tests to run, each one takes a whole train test cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c5a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    # ---------- FULL FIELD REVEAL (for comparison) ----------\n",
    "    {\n",
    "        \"name\": \"full_d1_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.0, 1.0)], [(0.0, 1.0)]],  # rows: all, cols: all\n",
    "        \"future_delta\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"full_d5_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.0, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"full_d10_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.0, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"full_d20_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.0, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 20,\n",
    "    },\n",
    "\n",
    "    # ---------- STRIP MASK (hide top 15% in K/P/phi) ----------\n",
    "    # rows ∈ [0.15, 1.0], cols ∈ [0, 1.0]\n",
    "    {\n",
    "        \"name\": \"strip_d1_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"strip_d5_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"strip_d10_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"strip_d20_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 20,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "tests += [\n",
    "    # ---------- FULL FIELD REVEAL (for comparison) ----------\n",
    "    {\n",
    "        \"name\": \"full_d1_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.0, 1.0)], [(0.0, 1.0)]],  # rows: all, cols: all\n",
    "        \"future_delta\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"full_d5_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.0, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"full_d10_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.0, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"full_d20_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.0, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 20,\n",
    "    },\n",
    "\n",
    "    # ---------- STRIP MASK (hide top 15% in K/P/phi) ----------\n",
    "    # rows ∈ [0.15, 1.0], cols ∈ [0, 1.0]\n",
    "    {\n",
    "        \"name\": \"strip_d1_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"strip_d5_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"strip_d10_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"strip_d20_n16\",\n",
    "        \"reveal_strategy\": \"disks\",\n",
    "        \"n_points\": 16,\n",
    "        \"radius\": 5,\n",
    "        \"mixed\": True,\n",
    "        \"noise\": 5,\n",
    "        \"deterministic_mask\": False,\n",
    "        \"jitter_std\": 0.02,\n",
    "        \"reveal_dim\": [[(0.15, 1.0)], [(0.0, 1.0)]],\n",
    "        \"future_delta\": 20,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3e6b6",
   "metadata": {},
   "source": [
    "Trains each configuration listed in `{tests}` one at a time.  \n",
    "For every model trained, these files are saved:\n",
    "- **`curves_{name}.npz`** – training and validation loss curves  \n",
    "- **`disks_{name}.pt`** – trained model weights  \n",
    "- **`meta_{name}.npz`** – run metadata (setup, noise)\n",
    "\n",
    "These outputs are used for evaluation and comparison in **`plot.ipynb`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31aa1e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training full_d1_n16:   0%|          | 0/250 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m crit = nn.MSELoss()\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# --- train ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m hist = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m results[name] = {\u001b[33m\"\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m\"\u001b[39m: hist, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model.state_dict()}\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# --- save meta so plotting notebook can reconstruct val_data ---\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_loader, val_loader, model, optim, schedule, crit, epochs, name, save_model, save_curves)\u001b[39m\n\u001b[32m     32\u001b[39m label = label.to(device)\n\u001b[32m     34\u001b[39m optim.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m p_loss, out = \u001b[43mdarcy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m s_loss      = crit(out, label)\n\u001b[32m     37\u001b[39m loss        = p_loss + s_loss\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mdarcy_loss\u001b[39m\u001b[34m(model, inp)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdarcy_loss\u001b[39m(model, inp):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Takes in the k,pres,phi and outputs the prediction across the image.\u001b[39;00m\n\u001b[32m      4\u001b[39m     inp = inp.requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# out is in order K,P,phi, (conductivity, pressure, porosity)\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Impose high pressure along the entire upper line by setting the pressure channelt to 200.\u001b[39;00m\n\u001b[32m      9\u001b[39m     out[:, \u001b[32m1\u001b[39m:\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, :] = \u001b[32m200\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 127\u001b[39m, in \u001b[36mSmallUnet.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m x5 = \u001b[38;5;28mself\u001b[39m.d5(x4)\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Now that we're at 256x7x7, we upsample from here.\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# At each layer with concatenate with the xi that is the same size as the up after upsampling.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m up = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mu1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m up = \u001b[38;5;28mself\u001b[39m.u2(up, x3)\n\u001b[32m    129\u001b[39m up = \u001b[38;5;28mself\u001b[39m.u3(up, x2) \u001b[38;5;66;03m# Again, a small downsample here to get back on the proper resolution\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mUpsample.forward\u001b[39m\u001b[34m(self, below, across)\u001b[39m\n\u001b[32m     81\u001b[39m concat = torch.concat((upsampled, across), dim=-\u001b[32m3\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Convolute them together\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_after\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mTwoConv.forward\u001b[39m\u001b[34m(self, inp)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/stochastic/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for config in tests:\n",
    "    name                        = config.get(\"name\")\n",
    "    reveal_strategy             = config.get(\"reveal_strategy\", \"disks\")\n",
    "    n_points                    = config.get(\"n_points\", 5)\n",
    "    radius                      = config.get(\"radius\", 4)\n",
    "    noise                       = config.get(\"noise\", 0)\n",
    "    deterministic_mask          = config.get(\"deterministic_mask\", False)   # allow jitter by default\n",
    "    jitter_std                  = float(config.get(\"jitter_std\", 0.02))     # 2% jitter\n",
    "    reveal_dim                  = config.get(\"reveal_dim\", [[(0,1)], [(0,1)]])\n",
    "    channels                    = config.get(\"channels\", \"all\")\n",
    "    mixed                       = bool(config.get(\"mixed\", True))\n",
    "    future_delta                = int(config.get(\"future_delta\", 0))\n",
    "\n",
    "\n",
    "    # Pre-define steps and points to maintain a consistent validation set\n",
    "    MAX_TIME = 201 - future_delta\n",
    "    val_steps = np.random.randint(1,MAX_TIME,(val_sims.shape[0],))\n",
    "    val_points = np.random.randint(0,149,(val_sims.shape[0],2))\n",
    "\n",
    "    # --- TRAIN dataset/loader ---\n",
    "    train_data = MaskedDataset(\n",
    "        train_sims,\n",
    "        reveal_strategy     =reveal_strategy,\n",
    "        n_points            =n_points,\n",
    "        radius              =radius,\n",
    "        mixed               =mixed,                      \n",
    "        noise               =noise,\n",
    "        channels            =channels,\n",
    "        reveal_dim          =reveal_dim,\n",
    "        deterministic_mask  =deterministic_mask,\n",
    "        jitter_std          =jitter_std,\n",
    "        future_delta        =future_delta\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "\n",
    "    # --- VAL dataset/loader (deterministic) ---\n",
    "    val_data = MaskedDataset(\n",
    "        val_sims,\n",
    "        reveal_strategy     =reveal_strategy,\n",
    "        n_points            =n_points,\n",
    "        radius              =radius,\n",
    "        mixed               =mixed,\n",
    "        noise               =noise,\n",
    "        channels            =channels,\n",
    "        points              =val_points,\n",
    "        steps               =val_steps,\n",
    "        reveal_dim          =reveal_dim,\n",
    "        deterministic_mask  =True,            \n",
    "        jitter_std          =0.0,                       \n",
    "        future_delta        =future_delta\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)\n",
    "\n",
    "    # --- model/optim ---\n",
    "    model = SmallUnet().to(device)\n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "    schedule = torch.optim.lr_scheduler.ExponentialLR(optim, 0.99)\n",
    "    crit = nn.MSELoss()\n",
    "\n",
    "    # --- train ---\n",
    "    hist = train(train_loader, val_loader, model, optim, schedule, crit, epochs=250, name=name)\n",
    "    results[name] = {\"hist\": hist, \"model\": model.state_dict()}\n",
    "\n",
    "    # --- save meta so plotting notebook can reconstruct val_data ---\n",
    "    save_meta(\n",
    "        name,\n",
    "        reveal_strategy=reveal_strategy,\n",
    "        n_points=n_points,\n",
    "        radius=radius,\n",
    "        noise=noise,\n",
    "        channels=channels,\n",
    "        val_steps=val_steps,\n",
    "        val_points=val_points,\n",
    "        reveal_dim=reveal_dim,\n",
    "        deterministic_mask_train=deterministic_mask,\n",
    "        jitter_std_train=jitter_std,\n",
    "        deterministic_mask_val=True,\n",
    "        jitter_std_val=0.0,\n",
    "        mixed=mixed,\n",
    "        future_delta=future_delta,\n",
    "    )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd80f0d",
   "metadata": {},
   "source": [
    "Mask Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d77bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGZCAYAAABmNy2oAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMKZJREFUeJzt3XlYVdXCP/DvPgMcEGRSEDSBEpAwGRzTxOkait4eNUKtVNR6ule9dX21yVSceu9t0rr5mveWmmXlUE5pWaZoaWqas6JiajkwxCTKETjD+v3Rz3XdHtRzOAcOyvfzPOt5ag9rr83ynO/Z09qKEEKAiIgIgMbdDSAiovqDoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhcAf48MMPoSiKLDqdDqGhoRg6dChycnLc3TyHRUREICMjw6V1KoqC6dOnu7TOjIwMREREuLTO623duhWKomDr1q21tg13uPbvde/eve5uCtWAzt0NIPstXrwYrVu3RkVFBXbs2IFXX30VWVlZOH78OAICAtzdvLvO1KlT8dxzz7m7GUR1iqFwB2nTpg3at28PAOjRowcsFgsyMzOxZs0ajBo1ys2tu/vcd9997m4CUZ3j6aM72LWAyM/PV03fu3cvHnnkEQQGBsJgMCAxMRErVqyQ8w8ePAhFUbBw4UKbOr/++msoioJ169bJaTk5OXj88ccRHBwMT09PxMbG4v/+7/9U61VUVGDixIlISEiAn58fAgMD8eCDD2Lt2rV27UtZWRkmTZqEyMhIeHh4oHnz5vj73/+O8vJym+WefvppBAUFwcfHB3379sXJkyft2gbw31MbmzZtwqhRoxAYGIhGjRrhz3/+M06fPq1a9sbTR8uWLYOiKJg3b55quczMTGi1WmzatElOu10f3Mzp06cxdOhQhIWFwdPTEyEhIejduzcOHDhwy/UyMjLg4+OD48ePIyUlBY0aNUJoaCj++c9/AgB27dqFhx56CI0aNUJ0dDSWLFmiWv/333/H2LFjcf/998PHxwfBwcHo1asXfvjhB5ttvffee4iPj4ePjw98fX3RunVrTJ48+Zbty83NRbt27RAVFXVHnvJsSHikcAc7c+YMACA6OlpOy8rKQt++fdGpUycsWLAAfn5+WLZsGYYMGQKj0YiMjAzEx8cjMTERixcvxpgxY1R1fvjhhwgODkZqaioA4NixY+jSpQtatmyJt956C82aNcM333yDZ599FoWFhcjMzAQAVFZWori4GJMmTULz5s1RVVWF7777DoMHD8bixYsxYsSIm+6H0WhE9+7dcf78eUyePBlt27bF0aNHMW3aNBw+fBjfffcdFEWBEAIDBw7Ejz/+iGnTpqFDhw7YsWMH+vXr5/DfbsyYMejTpw8+/fRTnDt3DlOmTEGPHj1w6NAh+Pv7V7vO0KFDsW3bNkycOBGdO3dG+/btsWXLFsyePRuTJ09Gnz597O6Dm0lNTYXFYsHrr7+Oli1borCwED/++CNKS0tvu08mkwmDBw/GX/7yFzz//PP49NNP8fLLL6OsrAxffPEFXnzxRbRo0QLvvvsuMjIy0KZNG7Rr1w4AUFxcDOCPgGvWrBmuXLmC1atXo0ePHti8eTN69OgB4I9gHDt2LP72t7/hzTffhEajwalTp3Ds2LGbtuvIkSNITU1FixYtsHPnTjRp0uS2+0JuJKjeW7x4sQAgdu3aJUwmk7h8+bLYuHGjaNasmUhOThYmk0ku27p1a5GYmKiaJoQQAwYMEKGhocJisQghhPjXv/4lAIgTJ07IZYqLi4Wnp6eYOHGinJaSkiJatGghLl26pKpv/PjxwmAwiOLi4mrbbDabhclkEmPGjBGJiYmqeeHh4WLkyJHy///xj38IjUYj9uzZo1ru888/FwDEV199JYQQ4uuvvxYAxDvvvKNa7tVXXxUARGZmZrVtud61v+WgQYNU03fs2CEAiNmzZ8tpI0eOFOHh4arlKioqRGJiooiMjBTHjh0TISEhonv37sJsNstl7O2DrKwsAUBkZWUJIYQoLCwUAMTbb7992/240ciRIwUA8cUXX8hpJpNJNG3aVAAQ+/btk9OLioqEVqsV//M//3PT+q71X+/evVV/q/Hjxwt/f/9btuXa33jPnj1i06ZNonHjxiItLU1cvXrV4f2iusfTR3eQzp07Q6/Xw9fXF3379kVAQADWrl0Lne6PA75Tp07h+PHjeOKJJwAAZrNZltTUVOTm5uLEiRMAgCeeeAKenp748MMPZf2fffYZKisr5fWJiooKbN68GYMGDYK3t7dNfRUVFdi1a5dcf+XKlejatSt8fHyg0+mg1+uxcOFCZGdn33K/1q9fjzZt2iAhIUG1jZSUFNXdOVlZWbLt13v88cdt6ry+HrPZDHHDa0NurKNLly4IDw+X27gZT09PrFixAkVFRUhKSoIQAp999hm0Wi0Ax/rgRoGBgbjvvvvwxhtvYM6cOdi/fz+sVust23M9RVHkER4A6HQ6tGrVCqGhoUhMTFRtJzg4GL/++qtq/QULFiApKQkGg0H23+bNm1X917FjR5SWlmLYsGFYu3YtCgsLb9qeJUuWIDU1FU899RRWrFgBg8Fg976Q+zAU7iAfffQR9uzZgy1btuCZZ55BdnY2hg0bJudfu7YwadIk6PV6VRk7diwAyA9xYGAgHnnkEXz00UewWCwA/jh11LFjR8TFxQEAioqKYDab8e6779rUd+3L51p9q1atQnp6Opo3b46lS5di586d2LNnD0aPHo2Kiopb7ld+fj4OHTpksw1fX18IIeQ2ioqKoNPpEBQUpFq/WbNmqv8/e/asTV3btm275TrXphUVFd2yrQDQqlUrdOvWDRUVFXjiiScQGhqq2hfAvj64kaIo2Lx5M1JSUvD6668jKSkJTZs2xbPPPovLly/ftl3e3t42X7weHh4IDAy0WdbDw0PVL3PmzMFf//pXdOrUCV988QV27dqFPXv2oG/fvrh69apcbvjw4Vi0aBF+/fVXPProowgODkanTp1U11OuWbZsGby8vPDUU09BUZTbtp/qB15TuIPExsbKi8s9e/aExWLBBx98gM8//xxpaWnyXO3LL7+MwYMHV1tHTEyM/O9Ro0Zh5cqV2LRpE1q2bIk9e/bgvffek/MDAgKg1WoxfPhwjBs3rtr6IiMjAQBLly5FZGQkli9frvoCqKysvO1+NWnSBF5eXli0aNFN5wNAUFAQzGYzioqKVMGQl5enWj4sLAx79uy56X5Xt861aa1atbptez/44ANs2LABHTt2xLx58zBkyBB06tRJ1VZ7++BG4eHh8gaAkydPYsWKFZg+fTqqqqqwYMGC27atppYuXYoePXqo+h9AtWE0atQojBo1CuXl5fj++++RmZmJAQMG4OTJkwgPD5fLffLJJ5g6dSq6d++Ob7/9FgkJCbXWfnIhN5++Ijtcf472esXFxSIgIEDExsbK89RRUVEiNTXVrnrNZrNo3ry5SE9PF5MmTRIGg0GUlpaqlvnTn/4k4uPjRWVl5S3rGjx4sIiJiVFNy83NFT4+PuLGf2Y3XlOYPXu28Pb2FqdPn77lNurimsKsWbPktOquKRw6dEh4eXmJESNGiMrKStGuXTsRHh6uurZibx/ceE3hZhISEkSHDh1uuczIkSNFo0aNbKZ3795dxMXF2UwPDw8X/fv3l/+flJQkUlJSVMscPHhQaDQam7/BjdasWSMAiA0bNggh1P9ey8rKRHJysvD39xc7d+68ZT1UP/BI4Q4WEBCAl19+GS+88AI+/fRTPPnkk/j3v/+Nfv36ISUlBRkZGWjevDmKi4uRnZ2Nffv2YeXKlXJ9rVaLESNGYM6cOWjcuDEGDx4MPz8/1TbeeecdPPTQQ+jWrRv++te/IiIiApcvX8apU6fw5ZdfYsuWLQCAAQMGYNWqVRg7dizS0tJw7tw5zJo1C6Ghobe9BfHvf/87vvjiCyQnJ2PChAlo27YtrFYrfvvtN3z77beYOHEiOnXqhIcffhjJycl44YUXUF5ejvbt22PHjh34+OOPHf7b7d27F0899RQee+wxnDt3Dq+88gqaN28uT/FUp7y8HOnp6YiMjMT8+fPh4eGBFStWICkpCaNGjcKaNWsAwKE+uN6hQ4cwfvx4PPbYY4iKioKHhwe2bNmCQ4cO4aWXXnJ4Hx0xYMAAzJo1C5mZmejevTtOnDiBmTNnIjIyEmazWS739NNPw8vLC127dkVoaCjy8vLwj3/8A35+fujQoYNNvb6+vti4cSMGDx6MPn36YN26dejZs2et7gs5yd2pRLd3syMFIYS4evWqaNmypYiKipJ3wBw8eFCkp6eL4OBgodfrRbNmzUSvXr3EggULbNY/efKkACAAiE2bNlW7/TNnzojRo0eL5s2bC71eL5o2bSq6dOmiulNHCCH++c9/ioiICOHp6SliY2PF+++/LzIzM297pCCEEFeuXBFTpkwRMTExwsPDQ/j5+YkHHnhATJgwQeTl5cnlSktLxejRo4W/v7/w9vYWffr0EcePH3f4SOHbb78Vw4cPF/7+/sLLy0ukpqaKnJwc1bI3Hik8+eSTwtvbWxw9elS13MqVKwUAMXfuXDnNnj648UghPz9fZGRkiNatW4tGjRoJHx8f0bZtWzF37lzV3U3VcfZIobKyUkyaNEk0b95cGAwGkZSUJNasWWPzN1iyZIno2bOnCAkJER4eHiIsLEykp6eLQ4cO2fyNr//3WllZKR599FFhMBjkEQXVT4oQN9yWQXQX+/DDDzFq1Cjs2bNHXp8hov/i3UdERCQxFIiISOLpIyIiknikQEREEkOBiIgkhgIREUl2P7x2u7FL9Ho9Vq9ejU6dOqF37944dOiQ040jIiLXsecSco2eaA4KClKN4Q/8EQoBAQHQ6XSIj49Ho0aNVPN///13nDp1qiabIyKiOmL33UfXHykMGjQIixYtksMFX+Pl5QWtVguj0Wgz5O/SpUtvOYQAERHVLpcfKQQFBSE5ORnJyclo3LgxNJrqL0nceJQA/DHCZ3p6Oo4cOXLLtzQRUd0wGAzo2bMnzGYztm3bhqqqKnc3iexUq31n73gYAETnzp1FSUmJsFgswmq1OjSehtVqFWazWUyZMkWOtcPCwuK+EhoaKo4dOyZ+/vlnERAQ4Pb2sNR+39nD4WsKWq32pkcIt6IoCrRaLV+2Uc/06dMHbdu2xerVq21eXE93j65du6Jr166qaY0bN0aTJk1gMpnw7LPPql6mA/zxprsb30tBda/O+87RI4WysjKHjhBuNHXqVLenLMt/y/z580VlZaVITU11e1tYaq/MmDHD4c/qxIkT3d5uFtf2nT34PoUGIjIyEs8++yw8PT1V05OTk6HVajFu3DgMGDBANe/EiROYP38+TCZTXTaVXOjBBx/E8OHDq33Xwe0MHjwYkZGRWLRoEfbt21cLraNbcVvf2Zs8er1edOvWzekjhenTpwu9Xi80Go3bE7ihlJr23ZYtW0Tjxo2FVqt1+z6w1KxkZGQ4fP3veiaTSaSlpbl9PxpiqY2+s4fdRwpr166Fv78/vLy87F2lWo8//jg6dOiAOXPmYPPmzU7VRbcXHByM1157DTExMQ73Xdu2bbFixQp88803mDt3bi21kIjqE7tDoUOHDtDpdDbPJjgqLCwM/v7+8gXnVLu8vLzQs2dP1QvV7RUUFISUlBRcvHixFlpGRPWR3bcR9e7dG3/7299gNBqd2uCSJUvwpz/9Cd9++61T9RARkevZfaRw6NAheHt72zyp7Ki8vDyOi0RUy7y9vXHPPfcgNDTUqXoURUHz5s0RHR2N3377DRUVFS5qId2Mu/uOo6QS3YUSExOxceNGvPDCC07Vo9FokJmZiS+//BL333+/i1pHt+LuvmMo3KW0Wi3atWuHLl26wGAwOFVXaGgoevXqhYiICNc0jmpdeXk5srOzXXI96Pz58zhx4oTNA1JUO9zed/be3gTw4bU7qfj6+oqtW7eKq1evCovF4lSfmUwmYTQaxcsvv+z2/WKxr2g0GmEwGMTTTz/t1G2NZrNZPP7448JgMAhFUdy+Xw2h1Gbf2cOhh9d+//13LF26FLGxsUhOTnZouIucnBxs374dBw8edGSTVEMmkwnfffcdCgoK0K9fP/j4+NS4rjNnzmD79u04evSoC1tItclqtaKiosLpBw+FEKiqquK1hDrk7r5zKBR++eUXjB07Funp6ejWrZtDG9q+fTvGjBlj19Ct5LyKigrMnj0bERER6Nixo1OhwL4jajhqNMzFkSNHMH36dNXgdlqtFsOGDUPz5s2xZMkS5OXlqdY5ePAgv1TcwFV/c/YdUcNQo1A4duyYzTsR9Ho92rVrh4CAAPz73//mbadE9YTVaoVGo3F4hGIhBH8MuJk7+s5ldx9ZLBbMnTsX48ePx7lz51xVLRE54YcffsCoUaOwdu1ah9ddtmwZRo8ezeGz3cRdfeeyUVKtViu2bNniqurIRYQQuHr1KioqKuDp6enQLw6LxYLKykq+kesO9ssvv+CXX35BeHg4Hn74YdU8RVHkqLnVXYzctWsXli5dWiftJFvu6rsavaOZ7hyenp5ISEhAUlIS3nzzTXh7e9u97r59+/DSSy/ht99+w4kTJ2qxlVTbIiIibMa/CgoKwttvv43KykpMmDABly9fVs3/5ZdfcP78+bpsJlXDlX1nz9c936dwl6usrMTu3bthMplw/vx5m/dn+/v7w9vbG8XFxTa/OE6dOoXvv/8elZWVddlkqgVnz57F2bNnVdNCQkJw9uxZVFRUYPv27SgtLXVL2+jW6rrveKTQQBgMBrRo0cLm2ZLp06fj0Ucfxfjx47Ft2zbVPKPRiAsXLvBi411Kq9XinnvugRAC586dc3pcM6o7Ne07HimQVFFRgVOnTtlMP3z4MO677z5kZ2fj5MmTbmgZuYvFYrH5BUp3htrsOx4pNHDe3t7w9PTElStX+NpNorucPV/3LgsFRVHQvn17+Pv7Y9euXTYXPoiIyL3s+bp32XMKOp0OU6ZMwZIlSziaJhHRHapG1xRatWqFhx9+2GaYi3vvvRe+vr4YNmwYkpOTVetkZ2fzOQYiovrO3mFYcd3Qrunp6cJsNgur1WpThBDVTl+0aJHbh6RlYWFhacjFHg6dPgoPD8fs2bPx5JNPQlGUaguAaqd36NABb775Jvr06ePIJqkeaN++Pd544w32HVE9ExYWhpkzZ2L06NHQarWuqdSRIwW+ZOfuLxqNRmi1WlUZPXq0sFqtIjMz02aeRqNxe5tZatbP7Ls7qyiKYvP5S0pKEkVFRWL9+vXCYDDYzL/xxUj24HMKJPn6+iIzM9PmkfprNw489thjaNOmjWpeSUkJMjMzkZubW1fNJCd5eHhg8uTJCAsLY9/dQcaOHYsePXqopvn7+8PHxwdJSUn45JNPVA+xWa1WzJ07F7t27XJoOwwFAvDH8wpBQUFISUmx+eK/Ji4uDnFxcappubm5WLBgAcrKymA0Gvn0cz2j1+vh5eWlmubl5YWePXsiKioKCxYsQHl5uWo+37RWv3h6esJgMKBLly5IS0urdpnQ0FAMHjxYNc1isWDDhg04evQojEYjLBaLXdtjKBB0Oh1mzZqF5ORkREZGOrRuUFAQFi5ciMOHD2P8+PEoKyurpVZSTTz88MN45ZVXVHcKajQaxMTEwMvLCwsXLrQJgM8//xxvvfVWXTeVbmLEiBEYPXo07rvvPofW02g0eOWVVzBixAg899xzdr9O1+5QiIyMRFhYmNNPNgcEBCAiIgKFhYW4cuWKU3WRayiKgpiYGLRv397hdT08PJCQkADgj3Ch+sFgMCAkJAT3338/OnfufNPP7bW+u97JkycRGRmJoqIihnw90KJFC3Tu3Nnh9RRFQXR0NEJCQhx6Ha/ddx9lZWVh3rx5Dg29XJ1Ro0YhKysLKSkpTtVDRDeXlJSEb775Bi+88ILD6w4cOBBZWVkYMmRILbSM6ju7f9pduHABPj4+CA4OdmqDZWVluHDhAoxGo1P1ENHNGQwGtGzZ0uZ6gj0aN24sCzU8dh8ppKSkYMKECU5/mX/88cfo27cvNm3a5FQ9RETkenYfKVy5csUlv+4rKyt5LaEeSUpKQkxMDEJDQ52qx9/fHwMHDsTJkyexY8cO3oVE5KSIiAh06NAB999/v1P16PV69O7d2+ZW85vhlcEGbsyYMXjmmWdsXr7jqPDwcPznP//Bhg0b5JveiKjmunfvjg8++MDpz6aXlxdmzZpl9w81hkIDt2nTJhiNRgwaNMjhW96uV1BQgOXLl2P//v123w9NrhcYGIihQ4ciPj7e6bvBevToAUVR8OWXX/Id3W5w5MgRvPXWW3jooYfQtWvXGtdTVVWFFStW4OLFi3jxxRdvv4K9w1MAfwxzcenSJTnwnSOuDYzHYS7qX9Hr9WL9+vUO9+n19u/fLwIDA92+Lw29xMTEiIsXL9boM1rdZ9ZkMom0tDS371dDLjNmzHCqH0tLS0WnTp0EUAsD4p05cwYTJkzAwoULHX6f686dOzF27Fh89dVXDq1HRPbLz8/HSy+9hHfeeQdVVVVO1bVq1SqMGzcO+/btc1Hr6E7g0PFlfn4+Fi1ahLKyMjzxxBM2o/LpdDooigKz2Wxz/uro0aNYsGCB8y0mopsqLS3FRx99hPPnz+OZZ55xqq6dO3fiP//5j4taRneKGp103L59u804G3q9HlOmTEFMTAwmT56M06dPq+ZfuHCh5q0kIqI6UaNQyMvLw8aNG1XT9Ho9hg0bBj8/P2zbts3ucTaofigrK0NRURH8/PwcukBpsVhQVlaG0tJSh08pEtHtGY1GFBYWwsfHBwaDwe71hBC4fPkyiouLYTab7d+gvRcrcJuLIYqiiMjISBEXFycMBoPbL86w2F+u9V1ycrI4fvy4Qxex8vPzxSOPPCKioqKEVqt1+76w/FF69eoljEajQ315o4kTJ7p9P1ggQkJCRHx8vFi7dq1D/Wc2m8XEiRNFXFyc8Pb2FkAdv09BCIEzZ864qjqqQ9f6rqSkBNnZ2Ta/+P38/BAaGorCwkIUFhaq5hUUFODQoUM4e/ZsHbaYbqe8vBwnTpxAcHAwQkNDHRrIsri4GPn5+SgqKqrFFpK98vPzkZ+fj6NHjyIqKko1z9PTE+Hh4TAajbhw4YLqWq7FYsGRI0ccPmujCGHfEw3Ojo5K9Z+iKAgMDIRer1dNHzJkCObOnYs333wTc+bMUc2zWCwoLi7mswn1jIeHBwICAjB06FDMnTvXoc/vokWL8Morr8h3ZFD94OfnZzOWVVxcHFauXIm9e/dizJgxqodGhRC4dOmSamh0e77u+fAaSUKIan8dHj9+HFu2bMHhw4eRl5fnhpaRo6qqqpCfny/77nparRbx8fHw9vbGvn37bL74Dxw4wH6uhy5duoRLly6ppjVq1Ehew83NzXXs2sFN8EiBbkur1UKv18NsNrvkHx3VnWt9dz0vLy+sXr0aUVFR6Nu3L3JyclTz2c93DkVR4OHhASGEXc+l8EiBXMJisfD00B2qur6zWq346quv0KxZMxQUFPDVm3cwIQQqKytdWiePFIiIGgh7vu6dG36PiIjuKgwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBiIgkhgIREUkMBSIikhgKREQkMRSIiEhiKBARkcRQICIiiaFAREQSQ4GIiCSGAhERSQwFIiKSGApERCQxFIiISGIoEBGRxFAgIiKJoUBERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQEREEkOBqAGJjY1F9+7d4e/v7+6mUD3FUCBqIBRFwYQJE7Bq1Sq0bdvW3c2hekrn7gYQkes1a9YMffr0gVarldMURUFsbCwaNWqE1NRU3Hvvvap1zp07h6ysLFit1rpuLtUjihBC2LWgotR2W4jIRXr27In169fDy8vL7nXWr1+PRx99FCaTqRZbRu5kz9c9jxSI7iJNmjRBRkYGHnjgAej1eod+zMXExGDatGnYuXMnvvrqq1psJdVrwk4AWFhY6nmJiYkRFy9etPdjXa13333X7fvBUjvFHrzQTEREkktDwcPDAwaDgdcf7jJarRZeXl7Q6Xi2kehu57JQ0Ol0mDFjBpYtW2ZzVwPd2fr06YMNGzbg8ccfd3dTiKiW1einn8FgQEBAgOqIQK/Xo0OHDkhMTERERASuXr2qWsdoNKK0tNSpxlLt0mg0CAoKgl6vV01v3bo1evTogZ9//hlhYWGqeRaLBYWFhbBYLHXZVLrBtb4LDg5W3YZaE40aNUJYWBguXbqE8vJyF7WQXEmj0aBJkyYQQqCwsNCuu4rsVaNbUvv164e33noLGo1GNT8sLAxeXl44d+4cKisrVeuvWrUKkydPdlGzqTb4+/vjww8/ROvWrVXT/fz8EBISgqKiIhQVFanmFRQUYMSIETh79mwdtpRudK3v2rZti3vuucepU30lJSUoKCjAa6+9hsWLF7uwleQqwcHBWLJkCSoqKpCRkYFLly7ZtZ49X/cO/cvx9vZGq1at8MADDyA6Ovqmv0giIiJspsXFxSExMRG5ubnIy8tzZLNUyxRFQWRkJMLDwxEbG4vo6Ohql2vSpAmaNGmimhYQEICEhAR4enri1KlTPGJwEyEEKioqcPXqVad/NZrNZpSXl/N5hXqiWbNmCA0NVU1r2rQpWrdujcrKSiQkJKCsrEw1/8KFCygoKKjZBu29TQ2AaN++vTh79qwoKysTVqvVodvcKioqRGFhoZg0aZLbb8tiURe9Xi8+++wzUVxcLEwmk0P9arFYRElJidi6davw9/d3+7401KIoimjcuLHo2LGjyMvLc6gPb/T++++LwMBAYTAY3L5fLBAvvviiKCwsVJXi4mJhNpuFyWQSxcXFNvPHjh1bbV32cOhIQafTITAwEL6+vo6sBgDw9PSEp6enQ09YUt3x9fVFQECAw+tpNBr4+/vDz89PdTqR6pYQAmVlZbh06ZLTw1RUVFSguLjYRS2jmmrRogXi4+MRHx+PoKCgmy5X3ec2KSkJqamp2L9/P3Jzcx3aLj/FRET1UK9evbBq1Sqkp6c7vG5GRgY+//xzPPjggw6vyxvPiYjqIY1G4/BQJddotVro9foaHb3zSIGIiCS7jxTeeOMNhIWFwdPT06kNpqSkoHHjxli+fDn27t3rVF3kvMGDB+Ohhx5CbGysU/WEhYVh5syZ2LdvH5YsWcK7kNykoKAAM2fORHx8PMaMGWPzzMmtHDt2DEuWLOHnsqGz944Ek8kkzGazw3cd3chisYiqqioxfPhwt1/VZ4GYN2+eMJlMTver1WoVZrNZrFmzRuj1erfvV0MvPXv2FJcvXxYmk0lVLBaL7Ksb57Hv6k/RaDRi9OjRTn0uTSaTSE9PFxqNRtZrD7sfXktLS0N0dDSmTp3q1B1Ey5Ytw8qVK7F371789ttvNa6HXCMxMRHR0dF4/vnn0a5duxrXc+bMGcyYMQM5OTnYuXOnS5+wJMc1bdoUXbt2tXmWaNy4cejSpQv+93//F0ePHlXNy83NZd/VA23atMHkyZMRFRWFdu3a1XgsOavVip9++gk5OTmYNWsWcnJy7Otbe1MHgOjcubMoKyurSWhJU6dOdXsKs6iLXq8X69evd6pf9+/fLwIDA92+Lyw3L4qiiPfee0/k5uaKbt26ub09LNWX5ORkkZeXJ4xGo1NHClarVZSXl4tz586J9u3bC4BDZxPRdYQQeOONN/DII4/g4MGD7m4O3cSBAwfw5z//GW+++aZT9VitVsyePRuDBg3C8ePH7V6Pt6QSNSCnT5/G6dOn3d0MuoWysjLs2bMHcXFxTtUjhEBOTo7DNw7wSIGIiCSHQuHy5cvYvXs3Tpw44fDFqIKCAvz44484f/68Q+tR7RNCIDs7Gz/99JPDQyVXVVVh3759OHjwIMxmcy21kIjqjL0XLYA/bpPy8fERI0aMEGaz2aGLHh9//LHw9fUVHh4ebr+Qw2JbvLy8RHh4uDh06JBD/Xrx4kWRmJgovL293b4PLCx3U8nIyHD6ltS0tDRVnfZw6JqC1WrFlStXkJOTg5UrV6puldJoNOjatSuCgoKwdetWmxfq/Pjjj7h8+bIjm6M6dPXqVRQXF2Pjxo04duyYal5kZCQ6dOiAo0eP2tzGWFJSgry8PBiNxrpsLtFd78yZM1ixYgXatGnj8PWFAwcOIDs7u2ZnZuxNHdyQYhqNRlUMBoPYsGGD+P3330VCQoLNfEVR3J68LLcviqLY9N21h2gyMzNt5l3/YAwLC4tri0ajETNnznT4KGHSpEnVfjZdfqRwvRuH5zWZTFi5ciV2796N/Px8p4fvJfcQQthcLzp48CBef/11bN++nf1KVIesVit++OEHvPbaa6rpPj4+GDZsGEwmE5YvX27z+uPdu3fX+LNao9dxEhGR+4SFhWHLli24evUqevfubff7L+z5uudzCkREd5jS0lJMnz5dvjrVlXikQETUQNjzdc+H14iISGIoEBHdobRaLQIDA+Hr6+uyOhkKRER3qFatWmH16tV49dVXodO55hIxLzTTTXl7e+Oee+5BWVkZcnNz3d0cogYtNDQUfn5+qmmtW7dG27ZtYbVaERsbC5PJpJp/4cIFhx8a5oVmuqmuXbti6dKlWLNmDSZMmODu5hA1WIqiYO7cuUhPT1dN1+v1CAwMRFVVFUpLS1UXkq1WK/7yl79g/fr1cppbbknV6/VISEiARqPB/v37UVVV5epNkIspioIHHngATZo0UU1PSEhAaGgoWrdujV69eqnmWSwWHDx40GY4EyJyrcjISERGRqJ169YIDQ2tdhmDwYBmzZqpplksFrRv3x5lZWU4cOAAysrK7NugvY9Nw87HsoOCgsTu3bvFgQMHREhIiNsfE2e5fdHr9WLVqlXCaDSqSkVFhbBarcJkMtnMKyoqEsnJyW5vOwvL3V6mTJkijEajMJlMDg11YbVaRWVlpcjLyxMdOnQQQC0PcwH88S7R9u3bq6b5+PggNDQUOp0OQ4cOxaVLl1Tz9+/fz7c+1SMPPvgg4uLicO+999703ds6nc7mIpZGo0FqaiqaNWuGjRs32v8rhOqdwMBApKSkoKCgAFlZWRzKpJ7R6/U3/WzeiqIo8PDwgMFggEbjwD1FzhwpPP/888JqtTpU+I7m+lXmz58v+8bRXyFWq1WcP39eREdHu30/WGpe4uPjRWFhoVi3bp3Q6/Vubw+LusyYMcOhz+aNSktLRadOnQRQi0cKcXFxSEtLw0MPPeTwBehevXpBq9VizZo1OHDgQE02Ty5Wk5sIeOPBnWngwIFITExUTQsJCYG3tzdiYmIwbdo01ZGC1WrFypUrbYZTp7tXjUNh6tSp0Gq1Dq/bo0cPJCcn48yZMwwFojqk0WgwcOBAjBw5str50dHRmDJlimqa2WzGsWPHkJ2d7fDbFsl5rvrxpSiK3XXxOQWiBmDQoEEYOHAgunbt6tB6Go0G48aNQ+/evfHGG2/gl19+qaUW0o26deuGMWPGICEhwal6vLy8MHXqVBQWFtq1PEOhgdLpdNDr9U4/BakoCgwGAzw9PVFZWemi1pGrJSQkYMSIEQ6vp9Fo0L17dyQkJGDx4sUMhToUHh6OtLQ0eHh4OFWPXq9Hr1697L6BgMNcNFBpaWn46quv0L9/f6fqCQoKwvvvv4958+a5dPwVooZu06ZN6N+/Pz799FOn6jEajZgwYQJSU1PtWt6hn4l6vR5BQUEICAioUeOu5+/vj9DQUBQVFfEBNzcIDAxEVFSUzWPzjtLpdAgPD8elS5dqdI2JiKqXn5+P/Px8mwdHHWU2m7F//37s3r3bruUdOlKIi4vDhg0bMG3aNMfue72Boih48cUX8fXXXzt9voxq5rPPPkOvXr2wbt06p+opLCzEyJEj8fTTT/NZBaK7gENHChaLBUaj0SXnjquqqmA0GvmgjJuUlJSgpKTE6WEqzGYzzpw5g19//dU1DSOXCgwMRMuWLW2GQHCUVqtFdHQ0Ll++jJycHJuB1+ju4dDP/ezsbDzyyCOYPXu2U1/mQgi8/vrr6N+/P29LJapFKSkp2LRpE4YPH+5UPd7e3nj33XfxySefICQkxEWto/rIoVAwm80oKSnBlStXnN5weXk5SkpKYDabna6LiKpXUFCAnTt34ty5c07VY7FYcPjwYfz888+8y6yOnThxAuvXr3e4D4UQ+Pnnn/HNN9+gpKTEoRXtguseu05PTxdms7lmz1wLISwWixg5cqTbHx9n+WOYC2dwmIv6XRRFEXq9XsyaNcupfi4tLRVdu3YVOp3O7fvU0IpGoxEeHh5iyZIlDvWZyWQSQ4YMETqdTiiKIoA6GBCP7nzbtm0DAPTr1w8RERF2r2cymbB+/XocO3aMw2fXY0IImEwml1y7M5vNPLJ3A6vViqqqKmzatMnmZo4mTZpg4MCByMvLw9dffw2LxaJa78SJEw73GUOhgVu+fDlWrVqFli1bOhwK//rXv7B169ZaaxsR/dfSpUuxdOlS1bT4+Hj06dMHR44cwXPPPeeSGwBqFAoHDhzA888/j169emHAgAEOrfvNN9/g22+/xZ49e2qyaaoFFosFCxcuRFZWlmp6q1atMGbMGBw4cADLly9XzTOZTHy6lcjNLl68iGnTpuHixYuqowSn2Ht+CtWc65o0aZIwmUyqYjab5bDKZrPZZv6UKVPcfo6Oxb7Ss2dPcfnyZfHBBx+4vS0szpXMzExhMpmExWJx6Lz0tc9xUVGR6Nixo9v3g8W5UuvXFNatW4czZ86opvn6+iIzMxN6vR6ZmZk255s5BO+d48iRIxg+fLjTd66Q+61cuRJHjhzBuHHj0LNnT7vXs1qtePvtt/H999/j1KlTtdhCqi+U/38UcPsF7Rx2NTAwEOvWrYOnpyf69++PgoICpxpIRK6hKArmz5+PYcOGqaZrtVp4e3vLh1OvZ7FYMHr0aKxdu7Yum0q1xJ6ve5eHgk6nQ2xsLBRFQXZ2Np98JKpH7r33XjRt2lQ1LSoqCvPmzcPhw4fx0ksvqe5WEULg1KlTKC4uruumUi2w5+ve5Xcfmc1mHD582NXVEpELnD59GqdPn1ZNq6iogNlsRmlpKX766Sf+kGvg7D5SICKiux/fp0BERBJDgYiIJIYCERFJDAUiIpIYCkREJDEUiIhIYigQEZHEUCAiIomhQERE0v8DuFvCOMAas60AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the dataset\n",
    "val_data = MaskedDataset(\n",
    "    val_sims,\n",
    "    reveal_strategy=\"disks\",\n",
    "    n_points=16,\n",
    "    radius=5,\n",
    "    noise=0,\n",
    "    reveal_dim=[[(0,0.15),(0.85,1)],[(0,1)]],\n",
    "    return_mask=True,\n",
    "    jitter_std=0.01,\n",
    "    deterministic_mask=False\n",
    ")\n",
    "\n",
    "z, t, mask = val_data[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mask.numpy(), cmap=\"gray\")\n",
    "plt.title(\"Revealed-pixels mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2f633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"delta_1_short\"\n",
    "# Rebuild exactly the same val dataset (disks + deterministic, jitter 0)\n",
    "meta = np.load(f\"meta_{name}.npz\", allow_pickle=True)\n",
    "val_data = MaskedDataset(\n",
    "    val_sims,\n",
    "    reveal_strategy=str(meta[\"reveal_strategy\"]),\n",
    "    n_points=int(meta[\"n_points\"]),\n",
    "    radius=int(meta[\"radius\"]),\n",
    "    noise=float(meta[\"noise\"]),\n",
    "    channels=str(meta[\"channels\"]),\n",
    "    steps=meta[\"val_steps\"],\n",
    "    points=meta[\"val_points\"],            # only matters if reveal_strategy == \"block\"\n",
    "    reveal_dim=meta[\"reveal_dim\"],\n",
    "    deterministic_mask=True,\n",
    "    jitter_std=0.0,\n",
    "    future_delta=int(meta[\"future_delta\"]),\n",
    "    return_mask=True                      # <— so we can inspect it\n",
    ")\n",
    "\n",
    "z, t_label, mask = val_data[0]\n",
    "plt.imshow(mask.numpy(), cmap=\"gray\"); plt.title(\"Val mask\"); plt.axis(\"off\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2326a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
